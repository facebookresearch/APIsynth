{
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "bento_kernel_pytorch",
      "metadata": {
        "kernel_name": "bento_kernel_pytorch",
        "nightly_builds": true,
        "fbpkg_supported": true,
        "is_prebuilt": true
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "captumWidgetMessage": {},
    "last_msg_id": "b03dfce9-b9a04a1a85010cca08478e62_1388",
    "last_server_session_id": "2bfade23-08dd-4475-85b9-3c2d1a6d51af",
    "last_kernel_id": "4ce595f2-db1e-4f21-91f4-f2f2910eeac8",
    "last_base_url": "https://devvm3095.ftw0.facebook.com:8090/",
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "originalKey": "af2ba64f-7791-435b-bd66-bafaf0d75661",
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "7ef50411-bdbf-4393-9572-3d05def2f25d",
        "executionStartTime": 1630712367820,
        "executionStopTime": 1630712368632
      },
      "source": [
        "import random\n",
        "from random import choice\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "0fff4266-d72a-4aa3-8ea3-919f9b257063",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "ca0303aa-8755-4c5a-8170-0d36ee0a4569",
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1630723787628,
        "executionStopTime": 1630723787851
      },
      "source": [
        "class pycoder_parameters:\n",
        "\n",
        "    ''' Path '''\n",
        "    Path =  'exhaustive_17api' #'seq_30api'\n",
        "\n",
        "    ''' Core Fuzzing Parameters '''\n",
        "    NUM_FUZZ_PER_API= 100001 #000\n",
        "    NUM_TEST_FUZZ = 2\n",
        "    FLOAT_TENSOR = False #We either generate float or integer tensors\n",
        "    UNIT_TEST = False\n",
        "    COMPOSITE = True\n",
        "\n",
        "    ''' Fuzzing Detailed Parameters '''\n",
        "    MAX_TENSOR_DIMENSIONS = 3 #how many rows, columns, etc.\n",
        "    MIN_VAL_PER_DIMENSION = 1 # e.g., min number of rows, columns, etc. \n",
        "    MAX_VAL_PER_DIMENSION = 5 # e.g., max number of rows, columns, etc. \n",
        "\n",
        "    #So far limiting to integers\n",
        "    MIN_TENSOR_VALUE = 1\n",
        "    MAX_TENSOR_VALUE = 15\n",
        "    \n",
        "\n",
        "    ''' Embedding Parameters '''\n",
        "    EMBEDDING_NOISE_LEVEL = 0 #0 noise by default\n",
        "    EMBEDDING_SIZE = 150\n",
        "    SHAPE_EMBEDDING_SIZE = 6\n",
        "\n",
        "\n",
        "    data_type = 'float' if FLOAT_TENSOR is  True else 'integer'\n",
        "    model_type = 'Composite_' if COMPOSITE is  True else 'Single_'\n",
        "    file_name = str(model_type) + str(NUM_FUZZ_PER_API) + '_' + data_type\n",
        "    fuzzing   = file_name + '.pt'\n",
        "    embedding = file_name + '.embedding' + '.pt',\n",
        "    classification = file_name + '.model_result' + '.pt' \n",
        "    train_valid_test = file_name + 'train_valid_test.pt'\n",
        "\n",
        "    def setNoiseLevel(self, noise):\n",
        "        self.EMBEDDING_NOISE_LEVEL = noise\n",
        "        self.embedding = self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt'\n",
        "\n",
        "    def getEmbeddingFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt')\n",
        "\n",
        "    def getVisulizationFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '_' +  'tSNE.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "cbb4753d-d497-4e01-acaf-d136a37c5a4b",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "3ec123e2-488a-4280-bd72-0236d059ae74",
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1630723788774,
        "executionStopTime": 1630723789105
      },
      "source": [
        "NOISE = 0\n",
        "f = pycoder_parameters()\n",
        "f.setNoiseLevel(NOISE)\n",
        "f.embedding = f.getEmbeddingFile() \n",
        "print(f.embedding)\n",
        "print(f.SHAPE_EMBEDDING_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7876d68e-2702-44e8-a5b9-c10d089d02ff",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "6e4fb8ca-5fc8-44a8-a581-66b908af21a3",
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1630720677452,
        "executionStopTime": 1630720677856
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "def add_noise(orig_tensor):\n",
        "    \n",
        "    orig_tensor = orig_tensor.double()\n",
        "    data = torch.flatten(orig_tensor).numpy()    \n",
        "    zero_like = torch.flatten(torch.zeros_like(orig_tensor,dtype=bool))\n",
        "    mask = zero_like.numpy()\n",
        "\n",
        "    elem_size = np.prod(list(orig_tensor.shape))\n",
        "    N =  int(elem_size * f.EMBEDDING_NOISE_LEVEL)\n",
        "    mask[:N] = True\n",
        "    \n",
        "    np.random.shuffle(mask)\n",
        "    data[mask] = 0\n",
        "    return(torch.Tensor(data))\n",
        "\n",
        "t1 = torch.tensor([1,2,3,4,5]) #[[1,2,3]],[[4,5,6]], [[7,8,9]]])\n",
        "print(t1, add_noise(t1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7c7e916a-34d7-4572-811c-4c01055e4064",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "159b1fbe-f643-4722-8bc0-c4116bc7088d",
        "executionStartTime": 1630720680766,
        "executionStopTime": 1630720680949
      },
      "source": [
        "import sklearn.datasets\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "EMBEDDING_SIZE = f.EMBEDDING_SIZE\n",
        "SHAPE_EMBEDDING_SIZE = f.SHAPE_EMBEDDING_SIZE\n",
        "\n",
        "def encode_values_to_code(tensor):\n",
        "    tensor = tensor.clone()\n",
        "    tensor[(tensor>=100) & (tensor<1000)] = 100\n",
        "    tensor[(tensor>=1000)] = 101\n",
        "    tensor[(tensor<=-20) & (tensor>-100)] = -20\n",
        "    tensor[(tensor<=-100) & (tensor>-1000)] = -21\n",
        "    tensor[(tensor<=-1000)] = -22\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def tensor_flatten_pad(tensor, embed_size=EMBEDDING_SIZE, shape_embed_size=SHAPE_EMBEDDING_SIZE, isNoise=False):\n",
        "    \n",
        "    t_flatten = torch.flatten(tensor)\n",
        "\n",
        "    if isNoise is True:\n",
        "        t_flatten = add_noise(t_flatten)\n",
        "    padding_length = embed_size - list(t_flatten.shape)[-1]\n",
        "    p1d = (0,padding_length) #just padding the last dimension\n",
        "    t_pad = F.pad(input=t_flatten, pad=p1d, mode='constant', value=0).type(torch.FloatTensor)\n",
        "    \n",
        "    type_padding = 0\n",
        "    if tensor.dtype == torch.bool:\n",
        "        type_padding = 1\n",
        "    elif tensor.dtype == torch.float64 \\\n",
        "        or tensor.dtype == torch.double \\\n",
        "        or tensor.dtype == torch.float32 \\\n",
        "        or tensor.dtype == torch.float16:\n",
        "            type_padding = 2\n",
        "    \n",
        "    \n",
        "    '''size embedding'''\n",
        "    if(shape_embed_size > 0):\n",
        "        t_shape = list(tensor.shape)\n",
        "        padding_length = shape_embed_size -1 - len(t_shape)\n",
        "        p1d = (0,padding_length) #just padding the last dimension\n",
        "        s_pad = F.pad(input=torch.Tensor(t_shape), pad=p1d, mode='constant', value=0).type(torch.float)\n",
        "\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        s_pad_list = s_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1] + s_pad_list + [-1])\n",
        "    \n",
        "    else:\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1])\n",
        "        \n",
        "    encoded_tensor = encode_values_to_code(tensor_embedding)\n",
        "    return(encoded_tensor)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f7fb4330-9c83-4abf-9f34-0ce396ba6c84",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "1a1f4810-017a-44c7-a46b-3f08611e889a",
        "executionStartTime": 1630720682403,
        "executionStopTime": 1630720682598
      },
      "source": [
        "import itertools\n",
        "from random import sample\n",
        "\n",
        "def split_dataset(orig_dataset, train_frac=0.9):\n",
        "\n",
        "    print('len orig_dataset', len(orig_dataset))\n",
        "  \n",
        "    dataset =  orig_dataset #sample(orig_dataset,len(orig_dataset)//10)\n",
        "\n",
        "    print('len dataset', len(dataset))\n",
        "\n",
        "    length = len(dataset)\n",
        "    train_length = int(length * train_frac)\n",
        "    valid_length = int((length - train_length) / 2)\n",
        "    test_length  = length - train_length - valid_length\n",
        "\n",
        "    print(train_length, valid_length, test_length)\n",
        "\n",
        "    idx = list(range(length))  # indices to all elements\n",
        "    random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
        "    train_idx = idx[:train_length]\n",
        "    val_idx = idx[train_length:(train_length + valid_length)]\n",
        "    test_idx = idx[(train_length + valid_length):]\n",
        "\n",
        "    train_set = [dataset[i] for i in train_idx]\n",
        "    valid_set = [dataset[i] for i in val_idx]\n",
        "    test_set = [dataset[i] for i in test_idx]\n",
        "\n",
        "\n",
        "    print(len(train_set), len(valid_set), len(test_set))\n",
        "    return(train_set, valid_set, test_set)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "05efa82a-7e22-4de7-9975-fdc7b24b0b0d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a1f7641a-ec15-46ce-a198-e4e4da729965",
        "executionStartTime": 1630720684168,
        "executionStopTime": 1630720684367
      },
      "source": [
        "import itertools\n",
        "from random import sample\n",
        "\n",
        "def sample_dataset(orig_dataset, frac=0.9):\n",
        "\n",
        "    print('len orig_dataset', len(orig_dataset))\n",
        "  \n",
        "    dataset =  orig_dataset #sample(orig_dataset,len(orig_dataset)//10)\n",
        "\n",
        "    print('len dataset', len(dataset))\n",
        "\n",
        "    length = len(dataset)\n",
        "    frac_length = int(length * frac)\n",
        "\n",
        "    idx = list(range(length))  # indices to all elements\n",
        "    random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
        "    frac_idx = idx[:frac_length]\n",
        "    frac_set = [dataset[i] for i in frac_idx]\n",
        "    return(frac_set)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "05fc3c8d-3586-4df9-ae2b-bcfa9d359a69",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2633a5f5-04ab-48dc-a465-ffefbe1e3416",
        "executionStartTime": 1630720691071,
        "executionStopTime": 1630720691258
      },
      "source": [
        "def load_test_data(dataset):\n",
        "       \n",
        "    global EMBEDDING_SIZE\n",
        "    global api2indx\n",
        "    \n",
        "    X=[]\n",
        "    X_alt = []\n",
        "    y=[]\n",
        "    dict_indx = len(api2indx)\n",
        "    for data_list in dataset:\n",
        "        if data_list[-1] == -1:\n",
        "            continue\n",
        "        final_output = data_list[-1][1]\n",
        "        prev_out = torch.Tensor()\n",
        "        api_seq_x = []\n",
        "        api_seq_x_alt = []\n",
        "        api_seq_y = []\n",
        "        for data in data_list:        \n",
        "            if data == -1:\n",
        "                continue    \n",
        "            api = data[0]\n",
        "            if api2indx.get(api, -1) == -1: \n",
        "                api2indx[api] = dict_indx\n",
        "                dict_indx += 1\n",
        "                 \n",
        "            api_indx = api2indx[api]\n",
        "            input_list = data[2] #.get_input()\n",
        "            output_tensor = final_output #data.get_output()\n",
        "\n",
        "            it_pad = []\n",
        "            it_pad_alt = []\n",
        "            for input_tensor in input_list:\n",
        "                if input_tensor.shape == prev_out.shape and torch.all(input_tensor.eq(prev_out)).item():\n",
        "                    #same with previous output\n",
        "                    t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                    t[-1] = -1\n",
        "                    it_pad.append(t)\n",
        "                else:         \n",
        "                    #flatten the input tensor\n",
        "                    it_pad.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "\n",
        "                it_pad_alt.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "                \n",
        "            \n",
        "            #adding addidional tensors with zero embeddings for < 2 tensors\n",
        "            for i in range(len(it_pad),3):\n",
        "                t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                t[-1] = -1\n",
        "                it_pad.append(t)\n",
        "                it_pad_alt.append(t)\n",
        "            \n",
        "            ot_pad = tensor_flatten_pad(output_tensor, isNoise=True)\n",
        "            \n",
        "            x = T.flatten(T.stack((it_pad[0],it_pad[1], it_pad[2], ot_pad)))      \n",
        "            api_seq_x.append(x) \n",
        "            api_seq_y.append(api_indx)\n",
        "\n",
        "            x_alt = T.flatten(T.stack((it_pad_alt[0],it_pad_alt[1], it_pad_alt[2], ot_pad)))      \n",
        "            api_seq_x_alt.append(x_alt) \n",
        "\n",
        "\n",
        "            prev_out = data[1]\n",
        "\n",
        "        X.append(api_seq_x)\n",
        "        X_alt.append(api_seq_x_alt)\n",
        "        y.append(api_seq_y)\n",
        "    print(len(X), len(y))\n",
        "    return(X,X_alt, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "125ae1ce-312b-4509-a0cc-82f9cb37eb4b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "69046049-3369-4d9f-ba65-56d56393f1f4",
        "executionStartTime": 1630604545112,
        "executionStopTime": 1630604545139
      },
      "source": [
        "api2indx = torch.load(f.Path + '/api2indx.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "45267b3e-802e-4de5-af9a-b9726c6774a0",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "faee515e-c48b-4956-b2e3-bfbab630e108",
        "executionStartTime": 1630723809723,
        "executionStopTime": 1630724043866
      },
      "source": [
        "SAVE_FILE = f.fuzzing\n",
        "i = 10\n",
        "fuzz_file = f.Path + '/fuzzing_data/' + str(i*10000) + '_' + SAVE_FILE\n",
        "embed_file = f.Path + '/' + str(i*10000) + '_test_embedding.pt' #+ f.embedding\n",
        "print(embed_file)\n",
        "l = torch.load(fuzz_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "bcc64c98-4a78-4303-b44b-1f954f961256",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "18f60cfd-7515-4194-9906-44dcf87d75fc",
        "executionStartTime": 1630727504486,
        "executionStopTime": 1630727506186
      },
      "source": [
        "test_set = sample_dataset(l,0.02)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "84c857c4-9404-4a7f-aacd-cfec141f7f55",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7ced6203-6ad8-4460-88a0-a839059de1b1",
        "executionStartTime": 1630727506195,
        "executionStopTime": 1630727506793
      },
      "source": [
        "len(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "dea5d7cb-8eac-4719-b686-0f3b2f1b005c",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "b1e68744-4cef-424e-8f85-1e5d4d0a0b2a",
        "executionStartTime": 1630715287876,
        "executionStopTime": 1630715288045
      },
      "source": [
        "class FinalEmbedding:\n",
        "    def __init__(self,x,y):\n",
        "        self.x_data = x\n",
        "        self.y_data = y\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        preds = self.x_data[idx]\n",
        "        trgts = self.y_data[idx] \n",
        "        sample = { \n",
        "        'predictors' : preds,\n",
        "        'targets' : trgts\n",
        "        }\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "0e2824cd-f132-4d0b-9bb5-0d41bb39762f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "e4c690ac-276a-40ce-a903-60321e22798b",
        "executionStartTime": 1630715289870,
        "executionStopTime": 1630715290045
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "device = T.device(\"cuda\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7e0f938e-2618-4844-96bf-d0ad29a07bec",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "fc8d6753-87e1-400e-8d68-8e0bb7bd2e39",
        "executionStartTime": 1630715291116,
        "executionStopTime": 1630715291280,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def process_dataX(tensor_list):\n",
        "    io_seq = []\n",
        "    \n",
        "    n0 = tensor_list[0]\n",
        "\n",
        "    if(len(tensor_list) == 1):\n",
        "        n1 = torch.zeros(n0.shape)\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "        \n",
        "    elif(len(tensor_list) == 2):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "\n",
        "    elif(len(tensor_list) == 3):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = tensor_list[2]\n",
        "\n",
        "    new_list = torch.stack((n0, n1, n2))\n",
        "    io_seq.append(new_list)\n",
        "    return(torch.stack(io_seq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "044f24e3-32a3-40c9-b1b5-87e29e83e485",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "4a372f7a-6e28-4d03-8dd1-9d07e1cc5ada",
        "executionStartTime": 1630715292261,
        "executionStopTime": 1630715292421
      },
      "source": [
        "indx2api = {}\n",
        "EOS = '<eol>'\n",
        "\n",
        "def process_dataY(api_seq):\n",
        "    global indx2api\n",
        "    global api2indx\n",
        "\n",
        "    ''' Add <eol> to the dictionary '''\n",
        "    indx2api = {v: k for k, v in api2indx.items()}\n",
        "\n",
        "    if api2indx.get(EOS, -1) == -1:\n",
        "        max_key = max(indx2api.keys())\n",
        "        print(max_key)\n",
        "        indx2api[max_key+1] = EOS\n",
        "        api2indx[EOS] = max_key+1\n",
        "\n",
        "    eos = api2indx[EOS]\n",
        "    api_tensors = []\n",
        "    api0 = api_seq[0]\n",
        "\n",
        "    if len(api_seq) == 1:\n",
        "        api1 = eos\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 2:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 3:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = api_seq[2]\n",
        "\n",
        "    else:\n",
        "        print('!!! Not supposed to be here')\n",
        "\n",
        "    t = torch.tensor([api0, api1, api2])\n",
        "    api_tensors.append(t)\n",
        "    \n",
        "    return(torch.stack(api_tensors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ca0d53e3-c277-464a-bbb5-d6cf13dcd058",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "49e371bd-d6cc-43ea-8f2b-b78c56d2bc92",
        "executionStartTime": 1630715293177,
        "executionStopTime": 1630715293345,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, bidirectional=True)   \n",
        "        \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        #Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        \n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out1 = out.contiguous().view(-1, self.hidden_dim*2)\n",
        "        out1 = self.fc(out1)\n",
        "        \n",
        "        return out1, hidden, out\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        hidden = torch.zeros(self.n_layers*2, batch_size, self.hidden_dim).to(device)\n",
        "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7d15661c-325f-47d2-bd2c-52c90e19ad04",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "92eec068-b0b9-4514-9f4f-2674b73d7ff1",
        "executionStartTime": 1630715294425,
        "executionStopTime": 1630715294595
      },
      "source": [
        "class FFNet(T.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FFNet, self).__init__()\n",
        "\n",
        "    self.hid1 = T.nn.Linear(4*(f.EMBEDDING_SIZE+f.SHAPE_EMBEDDING_SIZE+1+2), 500)\n",
        "    self.hid2 = T.nn.Linear(500, 250)\n",
        "    self.hid3 = T.nn.Linear(250, 100)\n",
        "    self.oupt = T.nn.Linear(100, len(api2indx))\n",
        "\n",
        "    T.nn.init.xavier_uniform_(self.hid1.weight)\n",
        "    T.nn.init.zeros_(self.hid1.bias)\n",
        "    T.nn.init.xavier_uniform_(self.hid2.weight)\n",
        "    T.nn.init.zeros_(self.hid2.bias)\n",
        "    T.nn.init.xavier_uniform_(self.oupt.weight)\n",
        "    T.nn.init.zeros_(self.oupt.bias)\n",
        "\n",
        "    T.nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    z1 = T.tanh(self.hid1(x))\n",
        "    z2 = T.tanh(self.hid2(z1))\n",
        "    z3 = T.tanh(self.hid3(z2))\n",
        "    z = self.oupt(z3)  # no softmax: CrossEntropyLoss() \n",
        "    return (z, z3, z2, z1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9e9fff4d-7f5c-4321-b466-f5bcd4a40594",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "45135368-d1f9-4435-b351-cce0fee837ee",
        "executionStartTime": 1630715296456,
        "executionStopTime": 1630715296615
      },
      "source": [
        "DEBUG = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f15439f8-bb33-473f-8af9-04d8aa68efb8",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "bb6c0089-548c-41c6-8236-beaf736d0826",
        "executionStartTime": 1630715297708,
        "executionStopTime": 1630715297878,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def embed_tensor_for_model(domain_io):\n",
        "\n",
        "    x, y = embed_tensors(domain_io)\n",
        "\n",
        "    X = process_dataX(x[0])\n",
        "    Y = process_dataY(y[0])\n",
        "    ds = FinalEmbedding(X,Y)\n",
        "\n",
        "    X = ds[0]['predictors'].to(device)\n",
        "    Y = ds[0]['targets'].to(device)  # [0] [1] or [2]\n",
        "\n",
        "    return(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f31631e5-a8d2-49a6-905d-89bae0eaa1ab",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "ee5c945a-60e8-442e-817b-179806bff104",
        "executionStartTime": 1630715303060,
        "executionStopTime": 1630715303226,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def beam_search(top3_list):\n",
        "\n",
        "    api_seq = []\n",
        "    api_seq1 = []\n",
        "    for i in top3_list[0]:\n",
        "        for j in top3_list[1]:\n",
        "            api_seq1.append(((i[0], j[0]), i[1]*j[1]))\n",
        "    \n",
        "    api_seq1.sort(key = lambda x: x[1], reverse=True) \n",
        "\n",
        "    for k in top3_list[2]:\n",
        "        for s1 in api_seq1:\n",
        "            api_seq.append(((s1[0][0], s1[0][1], k[0]), s1[1]*k[1]))\n",
        "\n",
        "    api_seq.sort(key = lambda x: x[1], reverse=True) \n",
        "    \n",
        "    return(api_seq)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "661ec441-e91b-41c3-ae63-2fec5fd1ccfe",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "b5f6fc34-74ac-4972-b822-3d4b2414d248",
        "executionStartTime": 1630715304963,
        "executionStopTime": 1630715305116,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def query_model(X, Y):\n",
        "\n",
        "    with T.no_grad():\n",
        "      start_time = time.time()\n",
        "      predicts, z3, z2, z1 = net(X)\n",
        "      temp_z3 = torch.unsqueeze(z3,0)\n",
        "      model_output, hidden, int_output = rnn_model(temp_z3)\n",
        "\n",
        "      target_list = list(Y.cpu().numpy())\n",
        "    \n",
        "    h = (int_output,target_list,temp_z3)\n",
        "\n",
        "    top_indx = []\n",
        "\n",
        "    for m in model_output:\n",
        "        prob = nn.functional.softmax(m, dim=0).data\n",
        "        # Taking the class with the highest probability score from the output\n",
        "        api_ind = torch.max(prob, dim=0)[1].item()\n",
        "        top_indx.append(api_ind)\n",
        "        if DEBUG:\n",
        "          print(indx2api[api_ind])\n",
        "      \n",
        "    ed = 0\n",
        "\n",
        "    return(h, top_indx)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "30937dd9-b111-4532-a2ca-00588e53a0a9",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "54de001c-3ba3-4da8-b948-9c8a3def7684",
        "executionStartTime": 1630712871099,
        "executionStopTime": 1630712871396,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def api_edit_distance(seq1, seq2):\n",
        "\n",
        "    edit_distantce = 0\n",
        "\n",
        "    for i in range(len(seq1)):\n",
        "        if seq1[i] != seq2[i]:\n",
        "            edit_distantce += 1\n",
        "\n",
        "    return(edit_distantce)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a3e4af71-f700-40dc-98b8-d94d6d8142e1",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "92cd894f-fcf8-48c2-b21d-dc6004dd123e",
        "executionStartTime": 1630715409877,
        "executionStopTime": 1630715410060
      },
      "source": [
        "net = torch.load('net_model.pt')\n",
        "rnn_model = torch.load('rnn_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ff1ca55c-20f5-47f8-ae0c-779e5c835f8b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "9bf3a7da-f8ce-431b-beb8-2614d9588d33",
        "executionStartTime": 1630727515701,
        "executionStopTime": 1630727554012
      },
      "source": [
        "x, x_alt, y = load_test_data(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9a5e7216-99b6-4ee4-b8e8-97026961ed3e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ba439dca-22aa-4adf-8d83-a21dd841a618",
        "executionStartTime": 1630715421721,
        "executionStopTime": 1630715421896
      },
      "source": [
        "def validation_fos(x, x_alt, y):\n",
        "\n",
        "    total_query = 0\n",
        "    ncorrect = 0\n",
        "\n",
        "    for i in range(0,len(x_alt)):\n",
        "        for j in range(0,len(y[i])):\n",
        "            test_set_x1 = process_dataX([x_alt[i][j]])\n",
        "            test_set_y1 = process_dataY([y[i][j]])\n",
        "            ds = FinalEmbedding(test_set_x1,test_set_y1)\n",
        "            X1 = ds[0]['predictors'].to(device)\n",
        "            Y1 = ds[0]['targets'].to(device)\n",
        "            model_output1, top_index1 = query_model(X1,Y1)\n",
        "            total_query += 1\n",
        "            if top_index1[0] == Y1[0]:\n",
        "                ncorrect += 1\n",
        "\n",
        "            \n",
        "    print (total_query, ncorrect, ncorrect/total_query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "73b4988b-aa27-4794-921a-171fed30171f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "16aeebe1-cd06-49d3-93db-6c6dd305f9ca",
        "executionStartTime": 1630715423464,
        "executionStopTime": 1630715479407
      },
      "source": [
        "validation_fos(x, x_alt, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7cf88f46-e018-46c0-befc-75ec8be132c3",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c18b8009-ca2f-4ded-87c6-3d30ed8e4877",
        "executionStartTime": 1630642187899,
        "executionStopTime": 1630642188408
      },
      "source": [
        "import scipy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "114202b3-a2b8-4b36-915f-f9d5da9429ea",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2a1dd379-d15f-4563-a704-0379b55e858e",
        "executionStartTime": 1630642208725,
        "executionStopTime": 1630642243418
      },
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "final_hiddens = []\n",
        "\n",
        "#comparing h2 of generative model with h1 of first in seq model\n",
        "hidden_states0 = []\n",
        "hidden_states1 = []\n",
        "y_axis = []\n",
        "\n",
        "ncorrect = 0\n",
        "sim_index = [0,0,0]\n",
        "\n",
        "similar = []\n",
        "dissimilar = []\n",
        "\n",
        "for i in range(0,len(x)):\n",
        "    if len(x[i]) < 2:\n",
        "        continue\n",
        "    if y[i][0] == y[i][1]:\n",
        "        continue #removing the same APIs to reduce noise\n",
        "    test_set_x = process_dataX(x[i])\n",
        "    test_set_y = process_dataY(y[i])\n",
        "    ds = FinalEmbedding(test_set_x,test_set_y)\n",
        "    X = ds[0]['predictors'].to(device)\n",
        "    Y = ds[0]['targets'].to(device)\n",
        "    model_output0, top_index0 = query_model(X,Y)\n",
        "\n",
        "    if top_index0[1] != Y[1]:\n",
        "        continue\n",
        "    else:\n",
        "        ncorrect += 1\n",
        "    \n",
        "    test_set_x1 = process_dataX([x_alt[i][1]])\n",
        "    test_set_y1 = process_dataY([y[i][1]])\n",
        "    ds = FinalEmbedding(test_set_x1,test_set_y1)\n",
        "    X1 = ds[0]['predictors'].to(device)\n",
        "    Y1 = ds[0]['targets'].to(device)\n",
        "    model_output1, top_index1 = query_model(X1,Y1)\n",
        "    \n",
        "    if top_index1[0] != Y1[0]:\n",
        "        continue\n",
        "\n",
        "    hiddens0 = model_output0[0].cpu()#.tolist()\n",
        "    hiddens1 = model_output1[0].cpu()#.tolist()\n",
        "\n",
        "    hiddens0 = hiddens0[0]\n",
        "    hiddens1 = hiddens1[0]\n",
        "\n",
        "    hidden_states0.append(hiddens0[1])\n",
        "    hidden_states1.append(hiddens1[0])\n",
        "    y_axis.append(Y1[0].item())\n",
        "\n",
        "    final_hiddens.append((hiddens0[0], hiddens0[1], hiddens0[2], hiddens1[0], Y1[0].item()))\n",
        "\n",
        "    results = []\n",
        "    for k in [0,1,2]:\n",
        "        result = 1 - distance.cosine(hiddens0[k], hiddens1[0])\n",
        "        results.append(result)\n",
        "        if k == 1:\n",
        "            similar.append(result)\n",
        "        elif k==0:\n",
        "            dissimilar.append(result)\n",
        "\n",
        "    max_value = max(results)\n",
        "    max_index = results.index(max_value)\n",
        "    sim_index[max_index] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "8f146857-caf9-4e30-924a-90d9a5c363bb",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "56c78bbf-94b6-402c-9135-6cebea7bdfbe",
        "executionStartTime": 1630609666136,
        "executionStopTime": 1630609666354
      },
      "source": [
        "torch.save(final_hiddens,'seq2_33/final_hiddens.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "84fad9a7-452b-41b4-8338-4be93c2f4895",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "11669866-d8c9-49a6-907e-a698a071300c",
        "executionStartTime": 1630609630051,
        "executionStopTime": 1630609635787
      },
      "source": [
        "''' Report h3 and h3' '''\n",
        "from scipy.spatial import distance\n",
        "\n",
        "final_hiddens = []\n",
        "\n",
        "#comparing h2 of generative model with h1 of first in seq model\n",
        "hidden_states0 = []\n",
        "hidden_states1 = []\n",
        "y_axis = []\n",
        "\n",
        "ncorrect = 0\n",
        "sim_index = [0,0,0]\n",
        "n = 2\n",
        "\n",
        "similar = []\n",
        "dissimilar0 = []\n",
        "dissimilar1 = []\n",
        "\n",
        "for i in range(0,len(x)):\n",
        "    if len(x[i]) < 3:\n",
        "        continue\n",
        "    if y[i][n-1] == y[i][n]:\n",
        "        continue #removing the same APIs to reduce noise\n",
        "    test_set_x = process_dataX(x[i])\n",
        "    test_set_y = process_dataY(y[i])\n",
        "    ds = FinalEmbedding(test_set_x,test_set_y)\n",
        "    X = ds[0]['predictors'].to(device)\n",
        "    Y = ds[0]['targets'].to(device)\n",
        "    model_output0, top_index0 = query_model(X,Y)\n",
        "\n",
        "    if top_index0[n] != Y[n]:\n",
        "        continue\n",
        "    else:\n",
        "        ncorrect += 1\n",
        "    \n",
        "    test_set_x1 = process_dataX([x_alt[i][n]])\n",
        "    test_set_y1 = process_dataY([y[i][n]])\n",
        "\n",
        "    ds = FinalEmbedding(test_set_x1,test_set_y1)\n",
        "    X1 = ds[0]['predictors'].to(device)\n",
        "    Y1 = ds[0]['targets'].to(device)\n",
        "    model_output1, top_index1 = query_model(X1,Y1)\n",
        "\n",
        "    if top_index1[0] != top_index0[2]:\n",
        "        continue\n",
        "\n",
        "    hiddens0 = model_output0[0].cpu()#.tolist()\n",
        "    hiddens1 = model_output1[0].cpu()#.tolist()\n",
        "\n",
        "    hiddens0 = hiddens0[0]\n",
        "    hiddens1 = hiddens1[0]\n",
        "\n",
        "    hidden_states0.append(hiddens0[n])\n",
        "    hidden_states1.append(hiddens1[0])\n",
        "    y_axis.append(Y1[0].item())\n",
        "\n",
        "    final_hiddens.append((hiddens0[0], hiddens0[1], hiddens0[2], hiddens1[0], Y1[0].item()))\n",
        "\n",
        "    results = []\n",
        "    for k in [0,1,2]:\n",
        "        result = 1 - distance.cosine(hiddens0[k], hiddens1[0])\n",
        "        results.append(result)\n",
        "        if k == n:\n",
        "            similar.append(result)\n",
        "        elif k==0:\n",
        "            dissimilar0.append(result)\n",
        "        elif k==1:\n",
        "            dissimilar1.append(result)\n",
        "\n",
        "    max_value = max(results)\n",
        "    max_index = results.index(max_value)\n",
        "\n",
        "    sim_index[max_index] += 1\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "0323a8e2-370b-4df2-8b57-faa49ae522fb",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "093f3664-46f3-4814-be3b-dd8dc2b3271e",
        "executionStartTime": 1630642278475,
        "executionStopTime": 1630642278799,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "scipy.stats.ttest_rel(dissimilar,similar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "46921cf0-e955-40b6-bc32-072a8c98a637",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2cfcb7e8-e7ee-4bf5-9e9a-8a9e9e388f7b",
        "executionStartTime": 1630605474403,
        "executionStopTime": 1630605474590
      },
      "source": [
        "np.median(dissimilar0),  np.median(dissimilar1), np.median(similar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1f0be69c-b9e8-4991-9692-2bc8c89933f6",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "a9a7f05c-5f84-4599-8520-910358e6ce74",
        "executionStartTime": 1629949917597,
        "executionStopTime": 1629949917871
      },
      "source": [
        "def pad_or_truncate(some_list, target_len):\n",
        "    return some_list[:target_len] + [0]*(target_len - len(some_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "81787cc7-75f9-45f9-9c1a-d2bfeb555a5d",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "c179963f-d6c8-4386-9070-21370e94abba",
        "executionStartTime": 1629944105272,
        "executionStopTime": 1629944720696,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "similar = []\n",
        "dissimilar = []\n",
        "\n",
        "for i in range(0,len(hidden_states0)):\n",
        "    for j in range(0,len(hidden_states1)):\n",
        "        result = 1 - spatial.distance.cosine(hidden_states0[i], hidden_states1[j])\n",
        "        print(i, j, result)\n",
        "        if i == j:\n",
        "            similar.append(result)\n",
        "        else:\n",
        "            dissimilar.append(result)\n",
        "        #results[i][j] = result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "5aa9acad-4798-4ba7-a295-aed3ec7987aa",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "2c8e42d8-e16b-422d-be7a-7cb410e8ff7d",
        "executionStartTime": 1629947888197,
        "executionStopTime": 1629947888452,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "from scipy.stats import ttest_ind\n",
        "import scipy.stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9a66a307-bc8d-4a13-943d-3078d938308b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "16aa9b0f-e112-41d7-a54c-5013e0d24148",
        "executionStartTime": 1630642763348,
        "executionStopTime": 1630642763737
      },
      "source": [
        "t = scipy.stats.ttest_ind(similar, dissimilar)\n",
        "t"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
