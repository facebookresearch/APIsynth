{
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "bento_kernel_pytorch",
      "metadata": {
        "kernel_name": "bento_kernel_pytorch",
        "nightly_builds": true,
        "fbpkg_supported": true,
        "is_prebuilt": true
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "last_server_session_id": "42787c29-39d7-4192-9f16-6a2180689457",
    "last_kernel_id": "92ff3845-6236-4f6c-9ba1-e7f8a39ac7f2",
    "last_base_url": "https://devvm3630.vll0.facebook.com:8090/",
    "last_msg_id": "b405a228-b6965e703e7aa072a976e3f4_1000",
    "captumWidgetMessage": {},
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "originalKey": "9bda37a1-2768-411a-9517-ffc6ad3ae5a7",
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "9bda37a1-2768-411a-9517-ffc6ad3ae5a7",
        "executionStartTime": 1632947911958,
        "executionStopTime": 1632947911997
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import torch as T\n",
        "from torch import nn\n",
        "# device = T.device(\"cuda\") \n",
        "device = T.device(\"cpu\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7249bf83-2543-4a9f-9ba4-aede429932a5",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7249bf83-2543-4a9f-9ba4-aede429932a5",
        "executionStartTime": 1632947912577,
        "executionStopTime": 1632947912622
      },
      "source": [
        "is16 = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "07dd2448-4aca-4f04-97d0-48e78435e5d8",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "07dd2448-4aca-4f04-97d0-48e78435e5d8",
        "executionStartTime": 1632947913358,
        "executionStopTime": 1632947913370
      },
      "source": [
        "class FinalEmbedding:\n",
        "    def __init__(self,x,y):\n",
        "        self.x_data = x\n",
        "        self.y_data = y\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        preds = self.x_data[idx]\n",
        "        trgts = self.y_data[idx] \n",
        "        sample = { \n",
        "        'predictors' : preds,\n",
        "        'targets' : trgts\n",
        "        }\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b0e9c47a-e7d9-437d-869c-5e5bdfd0a43f",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "b0e9c47a-e7d9-437d-869c-5e5bdfd0a43f",
        "executionStartTime": 1632947913890,
        "executionStopTime": 1632947913997
      },
      "source": [
        "from iopath.common.file_io import PathManager\n",
        "from iopath.fb.manifold import ManifoldPathHandler\n",
        "\n",
        "def load_checkpoint(checkpoint_path, map_location=None):\n",
        "    pm = PathManager()\n",
        "    pm.register_handler(ManifoldPathHandler())\n",
        "    with pm.open(checkpoint_path, \"rb\") as f:\n",
        "        if map_location is not None:\n",
        "            checkpoint = torch.load(f, map_location=map_location)\n",
        "        else:\n",
        "            checkpoint = torch.load(f, map_location=lambda storage, loc: storage)\n",
        "    return checkpoint\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "006aa7b4-1a32-492c-9d5c-a41d14755783",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "006aa7b4-1a32-492c-9d5c-a41d14755783",
        "executionStartTime": 1632947915284,
        "executionStopTime": 1632947915501
      },
      "source": [
        "api2indx = torch.load('gen1_33/api2indx.pt')\n",
        "api2indx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ff4d8db9-86b1-4a78-aee5-9c9ccc6fbbc5",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "ff4d8db9-86b1-4a78-aee5-9c9ccc6fbbc5",
        "executionStartTime": 1632947916922,
        "executionStopTime": 1632947916953,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class pycoder_parameters:\n",
        "\n",
        "    Path = 'gen1_33'\n",
        "\n",
        "    ''' Core Fuzzing Parameters '''\n",
        "    NUM_FUZZ_PER_API= 100001 #000\n",
        "    NUM_TEST_FUZZ = 2\n",
        "    FLOAT_TENSOR = False #We either generate float or integer tensors\n",
        "    UNIT_TEST = False\n",
        "    COMPOSITE = True\n",
        "\n",
        "    ''' Fuzzing Detailed Parameters '''\n",
        "    MAX_TENSOR_DIMENSIONS = 3 #how many rows, columns, etc.\n",
        "    MIN_VAL_PER_DIMENSION = 1 # e.g., min number of rows, columns, etc. \n",
        "    MAX_VAL_PER_DIMENSION = 5 # e.g., max number of rows, columns, etc. \n",
        "\n",
        "    #So far limiting to integers\n",
        "    MIN_TENSOR_VALUE = 1\n",
        "    MAX_TENSOR_VALUE = 15\n",
        "    \n",
        "\n",
        "    ''' Embedding Parameters '''\n",
        "    EMBEDDING_NOISE_LEVEL = 0 #0 noise by default\n",
        "    EMBEDDING_SIZE = 150\n",
        "    SHAPE_EMBEDDING_SIZE = 6\n",
        "\n",
        "\n",
        "    data_type = 'float' if FLOAT_TENSOR is  True else 'integer'\n",
        "    model_type = 'Composite_' if COMPOSITE is  True else 'Single_'\n",
        "    file_name = str(model_type) + str(NUM_FUZZ_PER_API) + '_' + data_type\n",
        "    fuzzing   = file_name + '.pt'\n",
        "    embedding = file_name + '.embedding' + '.pt',\n",
        "    classification = file_name + '.model_result' + '.pt' \n",
        "    train_valid_test = file_name + 'train_valid_test.pt'\n",
        "\n",
        "    def setNoiseLevel(self, noise):\n",
        "        self.EMBEDDING_NOISE_LEVEL = noise\n",
        "        self.embedding = self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt'\n",
        "\n",
        "    def getEmbeddingFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt')\n",
        "\n",
        "    def getVisulizationFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '_' +  'tSNE.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f6dbd35b-5132-4ec0-8752-0a1faae0b8a2",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "f6dbd35b-5132-4ec0-8752-0a1faae0b8a2",
        "executionStartTime": 1632947924745,
        "executionStopTime": 1632947924880,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "NOISE = 0\n",
        "f = pycoder_parameters()\n",
        "f.setNoiseLevel(NOISE)\n",
        "f.embedding = f.getEmbeddingFile() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "41ba3620-e262-4629-bc8c-ccdc9f0a8f3b",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "41ba3620-e262-4629-bc8c-ccdc9f0a8f3b",
        "executionStartTime": 1632947925511,
        "executionStopTime": 1632947925641,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "EMBEDDING_SIZE = f.EMBEDDING_SIZE\n",
        "SHAPE_EMBEDDING_SIZE = f.SHAPE_EMBEDDING_SIZE\n",
        "\n",
        "def encode_values_to_code(tensor):\n",
        "    tensor = tensor.clone()\n",
        "    tensor[(tensor>=100) & (tensor<1000)] = 100\n",
        "    tensor[(tensor>=1000)] = 101\n",
        "    tensor[(tensor<=-20) & (tensor>-100)] = -20\n",
        "    tensor[(tensor<=-100) & (tensor>-1000)] = -21\n",
        "    tensor[(tensor<=-1000)] = -22\n",
        "    return tensor\n",
        "\n",
        "def tensor_flatten_pad(tensor, embed_size=EMBEDDING_SIZE, shape_embed_size=SHAPE_EMBEDDING_SIZE, isNoise=False):\n",
        "    \n",
        "    t_flatten = torch.flatten(tensor)\n",
        "\n",
        "    padding_length = embed_size - list(t_flatten.shape)[-1]\n",
        "    p1d = (0,padding_length) #just padding the last dimension\n",
        "    t_pad = F.pad(input=t_flatten, pad=p1d, mode='constant', value=0).type(torch.FloatTensor)\n",
        "    \n",
        "    type_padding = 0\n",
        "    if tensor.dtype == torch.bool:\n",
        "        type_padding = 1\n",
        "    elif tensor.dtype == torch.float64 \\\n",
        "        or tensor.dtype == torch.double \\\n",
        "        or tensor.dtype == torch.float32 \\\n",
        "        or tensor.dtype == torch.float16:\n",
        "            type_padding = 2\n",
        "\n",
        "    \n",
        "    \n",
        "    '''size embedding'''\n",
        "    if(shape_embed_size > 0):\n",
        "        t_shape = list(tensor.shape)\n",
        "        padding_length = shape_embed_size -1 - len(t_shape)\n",
        "        p1d = (0,padding_length) #just padding the last dimension\n",
        "        s_pad = F.pad(input=torch.Tensor(t_shape), pad=p1d, mode='constant', value=0).type(torch.float)\n",
        "\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        s_pad_list = s_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1] + s_pad_list + [-1])\n",
        "    \n",
        "    else:\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1])\n",
        "        \n",
        "    encoded_tensor = encode_values_to_code(tensor_embedding)\n",
        "    return(encoded_tensor)\n",
        "\n",
        "'unit test'\n",
        "t1 = torch.tensor([[[1,2,3]],[[4,555,6]]])\n",
        "tf = tensor_flatten_pad(t1, shape_embed_size=5, isNoise=True)\n",
        "print(tf, tf.shape)\n",
        "\n",
        "t2 = torch.tensor([[[True,False,True]],[[True,True,False]]])\n",
        "tf1 = tensor_flatten_pad(t2, shape_embed_size=0)\n",
        "print(tf1, tf1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "0c669305-d8d1-4750-b3bb-6cd3b0b249b6",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "0c669305-d8d1-4750-b3bb-6cd3b0b249b6",
        "executionStartTime": 1632947927105,
        "executionStopTime": 1632947927128,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def embed_tensors(data_list):\n",
        "       \n",
        "    global EMBEDDING_SIZE\n",
        "    global api2indx\n",
        "    \n",
        "    X=[]\n",
        "    y=[]\n",
        "\n",
        "    all_input_output_tensors = set()\n",
        "    duplicate_count = 0\n",
        "\n",
        "    dict_indx = len(api2indx)\n",
        "\n",
        "    final_output = data_list[-1][1]\n",
        "\n",
        "    prev_out = torch.Tensor()\n",
        "    \n",
        "    api_seq_x = []\n",
        "    api_seq_y = []\n",
        "\n",
        "    for data in data_list:\n",
        "        api = data[0]      \n",
        "        api_indx = api2indx[api]\n",
        "        \n",
        "        input_list = data[2] #.get_input()\n",
        "        output_tensor = final_output #data.get_output()\n",
        "        \n",
        "        it_pad = []\n",
        "\n",
        "        for input_tensor in input_list:\n",
        "            if input_tensor.shape == prev_out.shape and torch.all(input_tensor.eq(prev_out)).item():\n",
        "                t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                t[-1] = -1\n",
        "                it_pad.append(t)\n",
        "            else:         \n",
        "                #flatten the input tensor\n",
        "                it_pad.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "            \n",
        "        \n",
        "        #adding addidional tensors with zero embeddings for < 2 tensors\n",
        "        for i in range(len(it_pad),3):\n",
        "            t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "            t[-1] = -1\n",
        "            it_pad.append(t)\n",
        "       \n",
        "        ot_pad = tensor_flatten_pad(output_tensor, isNoise=True)\n",
        "\n",
        "        x = T.flatten(T.stack((it_pad[0],it_pad[1], it_pad[2], ot_pad)))\n",
        "\n",
        "\n",
        "        xl = (x,api_indx)\n",
        "        \n",
        "        if xl in all_input_output_tensors:\n",
        "            duplicate_count += 1\n",
        "        else:\n",
        "            all_input_output_tensors.add(xl)\n",
        "\n",
        "    \n",
        "        api_seq_x.append(x) \n",
        "        api_seq_y.append(api_indx)\n",
        "\n",
        "        prev_out = data[1]\n",
        "\n",
        "    X.append(api_seq_x)\n",
        "    y.append(api_seq_y)\n",
        "    \n",
        "    return(X,y)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "93878a6f-b4d6-4c35-a053-78278661ad9f",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "93878a6f-b4d6-4c35-a053-78278661ad9f",
        "executionStartTime": 1632947928184,
        "executionStopTime": 1632947928277,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def process_dataX(tensor_list):\n",
        "    io_seq = []\n",
        "    \n",
        "    n0 = tensor_list[0]\n",
        "\n",
        "    if(len(tensor_list) == 1):\n",
        "        n1 = torch.zeros(n0.shape)\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "        \n",
        "    elif(len(tensor_list) == 2):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "\n",
        "    elif(len(tensor_list) == 3):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = tensor_list[2]\n",
        "\n",
        "        \n",
        "    new_list = torch.stack((n0, n1, n2))\n",
        "    io_seq.append(new_list)\n",
        "    \n",
        "    return(torch.stack(io_seq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "5385d444-1be0-4423-bfc2-c1f19acdb8a9",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "5385d444-1be0-4423-bfc2-c1f19acdb8a9",
        "executionStartTime": 1632947929259,
        "executionStopTime": 1632947929359,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "indx2api = {}\n",
        "EOS = '<eol>'\n",
        "\n",
        "def process_dataY(api_seq):\n",
        "    global indx2api\n",
        "    global api2indx\n",
        "\n",
        "    ''' Add <eol> to the dictionary '''\n",
        "    indx2api = {v: k for k, v in api2indx.items()}\n",
        "\n",
        "    if api2indx.get(EOS, -1) == -1:\n",
        "        max_key = max(indx2api.keys())\n",
        "        print(max_key)\n",
        "        indx2api[max_key+1] = EOS\n",
        "        api2indx[EOS] = max_key+1\n",
        "\n",
        "    eos = api2indx[EOS]\n",
        "\n",
        "    api_tensors = []\n",
        "\n",
        "\n",
        "    api0 = api_seq[0]\n",
        "\n",
        "    if len(api_seq) == 1:\n",
        "        api1 = eos\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 2:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 3:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = api_seq[2]\n",
        "\n",
        "    else:\n",
        "        print('!!! Not supposed to be here')\n",
        "\n",
        "    t = torch.tensor([api0, api1, api2])\n",
        "    api_tensors.append(t)\n",
        "    \n",
        "    return(torch.stack(api_tensors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "5ead262e-f1e7-4440-9d2f-bb9ce5e71169",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "5ead262e-f1e7-4440-9d2f-bb9ce5e71169",
        "executionStartTime": 1632947930413,
        "executionStopTime": 1632947930434,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, bidirectional=True)   \n",
        "        \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        #Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out1 = out.contiguous().view(-1, self.hidden_dim*2)\n",
        "        out1 = self.fc(out1)\n",
        "        \n",
        "        return out1, hidden, out\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        hidden = torch.zeros(self.n_layers*2, batch_size, self.hidden_dim).to(device)\n",
        "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ced6d4b5-021c-4c3c-812d-d3269b011ad0",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "ced6d4b5-021c-4c3c-812d-d3269b011ad0",
        "executionStartTime": 1632947930874,
        "executionStopTime": 1632947930893
      },
      "source": [
        "class FFNet(T.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FFNet, self).__init__()\n",
        "\n",
        "    self.hid1 = T.nn.Linear(4*(f.EMBEDDING_SIZE+f.SHAPE_EMBEDDING_SIZE+1+2), 500)\n",
        "    self.hid2 = T.nn.Linear(500, 250)\n",
        "    self.hid3 = T.nn.Linear(250, 100)\n",
        "    self.oupt = T.nn.Linear(100, len(api2indx))\n",
        "\n",
        "    T.nn.init.xavier_uniform_(self.hid1.weight)\n",
        "    T.nn.init.zeros_(self.hid1.bias)\n",
        "    T.nn.init.xavier_uniform_(self.hid2.weight)\n",
        "    T.nn.init.zeros_(self.hid2.bias)\n",
        "    T.nn.init.xavier_uniform_(self.oupt.weight)\n",
        "    T.nn.init.zeros_(self.oupt.bias)\n",
        "\n",
        "    T.nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    z1 = T.tanh(self.hid1(x))\n",
        "    z2 = T.tanh(self.hid2(z1))\n",
        "    z3 = T.tanh(self.hid3(z2))\n",
        "    z = self.oupt(z3)  # no softmax: CrossEntropyLoss() \n",
        "    return (z, z3, z2, z1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a73fd2f8-983f-4d78-ad68-7d24a97e2ed3",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a73fd2f8-983f-4d78-ad68-7d24a97e2ed3",
        "executionStartTime": 1632947932046,
        "executionStopTime": 1632947932136
      },
      "source": [
        "DEBUG = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "8f50704b-7584-4670-b07f-a4c3de28b5da",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8f50704b-7584-4670-b07f-a4c3de28b5da",
        "executionStartTime": 1632947932999,
        "executionStopTime": 1632947933011
      },
      "source": [
        "def embed_tensor_for_model(domain_io):\n",
        "\n",
        "    x, y = embed_tensors(domain_io)\n",
        "\n",
        "    X = process_dataX(x[0])\n",
        "    Y = process_dataY(y[0])\n",
        "    ds = FinalEmbedding(X,Y)\n",
        "\n",
        "    X = ds[0]['predictors'].to(device)\n",
        "    Y = ds[0]['targets'].to(device)  # [0] [1] or [2]\n",
        "\n",
        "    return(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c41e3a41-d42d-4858-b56d-a2552c9a344f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c41e3a41-d42d-4858-b56d-a2552c9a344f",
        "executionStartTime": 1632947933549,
        "executionStopTime": 1632947933667
      },
      "source": [
        "def beam_search(top3_list):\n",
        "\n",
        "    api_seq = []\n",
        "    api_seq1 = []\n",
        "    for i in top3_list[0]:\n",
        "        for j in top3_list[1]:\n",
        "            api_seq1.append(((i[0], j[0]), i[1]*j[1]))\n",
        "    \n",
        "    api_seq1.sort(key = lambda x: x[1], reverse=True) \n",
        "\n",
        "    for k in top3_list[2]:\n",
        "        for s1 in api_seq1:\n",
        "            api_seq.append(((s1[0][0], s1[0][1], k[0]), s1[1]*k[1]))\n",
        "\n",
        "    api_seq.sort(key = lambda x: x[1], reverse=True) \n",
        "    \n",
        "    return(api_seq)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "cfd7dd0c-a76f-4072-943d-1660d2ad4503",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "cfd7dd0c-a76f-4072-943d-1660d2ad4503",
        "executionStartTime": 1632947934703,
        "executionStopTime": 1632947934741
      },
      "source": [
        "total_correct = {}\n",
        "seq_len_correct = {}\n",
        "seq_len_total = {}\n",
        "total_benchmark = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "2fbabe21-ed3d-41b8-8806-b6f4ac39dfde",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "2fbabe21-ed3d-41b8-8806-b6f4ac39dfde",
        "executionStartTime": 1632947935418,
        "executionStopTime": 1632947935499
      },
      "source": [
        "def reset_stat():\n",
        "    global total_correct\n",
        "    global seq_len_correct\n",
        "    global seq_len_total\n",
        "    global total_benchmark\n",
        "    \n",
        "    total_correct = {}\n",
        "    seq_len_correct = {}\n",
        "    seq_len_total = {}\n",
        "    total_benchmark = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6130721f-7f07-4820-8670-7aa29c90ccc0",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "6130721f-7f07-4820-8670-7aa29c90ccc0",
        "executionStartTime": 1632947935970,
        "executionStopTime": 1632947935986
      },
      "source": [
        "def print_stat():\n",
        "    print('total_correct', total_correct)\n",
        "    print('seq_len_correct', seq_len_correct)\n",
        "    print('seq_len_total', seq_len_total)\n",
        "    print('total_benchmark', total_benchmark)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7b348d83-b099-493f-999d-4f85b9313fb1",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "7b348d83-b099-493f-999d-4f85b9313fb1",
        "executionStartTime": 1632947947334,
        "executionStopTime": 1632947947432
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b67524f4-ef1d-461c-961b-447eeaebdf51",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "b67524f4-ef1d-461c-961b-447eeaebdf51",
        "executionStartTime": 1632947951080,
        "executionStopTime": 1632947951090,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def query_model(X, Y):\n",
        "\n",
        "    global total_benchmark\n",
        "    with T.no_grad():\n",
        "        start_time = time.time()\n",
        "        predicts, z3, z2, z1 = net(X)\n",
        "        temp_z3 = torch.unsqueeze(z3, 0)\n",
        "        model_output, hidden, int_output = rnn_model(temp_z3)\n",
        "\n",
        "        target_list = list(Y.cpu().numpy())\n",
        "\n",
        "    top_indx = []\n",
        "\n",
        "    top3_list = []\n",
        "\n",
        "    print(\"---- Top-k ----\")\n",
        "    for i, m in enumerate(model_output):\n",
        "        top3 = []\n",
        "        prob = nn.functional.softmax(m, dim=0).data\n",
        "        # Taking the class with the highest probability score from the output\n",
        "        xx = torch.topk(prob, 3, dim=0)[1]\n",
        "        for x in xx.cpu().numpy():\n",
        "            print(indx2api[x])\n",
        "            top3.append((indx2api[x], prob[x].item()))\n",
        "        top3_list.append(top3)\n",
        "        print(\"====\")\n",
        "\n",
        "    print(\"---- Predicted ----\")\n",
        "    for m in model_output:\n",
        "        prob = nn.functional.softmax(m, dim=0).data\n",
        "        api_ind = torch.max(prob, dim=0)[1].item()\n",
        "        top_indx.append(api_ind)\n",
        "        if DEBUG:\n",
        "            print(indx2api[api_ind], prob[api_ind])\n",
        "\n",
        "    print(\"---- Expected ----\")\n",
        "    seq_len = 0\n",
        "    for o in list(Y):\n",
        "        # print(o.item())\n",
        "        if o.item() != len(api2indx) - 1:\n",
        "            seq_len += 1\n",
        "        print(indx2api[o.item()])\n",
        "    # print(\"seq length\", seq_len)\n",
        "    if seq_len_correct.get(seq_len, -1) == -1:\n",
        "        seq_len_correct[seq_len] = 0\n",
        "        seq_len_total[seq_len] = 0\n",
        "\n",
        "    seq_len_total[seq_len] += 1\n",
        "    total_benchmark += 1\n",
        "\n",
        "    o = list(Y)\n",
        "    expected = (indx2api[o[0].item()], indx2api[o[1].item()], indx2api[o[2].item()])\n",
        "\n",
        "    top3_list = beam_search(top3_list)\n",
        "    for i, t in enumerate(top3_list):\n",
        "        if t[0][0] == expected[0]:\n",
        "            print(i + 1, t[0], \"\\t***MATCH\")\n",
        "            if total_correct.get(i + 1, -1) == -1:\n",
        "                total_correct[i + 1] = 0\n",
        "            total_correct[i + 1] += 1\n",
        "            seq_len_correct[seq_len] += 1\n",
        "            break\n",
        "        else:\n",
        "            print(t[0])\n",
        "    return top3_list\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "60bc289c-9db2-4150-9e45-58b8c9032d2a",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "60bc289c-9db2-4150-9e45-58b8c9032d2a",
        "executionStartTime": 1632947951467,
        "executionStopTime": 1632947951503,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def api_edit_distance(seq1, seq2):\n",
        "\n",
        "    edit_distantce = 0\n",
        "\n",
        "    for i in range(len(seq1)):\n",
        "        if seq1[i] != seq2[i]:\n",
        "            edit_distantce += 1\n",
        "\n",
        "    return(edit_distantce)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "abaaf2b4-dd6d-40ef-8dd4-a2e844eb14f1",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "abaaf2b4-dd6d-40ef-8dd4-a2e844eb14f1",
        "executionStartTime": 1632947953178,
        "executionStopTime": 1632947953222
      },
      "source": [
        "max_epochs = 20\n",
        "net = torch.load(f.Path + '/' + str(max_epochs) + '_train_net_model.pt')\n",
        "rnn_model = torch.load(f.Path + '/' + str(max_epochs) + '_train_rnn_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3a648c43-98b4-462f-9b62-0cb88a143c48",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "3a648c43-98b4-462f-9b62-0cb88a143c48",
        "executionStartTime": 1632947954021,
        "executionStopTime": 1632947954054
      },
      "source": [
        "reset_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "46c690c3-7200-43ff-94a4-f08008b7f6e3",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "46c690c3-7200-43ff-94a4-f08008b7f6e3",
        "executionStartTime": 1632947954819,
        "executionStopTime": 1632947955006
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "42e8796e-643e-4b53-a7d0-089cdfa0b362",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "42e8796e-643e-4b53-a7d0-089cdfa0b362",
        "executionStartTime": 1632947956473,
        "executionStopTime": 1632947956496
      },
      "source": [
        "def Composite01():\n",
        "    in1 = torch.tensor([[5, 2], [1, 3], [0, 2]])\n",
        "    out_orig = torch.tensor([[[5, 5], [1, 1], [0, 0]], [[2, 2], [3, 3], [2, 2]]])\n",
        "    out = torch.transpose(in1.expand((2, 3, 2)), 0, 2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(in1, out))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append([\"expand\", torch.transpose(in1.expand((2, 3, 2)), 0, 2), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    print(\"-------------------------------------\")\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(\n",
        "        [\n",
        "            \"transpose\",\n",
        "            torch.transpose(in1.expand((2, 3, 2)), 0, 2),\n",
        "            [in1.expand((2, 3, 2))],\n",
        "        ]\n",
        "    )\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite01()\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "03b44f94-f948-4d74-bdd6-5983bee7002d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "03b44f94-f948-4d74-bdd6-5983bee7002d",
        "executionStartTime": 1632947960597,
        "executionStopTime": 1632947960838
      },
      "source": [
        "def Composite02():\n",
        "    domain_inpt10 = torch.tensor([5, 1, 0, 3, 0, 0, 2, 0, 2])\n",
        "    domain_out10 = torch.lt(domain_inpt10, 1)\n",
        "    \n",
        "    domain_inpt20 = domain_out10\n",
        "    domain_inpt21 = domain_inpt10\n",
        "\n",
        "    domain_output_orig = torch.tensor([1, 1, 0, 1, 0, 0, 1, 0, 1])\n",
        "    domain_output = torch.where(domain_inpt20, domain_inpt21, 1)\n",
        "\n",
        "    print('domain_inpt10 : ', domain_inpt10, domain_inpt10.shape)\n",
        "    print('domain_inpt20 : ', domain_inpt20, domain_inpt20.shape)\n",
        "    print('domain_output : ', domain_output, domain_output.shape)\n",
        "    print(torch.equal(domain_output, domain_output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['lt', domain_output, [domain_inpt10, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['where', domain_output, [domain_inpt20, domain_inpt21, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite02()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "36907cff-0556-4b87-a6a4-c8f3d0e2dfe6",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "36907cff-0556-4b87-a6a4-c8f3d0e2dfe6",
        "executionStartTime": 1632947965273,
        "executionStopTime": 1632947965295
      },
      "source": [
        "def Composite05():\n",
        "    in1 = torch.tensor([[4, 3, 1], [6, 5, 2]])\n",
        "    in2 = torch.tensor([[[5, 5]], [[1, 5]], [[6, 0]]])\n",
        "    output_orig = torch.tensor([[[29, 35]], [[47, 55]]])\n",
        "    output = torch.tensordot(in1, in2, 1)\n",
        "    \n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output_orig, output))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', output, [in1, in2]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite05()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1f546196-ec68-405e-8de2-6abf827d1b0c",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "1f546196-ec68-405e-8de2-6abf827d1b0c",
        "executionStartTime": 1632947968357,
        "executionStopTime": 1632947968391
      },
      "source": [
        "def Composite06():\n",
        "    in1 = torch.tensor([3, 5, 0, 2, 3, 3, 0])\n",
        "    in2 = torch.unsqueeze(in1, 1)\n",
        "    output_orig = torch.tensor([\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
        "                [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
        "            ]).int()\n",
        "    output = torch.eq(in1, in2).int()\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['unsqueeze',  torch.eq(in1, in2), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['eq', torch.eq(in1, in2), [in1, torch.unsqueeze(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite06()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7ed363f1-34ce-4809-a012-8e12231784c5",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7ed363f1-34ce-4809-a012-8e12231784c5",
        "executionStartTime": 1632947976691,
        "executionStopTime": 1632947976706
      },
      "source": [
        "def Composite07():\n",
        "    in1 = torch.tensor([\n",
        "                    [[8, 4, 6], [2, 12, 3]],\n",
        "                    [[11, 12, 5], [9, 12, 12]],\n",
        "                    [[9, 2, 13], [7, 0, 7]],\n",
        "                    [[2, 10, 5], [7, 1, 2]],\n",
        "                ])\n",
        "    output_orig = torch.tensor([\n",
        "                [[8, 4, 6], [11, 12, 5], [9, 2, 13], [2, 10, 5]],\n",
        "                [[2, 12, 3], [9, 12, 12], [7, 0, 7], [7, 1, 2]],\n",
        "            ])\n",
        "    output = torch.transpose(in1, 0, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', output, [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite07()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c4725df8-56bc-4e0d-a4ff-89645a065d27",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c4725df8-56bc-4e0d-a4ff-89645a065d27",
        "executionStartTime": 1632947976736,
        "executionStopTime": 1632947976814
      },
      "source": [
        "def Composite08():\n",
        "    in1 = torch.tensor([1, 0, 0, 2, 1, 3, 5, 0, 1, 2, 10])\n",
        "    in2 = torch.tensor([12, 3, 45, 6, 7, 8, 9, 87, 65, 4, 32])\n",
        "    in3 = torch.gt(in1, 1)\n",
        "    output_orig = torch.tensor([6, 8, 9, 4, 32])\n",
        "    output = torch.masked_select(in2, torch.gt(in1, 1))\n",
        "\n",
        "    print('in1: ', in1, in1.shape, in1.dtype)\n",
        "    print('in2: ', in2, in2.shape, in2.dtype)\n",
        "    print('in3: ', in2, in2.shape, in2.dtype)\n",
        "    print('output', output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []   \n",
        "    domain_io.append(['gt', torch.masked_select(in2, torch.gt(in1, 1)), [in1, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []   \n",
        "    domain_io.append(['masked_select', torch.masked_select(in2, torch.gt(in1, 1)), [in2, torch.gt(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite08()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c0970055-6e28-4d25-ac6b-99a4f28735c8",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c0970055-6e28-4d25-ac6b-99a4f28735c8",
        "executionStartTime": 1632947976824,
        "executionStopTime": 1632947976972
      },
      "source": [
        "def Composite11():\n",
        "    in1 = torch.tensor([4, 0, 1, 1, 0, 4, 0, 0, 3, 4, 1])\n",
        "    out_orig = torch.tensor([4, 3, 0, 1, 3])\n",
        "    out = torch.bincount(in1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['bincount', torch.bincount(in1), [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite11()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "85bdf22a-d811-4baf-9abe-279c8fbf70ea",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "85bdf22a-d811-4baf-9abe-279c8fbf70ea",
        "executionStartTime": 1632947977006,
        "executionStopTime": 1632947977132
      },
      "source": [
        "def Composite13():\n",
        "    in1 = torch.tensor([[3, 5], [10, 2]])\n",
        "    in2 = torch.tensor([[[1, 0], [5, 4]], [[3, 10], [2, 0]]])\n",
        "    in3 = torch.matmul(in1, in2)\n",
        "    out_orig = torch.tensor([[[28, 20], [19, 30]], [[20, 8], [34, 100]]])\n",
        "    out = torch.transpose(torch.matmul(in1, in2), 0, 1)\n",
        "\n",
        "    print('in1 : ', in1, in1.shape, in1.dtype)\n",
        "    print('in2 : ', in2, in2.shape, in2.dtype)\n",
        "    print('in3 : ', in3, in3.shape, in3.dtype)\n",
        "    print('output : ', out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['matmul', torch.transpose(torch.matmul(in1, in2), 0, 1), [in1, in2]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', torch.transpose(torch.matmul(in1, in2), 0, 1), [torch.matmul(in1, in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite13()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1fa485a0-7e5b-4449-a34f-b035c3342c2d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "1fa485a0-7e5b-4449-a34f-b035c3342c2d",
        "executionStartTime": 1632947977187,
        "executionStopTime": 1632947977226
      },
      "source": [
        "def Composite14():\n",
        "    in1 = torch.tensor([\n",
        "                    [\n",
        "                        [False, False, True],\n",
        "                        [False, False, False],\n",
        "                        [True, False, True],\n",
        "                        [False, True, False],\n",
        "                        [False, False, False],\n",
        "                        [True, True, True],\n",
        "                        [True, True, False],\n",
        "                    ]\n",
        "                ]).int()\n",
        "    out_orig = torch.tensor([[True, False, True, True, False, True, True]]).int()\n",
        "    out = torch.any(in1, -1).int()\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['any', torch.any(in1, -1), [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite14()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "fd37a63f-e5c9-4b25-b2a4-34343ad4fa05",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "fd37a63f-e5c9-4b25-b2a4-34343ad4fa05",
        "executionStartTime": 1632947977356,
        "executionStopTime": 1632947977415
      },
      "source": [
        "def Composite15():\n",
        "    in1 = torch.tensor([3, 1, 2, 0, 1, 0, 10, 1, 0])\n",
        "    out_orig = torch.tensor([3, 0, 2, 0, 0, 0, 10, 0, 0])\n",
        "    out = torch.mul(in1, torch.ne(in1, 1)) \n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['ne', torch.mul(in1, torch.ne(in1, 1)), [in1, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['mul', torch.mul(in1, torch.ne(in1, 1)), [in1, torch.ne(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite15()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7e395c1f-731d-4bdf-82d3-268a51825b8b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7e395c1f-731d-4bdf-82d3-268a51825b8b",
        "executionStartTime": 1632947977519,
        "executionStopTime": 1632947977602
      },
      "source": [
        "def Composite16():\n",
        "    in1 = torch.tensor([[2, 5], [3, 0], [8, 7]])\n",
        "    in2 = torch.tensor([4, 10, 6])\n",
        "    out_orig = torch.tensor([[8, 20], [30, 0], [48, 42]])\n",
        "    out = torch.mul(in1, torch.unsqueeze(in2, 1))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = [] \n",
        "    domain_io.append(['unsqueeze',torch.mul(in1, torch.unsqueeze(in2, 1)), [in2]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = [] \n",
        "    domain_io.append(['mul', torch.mul(in1, torch.unsqueeze(in2, 1)), [in1,torch.unsqueeze(in2, 1)]])    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "67c0af79-25a6-4717-9ccc-c570322e5e9d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "67c0af79-25a6-4717-9ccc-c570322e5e9d",
        "executionStartTime": 1632947977609,
        "executionStopTime": 1632947977733
      },
      "source": [
        "def Composite17():\n",
        "    in1 = torch.tensor([17, 32, 99])\n",
        "    out_orig = torch.tensor([[17, 17], [32, 32], [99, 99]])\n",
        "    out = torch.stack((in1, in1), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []    \n",
        "    domain_io.append(['stack', out, [in1, in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite17()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "876fe9c6-2a54-46d0-8346-3c9ca826c7b2",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "876fe9c6-2a54-46d0-8346-3c9ca826c7b2",
        "executionStartTime": 1632947977789,
        "executionStopTime": 1632947977857
      },
      "source": [
        "def Composite18():\n",
        "    in1 = torch.tensor([[[1, 1, 1], [1, 0, 1]], [[1, 2, 3], [4, 5, 6]]])\n",
        "    in2 = torch.tensor([[1, 1, 1, 1], [1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "    in3 = torch.tensor([100, 200, 300, 400])\n",
        "    in4 = torch.matmul(in1, in2)\n",
        "\n",
        "    out_orig = torch.tensor([\n",
        "                [[107, 209, 311, 413], [106, 207, 308, 409]],\n",
        "                [[118, 223, 328, 433], [139, 250, 361, 472]],\n",
        "            ])\n",
        "    out = torch.add(in3, torch.matmul(in1, in2))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(in3, in3.shape, in3.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['matmul', out, [in1, in2]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['add', out, [in3, torch.matmul(in1, in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite18()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1a4afe8b-ebcd-4ce9-a301-dcf7eb5a8a52",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "1a4afe8b-ebcd-4ce9-a301-dcf7eb5a8a52",
        "executionStartTime": 1632947977907,
        "executionStopTime": 1632947978018
      },
      "source": [
        "# NOT SUPPORTING by 16\n",
        "def Composite20():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([\n",
        "                    [7, 2, 1],\n",
        "                    [4, 5, 1],\n",
        "                    [4, 4, 2],\n",
        "                    [3, 4, 3],\n",
        "                    [0, 0, 1],\n",
        "                ])\n",
        "    out_orig = torch.tensor([[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "    out = torch.nn.functional.one_hot(torch.argmax(in1, 1), 3)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['argmax', torch.nn.functional.one_hot(torch.argmax(in1, 1),3), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(torch.argmax(in1, 1),3), [torch.argmax(in1, 1), torch.tensor(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite20()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7f0c62ac-611c-4775-bc59-2571970e69fa",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7f0c62ac-611c-4775-bc59-2571970e69fa",
        "executionStartTime": 1632947978028,
        "executionStopTime": 1632947978083
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite21():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[2], [0], [1], [0]])\n",
        "    in2 = torch.tensor([[2, 5, 3], [1, 3, 6], [1, 6, 3], [7, 0, 3]])\n",
        "    out_orig = torch.tensor([[3], [1], [6], [7]])\n",
        "    out = torch.gather(in2, 1, in1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['gather', out, [in2, in1]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite21()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a622bc26-47ed-40dd-aa12-d4d76b245fc3",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a622bc26-47ed-40dd-aa12-d4d76b245fc3",
        "executionStartTime": 1632947978150,
        "executionStopTime": 1632947978227
      },
      "source": [
        "def Composite22():\n",
        "    in1 = torch.tensor([3, 1, 10])\n",
        "    in2 = torch.tensor([[6, 4], [5, 1], [3, 4]])\n",
        "    out_orig = torch.tensor([53, 53])\n",
        "    out = torch.tensordot(in1, in2, 1 )\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite22()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7b4e3455-3aff-4799-83d7-410cf7e38905",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7b4e3455-3aff-4799-83d7-410cf7e38905",
        "executionStartTime": 1632947978240,
        "executionStopTime": 1632947978424
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite23():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[0, 5, 2], [3, 1, 4], [5, 1, 5]])\n",
        "    out_orig = torch.tensor([\n",
        "                [1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
        "                [0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
        "                [0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "            ])\n",
        "    out = torch.max(torch.nn.functional.one_hot(in1, 9), 1)[0]\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.sum(torch.nn.functional.one_hot(in1, 9), 1), [in1, torch.tensor(9)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.nn.functional.one_hot(in1, 9), 1), [torch.nn.functional.one_hot(in1, 9)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite23()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b77aee3d-7442-42fc-ad7c-1c82e796b125",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b77aee3d-7442-42fc-ad7c-1c82e796b125",
        "executionStartTime": 1632947978429,
        "executionStopTime": 1632947978603
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite24():\n",
        "  if is16 == True:\n",
        "        return\n",
        "  in1 = torch.tensor([3, 1, 4, 5, 2, 8, 6, 7])\n",
        "  in2 = 0\n",
        "  in3 = torch.tensor([1, 0, 2, 0, 1, 1, 0, 2])\n",
        "  out_orig = torch.tensor([3, 1, 2, 5, 2, 8, 6, 3.5])\n",
        "  out = torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float())\n",
        "\n",
        "  print(in1, in1.shape, in1.dtype)\n",
        "  print(in2)\n",
        "  print(in3, in3.shape, in3.dtype)\n",
        "  print(out, out.shape)\n",
        "  print(torch.equal(out, out_orig))\n",
        "\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['ne', torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float()), [in3, torch.tensor(in2)]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['div', torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float()), [in1, in3]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['where', torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float()), [torch.ne(in3, in2), torch.div(in1, in3), in1]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "Composite24()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6fb560ad-5337-4f6c-8606-4f623d02951c",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "6fb560ad-5337-4f6c-8606-4f623d02951c",
        "executionStartTime": 1632947978608,
        "executionStopTime": 1632947978663
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIS\n",
        "def Composite25():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    out_orig = torch.tensor([\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "            ]).int()\n",
        "    out = torch.tile(torch.eye(3), (4, 1)).int()\n",
        "\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['eye', torch.tile(torch.eye(3), (4, 1)), []])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tile', torch.tile(torch.eye(3), (4, 1)), [torch.eye(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite25()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "0b5b43a0-d870-40f5-ac4c-771355fdaf4c",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "0b5b43a0-d870-40f5-ac4c-771355fdaf4c",
        "executionStartTime": 1632947978742,
        "executionStopTime": 1632947978775
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite26():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[[3, 4], [1, 2]], [[5, 2], [10, 3]], [[10, 20], [4, 7]]])\n",
        "    out_orig = torch.tensor([10, 20, 41])\n",
        "    out = torch.sum(torch.sum(in1, 1), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.sum(in1, 1), 1), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.sum(in1, 1), 1), [torch.sum(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite26()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "69ff7612-359e-468d-86d4-12572e20c28f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "69ff7612-359e-468d-86d4-12572e20c28f",
        "executionStartTime": 1632947978839,
        "executionStopTime": 1632947978931
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite27():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([0, 3, 5, 6])\n",
        "    out_orig = torch.tensor([1, 0, 0, 1, 0, 1, 1, 0])\n",
        "    out = torch.sum(torch.nn.functional.one_hot(in1, 8), 0)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.sum(torch.nn.functional.one_hot(in1, 8), 0), [in1, torch.tensor(8)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.nn.functional.one_hot(in1, 8), 0), [torch.nn.functional.one_hot(in1, 8)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite27()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f63ee9cb-9860-49a9-8e35-32cc4ee27c0e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "f63ee9cb-9860-49a9-8e35-32cc4ee27c0e",
        "executionStartTime": 1632947978940,
        "executionStopTime": 1632947979035
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite29():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21])\n",
        "    in2 = torch.tensor([12, 0, 10, 23, 16])\n",
        "    out_orig = torch.tensor([6, 0, 5, 11, 8])\n",
        "    out = torch.searchsorted(in1, in2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['searchsorted', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite29()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "001682af-0839-497d-a72d-8ac12bed5b04",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "001682af-0839-497d-a72d-8ac12bed5b04",
        "executionStartTime": 1632947979080,
        "executionStopTime": 1632947979108
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "import math\n",
        "def Composite30():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "    in2 = torch.tensor([[9.0, 4.0], [8.0, 5.0], [7.0, 6.0]])\n",
        "    out_orig = torch.tensor([[math.sqrt(68), math.sqrt(58), math.sqrt(52)],\n",
        "                  [math.sqrt(36), math.sqrt(26), math.sqrt(20)],\n",
        "                  [math.sqrt(20), math.sqrt(10), math.sqrt(4)]])\n",
        "    out = torch.cdist(in1, in2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['cdist', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite30()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3d712d73-ebfb-4f8d-98d6-897c3af5c60d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "3d712d73-ebfb-4f8d-98d6-897c3af5c60d",
        "executionStartTime": 1632947979115,
        "executionStopTime": 1632947979259
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite32():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[1, 6, 2, 1], [3, 1, 4, 2], [2, 1, 2, 5]])\n",
        "    out_orig = torch.tensor([13, 15, 20])\n",
        "    out = torch.tensordot(in1, torch.arange(4), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.tensordot(in1, torch.arange(4), 1), []])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', torch.tensordot(in1, torch.arange(4), 1), [in1, torch.arange(4)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite32()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d9046ad9-d562-4de0-abb5-8306138204ee",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "d9046ad9-d562-4de0-abb5-8306138204ee",
        "executionStartTime": 1632947979339,
        "executionStopTime": 1632947979395
      },
      "source": [
        "def Composite34():\n",
        "    in1 = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[10, 20], [30, 40]]])\n",
        "    in2 = torch.tensor([3, 5, 10])\n",
        "    out_orig = torch.tensor([[128, 236], [344, 452]])\n",
        "    out = torch.tensordot(in2, in1, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite34()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "264364dc-2ba9-4b8e-ae96-a2028ae689c7",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "264364dc-2ba9-4b8e-ae96-a2028ae689c7",
        "executionStartTime": 1632947979400,
        "executionStopTime": 1632947979528
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite36():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([1, 0, 1, 1, 0, 1, 0, 1])\n",
        "    out_orig = torch.tensor([1.0, 0.0, 0.333333, 0.25, 0.0, 0.166667, 0.0, 0.125])\n",
        "    out = torch.div(in1, torch.add(in1, torch.arange(8)))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(out_orig, out_orig.shape, out_orig.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.arange(8), []])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "    print('--------------------------------------')\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['add', torch.div(in1, torch.add(in1, torch.arange(8))), [in1, torch.arange(8)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "    print('--------------------------------------')\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['div', torch.div(in1, torch.add(in1, torch.arange(8))), [in1, torch.add(in1, torch.arange(8))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite36()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ec6dfc48-7eb1-4d09-b58a-6d5b894ceec1",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ec6dfc48-7eb1-4d09-b58a-6d5b894ceec1",
        "executionStartTime": 1632947979582,
        "executionStopTime": 1632947979615
      },
      "source": [
        "def Composite37():\n",
        "    in1 = torch.tensor([\n",
        "                    [\n",
        "                        [[10, 20, 30], [40, 50, 60]],\n",
        "                        [[12, 34, 56], [78, 98, 76]],\n",
        "                    ]\n",
        "                ])\n",
        "    in2 = torch.tensor([5, 10, 20])\n",
        "    out_orig = torch.tensor([[[850, 1900], [1520, 2890]]])\n",
        "    out = torch.tensordot(in1, in2, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite37()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9234715e-0f36-46a7-9564-f2abbe52c551",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "9234715e-0f36-46a7-9564-f2abbe52c551",
        "executionStartTime": 1632947979675,
        "executionStopTime": 1632947979686
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite39():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[15, 10, 9, 20], [11, 0, 1, 9], [10, 1, 11, 25]])\n",
        "    out_orig = torch.tensor([\n",
        "                [225, 100, 81, 400],\n",
        "                [121, 0, 1, 81],\n",
        "                [100, 1, 121, 625],\n",
        "            ])\n",
        "    out = torch.square(torch.mul(in1, in1.bool()))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['mul', torch.square(torch.mul(in1, in1.bool().long())), [in1, in1.bool().long()]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['square', torch.square(torch.mul(in1, in1.bool().long())), [torch.mul(in1, in1.bool().long())]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite39()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "dcaac9b6-281e-40b8-9055-b164ad0c6dad",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "dcaac9b6-281e-40b8-9055-b164ad0c6dad",
        "executionStartTime": 1632947979767,
        "executionStopTime": 1632947979846
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "#torch.masked_select(in1, torch.ne(torch.arange(10), in2))\n",
        "def Composite41():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([5, 2, 8, 2, 4, 1, 1, 0, 2, 1])\n",
        "    in2 = 3\n",
        "    out_orig = torch.tensor([5, 2, 8, 4, 1, 1, 0, 2, 1])\n",
        "    out = torch.masked_select(in1, torch.ne(torch.arange(10), in2))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.masked_select(in1, torch.ne(torch.arange(10), in2)),[]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['ne', torch.masked_select(in1, torch.ne(torch.arange(10), in2)), [torch.arange(10), torch.tensor(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['masked_select',torch.masked_select(in1, torch.ne(torch.arange(10), in2)), [in1, torch.ne(torch.arange(10), in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite41()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4c70e639-b927-485b-8e3b-fae4e5984e51",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "4c70e639-b927-485b-8e3b-fae4e5984e51",
        "executionStartTime": 1632947979857,
        "executionStopTime": 1632947979986
      },
      "source": [
        "def Composite42():\n",
        "    in1 = torch.tensor([4, 6, 2, 6, 7, 3, 3])\n",
        "    out_orig = torch.tensor([0, 0, 0, 0, 1, 0, 0]).int()\n",
        "    out = torch.eq(in1, 7)\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['eq', torch.eq(in1, 7), [in1, torch.tensor(7)]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite42()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9f1953bb-46bb-4f58-8b22-ad54a97fd6d7",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "9f1953bb-46bb-4f58-8b22-ad54a97fd6d7",
        "executionStartTime": 1632947980045,
        "executionStopTime": 1632947980098
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite44():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([\n",
        "                    [3, 5, 2],\n",
        "                    [6, 2, 3],\n",
        "                    [8, 7, 1],\n",
        "                    [0, 3, 5],\n",
        "                    [4, 7, 3],\n",
        "                    [2, 1, 6],\n",
        "                    [10, 20, 30],\n",
        "                    [4, 5, 6],\n",
        "                ])                \n",
        "    out_orig = torch.tensor([[9, 7, 5], [8, 19, 6], [6, 8, 9], [14, 25, 36]])\n",
        "    out = torch.sum(torch.reshape(in1, (-1, 2, 3)), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['reshape', torch.sum(torch.reshape(in1, (-1, 2, 3)), 1), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    print('-----------------------')\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.reshape(in1, (-1, 2, 3)), 1), [torch.reshape(in1, (-1, 2, 2))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite44()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "22172834-8a68-42bc-9f00-23c10f637d4f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "22172834-8a68-42bc-9f00-23c10f637d4f",
        "executionStartTime": 1632947980107,
        "executionStopTime": 1632947980197
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite45():\n",
        "  if is16 == True:\n",
        "        return\n",
        "  in1 = torch.tensor([1, 0, 1, 0, 1])\n",
        "  in2 = torch.tensor([[[12, 34], [56, 78], [23, 54], [76, 78], [42, 24]]])\n",
        "  out_orig = torch.tensor([[[34, 12],\n",
        "         [56, 78],\n",
        "         [54, 23],\n",
        "         [76, 78],\n",
        "         [24, 42]]])\n",
        "  out = torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2)\n",
        "\n",
        "  print(in1, in1.shape)\n",
        "  print(in2, in2.shape)\n",
        "  print(out, out.shape)\n",
        "  print(torch.equal(out, out_orig))\n",
        "  \n",
        "  domain_io = []\n",
        "  domain_io.append(['unsqueeze',torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2), [in1]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['roll', torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2), [in2]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['where', torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2), [torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "Composite45()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "266264a2-5fcf-4e22-bab5-359d844dfa9e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "266264a2-5fcf-4e22-bab5-359d844dfa9e",
        "executionStartTime": 1632947980273,
        "executionStopTime": 1632947980362
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite46():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([3, 4, 1])\n",
        "    out_orig = torch.tensor([0, 0, 0, 1, 1, 1, 1, 2])\n",
        "    out = torch.repeat_interleave(torch.arange(3), in1, 0)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.repeat_interleave(torch.arange(3), in1, 0), []])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['repeat_interleave', torch.repeat_interleave(torch.arange(3), in1, 0), [torch.arange(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite46()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "65cf9d8d-b58c-4465-87a4-b57d6da11a83",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "65cf9d8d-b58c-4465-87a4-b57d6da11a83",
        "executionStartTime": 1632947980400,
        "executionStopTime": 1632947980519
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite48():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([32, 53, 45, 38, 29, 89, 64, 23])\n",
        "    in2 = torch.tensor([38, 53, 89, 38, 32, 64])\n",
        "    out_orig = torch.tensor([3, 1, 5, 3, 0, 6])\n",
        "    out = torch.argmax(torch.eq(in1, torch.unsqueeze(in2, 1)).int(), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    print('torch.unsqueeze(in1, 1)', torch.unsqueeze(in1, 1))\n",
        "    print('torch.eq(in2, torch.unsqueeze(in1, 1)).float()', torch.eq(in2, torch.unsqueeze(in1, 1)).int())\n",
        "    print('torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1)', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).int(), 1))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['unsqueeze',torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['eq', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1), [in2,torch.unsqueeze(in1, 1).float()]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['argmax', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1), [torch.eq(in2, torch.unsqueeze(in1, 1)).float()]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite48()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "389e3f65-7ee3-4cfa-a9c4-731f8c7c7a5b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "389e3f65-7ee3-4cfa-a9c4-731f8c7c7a5b",
        "executionStartTime": 1632947980630,
        "executionStopTime": 1632947980692
      },
      "source": [
        "def Composite49():\n",
        "    in1 = torch.tensor([\n",
        "                    [[[1, 2, 3], [4, 5, 6]]],\n",
        "                    [[[8, 10, 0], [6, 4, 2]]],\n",
        "                    [[[9, 8, 7], [1, 2, 3]]],\n",
        "                ])\n",
        "    in2 = torch.tensor([20, 5, 10])\n",
        "    out_orig = torch.tensor([\n",
        "                [[[20, 40, 60], [80, 100, 120]]],\n",
        "                [[[40, 50, 0], [30, 20, 10]]],\n",
        "                [[[90, 80, 70], [10, 20, 30]]],\n",
        "            ])\n",
        "    out = torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['mul', torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3), [in2,torch.transpose(in1, 0, 3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3), [torch.mul(in2, torch.transpose(in1, 0, 3))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite49()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6004858e-6776-4075-87c0-6b0f8065621f",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "6004858e-6776-4075-87c0-6b0f8065621f",
        "executionStopTime": 1632947980830,
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1632947980758
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite50():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor(3)\n",
        "    out_orig = torch.tensor([\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "            ])\n",
        "    out = torch.nn.functional.one_hot(in1.expand(5), 6)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['expand', torch.nn.functional.one_hot(in1, 6), [torch.tensor(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(in1, 6), [in1, torch.tensor(6)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ee680493-5556-49ba-b734-e5a2767465f9",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "ee680493-5556-49ba-b734-e5a2767465f9",
        "executionStartTime": 1632947980878,
        "executionStopTime": 1632947980927
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f22efbb7-5acb-46ed-ba04-cf489ee1f7a4",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "f22efbb7-5acb-46ed-ba04-cf489ee1f7a4",
        "executionStartTime": 1632947980936,
        "executionStopTime": 1632947980985
      },
      "source": [
        "tc = 0\n",
        "for t in sorted(total_correct):\n",
        "    tc +=  total_correct[t]\n",
        "    print(t, total_correct[t], tc/(total_benchmark-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a56ea360-c23b-4063-8475-a157fa015809",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "a56ea360-c23b-4063-8475-a157fa015809",
        "executionStartTime": 1632947980995,
        "executionStopTime": 1632947981001
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
