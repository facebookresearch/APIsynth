{
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "bento_kernel_pytorch",
      "metadata": {
        "kernel_name": "bento_kernel_pytorch",
        "nightly_builds": true,
        "fbpkg_supported": true,
        "is_prebuilt": true
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "last_server_session_id": "6667c6f8-b139-4619-bd2e-7bb8d20b4177",
    "last_kernel_id": "17cede80-cd11-407f-bce7-c58947c579a9",
    "last_base_url": "https://devvm3095.ftw0.facebook.com:8090/",
    "last_msg_id": "8267ab11-fed7755479156857b2d76124_1806",
    "captumWidgetMessage": {},
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "originalKey": "72249875-caad-47b6-a9b3-cfdab49470b6",
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "fedab9d8-e7e0-4280-a396-6db0dee8c5e7",
        "executionStartTime": 1630731937778,
        "executionStopTime": 1630731937802
      },
      "source": [
        "import random\n",
        "from random import choice\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch as T\n",
        "device = T.device(\"cuda\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3b3daf1e-318c-48a5-b8ca-81ecfdf981b3",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "07df088c-b141-4b84-b701-e307d6cb7c45",
        "executionStartTime": 1630732559829,
        "executionStopTime": 1630732559867
      },
      "source": [
        "is16 = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "eae3c46a-43ee-4108-b084-76485a21de4b",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "9701cbdf-6c93-4ab5-9abb-6786f2ecbdf2",
        "executionStartTime": 1630731939710,
        "executionStopTime": 1630731939716
      },
      "source": [
        "class FinalEmbedding:\n",
        "    def __init__(self,x,y):\n",
        "        self.x_data = x\n",
        "        self.y_data = y\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        preds = self.x_data[idx]\n",
        "        trgts = self.y_data[idx] \n",
        "        sample = { \n",
        "        'predictors' : preds,\n",
        "        'targets' : trgts\n",
        "        }\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "24b1f871-3d08-49e8-a0a2-4d704efae887",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "65df0781-8327-4331-92a3-f43da1a73f28",
        "executionStartTime": 1630731940758,
        "executionStopTime": 1630731940765
      },
      "source": [
        "from iopath.common.file_io import PathManager\n",
        "from iopath.fb.manifold import ManifoldPathHandler\n",
        "\n",
        "def load_checkpoint(checkpoint_path, map_location=None):\n",
        "    pm = PathManager()\n",
        "    pm.register_handler(ManifoldPathHandler())\n",
        "    with pm.open(checkpoint_path, \"rb\") as f:\n",
        "        if map_location is not None:\n",
        "            checkpoint = torch.load(f, map_location=map_location)\n",
        "        else:\n",
        "            checkpoint = torch.load(f, map_location=lambda storage, loc: storage)\n",
        "    return checkpoint\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "925ed554-a1b1-49f7-a450-1a0513433f41",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a36395b0-d31c-4a93-b72f-2ec29d69ce04",
        "executionStartTime": 1630732244333,
        "executionStopTime": 1630732244487
      },
      "source": [
        "api2indx = torch.load('gen1_33/api2indx.pt')\n",
        "api2indx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "bdcc3108-84a5-4d52-82f4-ff84fab43d13",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "eb88d846-8714-4174-bbc7-5dda9f05d0f5",
        "executionStartTime": 1630732248620,
        "executionStopTime": 1630732248632,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class pycoder_parameters:\n",
        "\n",
        "    ''' Core Fuzzing Parameters '''\n",
        "    NUM_FUZZ_PER_API= 100001 #000\n",
        "    NUM_TEST_FUZZ = 2\n",
        "    FLOAT_TENSOR = False #We either generate float or integer tensors\n",
        "    UNIT_TEST = False\n",
        "    COMPOSITE = True\n",
        "\n",
        "    ''' Fuzzing Detailed Parameters '''\n",
        "    MAX_TENSOR_DIMENSIONS = 3 #how many rows, columns, etc.\n",
        "    MIN_VAL_PER_DIMENSION = 1 # e.g., min number of rows, columns, etc. \n",
        "    MAX_VAL_PER_DIMENSION = 5 # e.g., max number of rows, columns, etc. \n",
        "\n",
        "    #So far limiting to integers\n",
        "    MIN_TENSOR_VALUE = 1\n",
        "    MAX_TENSOR_VALUE = 15\n",
        "    \n",
        "\n",
        "    ''' Embedding Parameters '''\n",
        "    EMBEDDING_NOISE_LEVEL = 0 #0 noise by default\n",
        "    EMBEDDING_SIZE = 150\n",
        "    SHAPE_EMBEDDING_SIZE = 6\n",
        "\n",
        "\n",
        "    data_type = 'float' if FLOAT_TENSOR is  True else 'integer'\n",
        "    model_type = 'Composite_' if COMPOSITE is  True else 'Single_'\n",
        "    file_name = str(model_type) + str(NUM_FUZZ_PER_API) + '_' + data_type\n",
        "    fuzzing   = file_name + '.pt'\n",
        "    embedding = file_name + '.embedding' + '.pt',\n",
        "    classification = file_name + '.model_result' + '.pt' \n",
        "    train_valid_test = file_name + 'train_valid_test.pt'\n",
        "\n",
        "    def setNoiseLevel(self, noise):\n",
        "        self.EMBEDDING_NOISE_LEVEL = noise\n",
        "        self.embedding = self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt'\n",
        "\n",
        "    def getEmbeddingFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt')\n",
        "\n",
        "    def getVisulizationFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '_' +  'tSNE.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ccb2c8c9-45ef-4bb8-b5fb-61448cc6db01",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "d308f3c5-8020-4106-9fd6-7b1bdba08e95",
        "executionStartTime": 1630732254820,
        "executionStopTime": 1630732254920,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "NOISE = 0\n",
        "f = pycoder_parameters()\n",
        "f.setNoiseLevel(NOISE)\n",
        "f.embedding = f.getEmbeddingFile() \n",
        "print(f.embedding)\n",
        "print(f.SHAPE_EMBEDDING_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7e1a6d67-1ad4-436a-9991-6e8d49fde2a9",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "2a608330-84b0-4df7-bd8e-019604a0fce2",
        "executionStartTime": 1630732257122,
        "executionStopTime": 1630732257152,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "import sklearn.datasets\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "EMBEDDING_SIZE = f.EMBEDDING_SIZE\n",
        "SHAPE_EMBEDDING_SIZE = f.SHAPE_EMBEDDING_SIZE\n",
        "\n",
        "def encode_values_to_code(tensor):\n",
        "    tensor = tensor.clone()\n",
        "    tensor[(tensor>=100) & (tensor<1000)] = 100\n",
        "    tensor[(tensor>=1000)] = 101\n",
        "    tensor[(tensor<=-20) & (tensor>-100)] = -20\n",
        "    tensor[(tensor<=-100) & (tensor>-1000)] = -21\n",
        "    tensor[(tensor<=-1000)] = -22\n",
        "    return tensor\n",
        "\n",
        "def tensor_flatten_pad(tensor, embed_size=EMBEDDING_SIZE, shape_embed_size=SHAPE_EMBEDDING_SIZE, isNoise=False):\n",
        "    \n",
        "    t_flatten = torch.flatten(tensor)\n",
        "\n",
        "    padding_length = embed_size - list(t_flatten.shape)[-1]\n",
        "    p1d = (0,padding_length) #just padding the last dimension\n",
        "    t_pad = F.pad(input=t_flatten, pad=p1d, mode='constant', value=0).type(torch.FloatTensor)\n",
        "    \n",
        "    type_padding = 0\n",
        "    if tensor.dtype == torch.bool:\n",
        "        type_padding = 1\n",
        "    elif tensor.dtype == torch.float64 \\\n",
        "        or tensor.dtype == torch.double \\\n",
        "        or tensor.dtype == torch.float32 \\\n",
        "        or tensor.dtype == torch.float16:\n",
        "            type_padding = 2\n",
        "\n",
        "    \n",
        "    \n",
        "    '''size embedding'''\n",
        "    if(shape_embed_size > 0):\n",
        "        t_shape = list(tensor.shape)\n",
        "        padding_length = shape_embed_size -1 - len(t_shape)\n",
        "        p1d = (0,padding_length) #just padding the last dimension\n",
        "        s_pad = F.pad(input=torch.Tensor(t_shape), pad=p1d, mode='constant', value=0).type(torch.float)\n",
        "\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        s_pad_list = s_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1] + s_pad_list + [-1])\n",
        "    \n",
        "    else:\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1])\n",
        "        \n",
        "    encoded_tensor = encode_values_to_code(tensor_embedding)\n",
        "    return(encoded_tensor)\n",
        "\n",
        "'unit test'\n",
        "t1 = torch.tensor([[[1,2,3]],[[4,555,6]]])\n",
        "tf = tensor_flatten_pad(t1, shape_embed_size=5, isNoise=True)\n",
        "print(tf, tf.shape)\n",
        "\n",
        "t2 = torch.tensor([[[True,False,True]],[[True,True,False]]])\n",
        "tf1 = tensor_flatten_pad(t2, shape_embed_size=0)\n",
        "print(tf1, tf1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "74bda699-bb24-492e-9f3e-19abf88f693a",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "b8d139a0-e5e7-43aa-9f11-ee1af5f4d2a4",
        "executionStartTime": 1630731951611,
        "executionStopTime": 1630731951617,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def embed_tensors(data_list):\n",
        "       \n",
        "    global EMBEDDING_SIZE\n",
        "    global api2indx\n",
        "    \n",
        "    X=[]\n",
        "    y=[]\n",
        "\n",
        "    all_input_output_tensors = set()\n",
        "    duplicate_count = 0\n",
        "\n",
        "    dict_indx = len(api2indx)\n",
        "\n",
        "    final_output = data_list[-1][1]\n",
        "\n",
        "    prev_out = torch.Tensor()\n",
        "    \n",
        "    api_seq_x = []\n",
        "    api_seq_y = []\n",
        "\n",
        "    for data in data_list:\n",
        "        api = data[0]      \n",
        "        api_indx = api2indx[api]\n",
        "        \n",
        "        input_list = data[2] #.get_input()\n",
        "        output_tensor = final_output #data.get_output()\n",
        "        \n",
        "        it_pad = []\n",
        "\n",
        "        for input_tensor in input_list:\n",
        "            if input_tensor.shape == prev_out.shape and torch.all(input_tensor.eq(prev_out)).item():\n",
        "                t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                t[-1] = -1\n",
        "                it_pad.append(t)\n",
        "            else:         \n",
        "                #flatten the input tensor\n",
        "                it_pad.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "            \n",
        "        \n",
        "        #adding addidional tensors with zero embeddings for < 2 tensors\n",
        "        for i in range(len(it_pad),3):\n",
        "            t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "            t[-1] = -1\n",
        "            it_pad.append(t)\n",
        "       \n",
        "        ot_pad = tensor_flatten_pad(output_tensor, isNoise=True)\n",
        "\n",
        "        x = T.flatten(T.stack((it_pad[0],it_pad[1], it_pad[2], ot_pad)))\n",
        "\n",
        "\n",
        "        xl = (x,api_indx)\n",
        "        \n",
        "        if xl in all_input_output_tensors:\n",
        "            duplicate_count += 1\n",
        "        else:\n",
        "            all_input_output_tensors.add(xl)\n",
        "\n",
        "    \n",
        "        api_seq_x.append(x) \n",
        "        api_seq_y.append(api_indx)\n",
        "\n",
        "        prev_out = data[1]\n",
        "\n",
        "    X.append(api_seq_x)\n",
        "    y.append(api_seq_y)\n",
        "    \n",
        "    return(X,y)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d13c3e91-3e93-4d27-b645-efc3d28ceb36",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "06b68fb9-2fa6-464b-ad96-4cc8240e06c2",
        "executionStartTime": 1630732307729,
        "executionStopTime": 1630732307842
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "e53a2472-3455-43ea-a026-746a14c59a4c",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "2363db56-495b-4339-8259-eaf652125ac4",
        "executionStartTime": 1630732308974,
        "executionStopTime": 1630732308992,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def process_dataX(tensor_list):\n",
        "    io_seq = []\n",
        "    \n",
        "    n0 = tensor_list[0]\n",
        "\n",
        "    if(len(tensor_list) == 1):\n",
        "        n1 = torch.zeros(n0.shape)\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "        \n",
        "    elif(len(tensor_list) == 2):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "\n",
        "    elif(len(tensor_list) == 3):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = tensor_list[2]\n",
        "\n",
        "        \n",
        "    new_list = torch.stack((n0, n1, n2))\n",
        "    io_seq.append(new_list)\n",
        "    \n",
        "    return(torch.stack(io_seq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "43e37999-40cd-40e6-abc2-b1ea9d9874fa",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "d2191af8-b575-4df5-8d08-f919aa14db2a",
        "executionStartTime": 1630732311082,
        "executionStopTime": 1630732311099,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "indx2api = {}\n",
        "EOS = '<eol>'\n",
        "\n",
        "def process_dataY(api_seq):\n",
        "    global indx2api\n",
        "    global api2indx\n",
        "\n",
        "    ''' Add <eol> to the dictionary '''\n",
        "    indx2api = {v: k for k, v in api2indx.items()}\n",
        "\n",
        "    if api2indx.get(EOS, -1) == -1:\n",
        "        max_key = max(indx2api.keys())\n",
        "        print(max_key)\n",
        "        indx2api[max_key+1] = EOS\n",
        "        api2indx[EOS] = max_key+1\n",
        "\n",
        "    eos = api2indx[EOS]\n",
        "\n",
        "    api_tensors = []\n",
        "\n",
        "\n",
        "    api0 = api_seq[0]\n",
        "\n",
        "    if len(api_seq) == 1:\n",
        "        api1 = eos\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 2:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 3:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = api_seq[2]\n",
        "\n",
        "    else:\n",
        "        print('!!! Not supposed to be here')\n",
        "\n",
        "    t = torch.tensor([api0, api1, api2])\n",
        "    api_tensors.append(t)\n",
        "    \n",
        "    return(torch.stack(api_tensors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6cf224d3-dcc6-4df0-81be-ed7252aa6e4e",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "fccd0758-7228-430c-9c1f-6b11eb206df0",
        "executionStartTime": 1630732312792,
        "executionStopTime": 1630732312822,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, bidirectional=True)   \n",
        "        \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        #Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out1 = out.contiguous().view(-1, self.hidden_dim*2)\n",
        "        out1 = self.fc(out1)\n",
        "        \n",
        "        return out1, hidden, out\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        hidden = torch.zeros(self.n_layers*2, batch_size, self.hidden_dim).to(device)\n",
        "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b926dcdc-2b2a-489f-98b0-0a51b24a5ca0",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "196df41b-a4c2-427f-896a-79b9243b4d27",
        "executionStartTime": 1630732314678,
        "executionStopTime": 1630732314691
      },
      "source": [
        "class FFNet(T.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FFNet, self).__init__()\n",
        "\n",
        "    self.hid1 = T.nn.Linear(4*(f.EMBEDDING_SIZE+f.SHAPE_EMBEDDING_SIZE+1+2), 500)\n",
        "    self.hid2 = T.nn.Linear(500, 250)\n",
        "    self.hid3 = T.nn.Linear(250, 100)\n",
        "    self.oupt = T.nn.Linear(100, len(api2indx))\n",
        "\n",
        "    T.nn.init.xavier_uniform_(self.hid1.weight)\n",
        "    T.nn.init.zeros_(self.hid1.bias)\n",
        "    T.nn.init.xavier_uniform_(self.hid2.weight)\n",
        "    T.nn.init.zeros_(self.hid2.bias)\n",
        "    T.nn.init.xavier_uniform_(self.oupt.weight)\n",
        "    T.nn.init.zeros_(self.oupt.bias)\n",
        "\n",
        "    T.nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    z1 = T.tanh(self.hid1(x))\n",
        "    z2 = T.tanh(self.hid2(z1))\n",
        "    z3 = T.tanh(self.hid3(z2))\n",
        "    z = self.oupt(z3)  # no softmax: CrossEntropyLoss() \n",
        "    return (z, z3, z2, z1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c20ec81e-d7f5-4538-812e-a6a1159474bb",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "07d05707-3f2c-41bb-8329-6ade3d21428a",
        "executionStartTime": 1630732316736,
        "executionStopTime": 1630732316839
      },
      "source": [
        "DEBUG = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "178bcf38-8eff-4df2-8da2-23ec58bc507a",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "04f154ab-b995-4f6d-aabf-75e63e9e621c",
        "executionStartTime": 1630732317694,
        "executionStopTime": 1630732317722
      },
      "source": [
        "def embed_tensor_for_model(domain_io):\n",
        "\n",
        "    x, y = embed_tensors(domain_io)\n",
        "\n",
        "    X = process_dataX(x[0])\n",
        "    Y = process_dataY(y[0])\n",
        "    ds = FinalEmbedding(X,Y)\n",
        "\n",
        "    X = ds[0]['predictors'].to(device)\n",
        "    Y = ds[0]['targets'].to(device)  # [0] [1] or [2]\n",
        "\n",
        "    return(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "520c1443-57b2-499e-96fa-7783d6758f05",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "906b1a0b-2c47-4f7a-91e8-23513d276897",
        "executionStartTime": 1630732319485,
        "executionStopTime": 1630732319503
      },
      "source": [
        "def beam_search(top3_list):\n",
        "\n",
        "    api_seq = []\n",
        "    api_seq1 = []\n",
        "    for i in top3_list[0]:\n",
        "        for j in top3_list[1]:\n",
        "            api_seq1.append(((i[0], j[0]), i[1]*j[1]))\n",
        "    \n",
        "    api_seq1.sort(key = lambda x: x[1], reverse=True) \n",
        "\n",
        "    for k in top3_list[2]:\n",
        "        for s1 in api_seq1:\n",
        "            api_seq.append(((s1[0][0], s1[0][1], k[0]), s1[1]*k[1]))\n",
        "\n",
        "    api_seq.sort(key = lambda x: x[1], reverse=True) \n",
        "    \n",
        "    return(api_seq)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a175a87b-99c9-4464-ac1e-112e2305b3f3",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "89b024a0-5464-4ba0-bb3a-838f61bbb83b",
        "executionStartTime": 1630732320985,
        "executionStopTime": 1630732320995
      },
      "source": [
        "total_correct = {}\n",
        "seq_len_correct = {}\n",
        "seq_len_total = {}\n",
        "total_benchmark = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "91ac3541-ceaa-4542-8269-e181a1b4ea95",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "5bc2e259-9ed7-464f-8161-cd7a99260256",
        "executionStartTime": 1630732367280,
        "executionStopTime": 1630732367287
      },
      "source": [
        "def reset_stat():\n",
        "    global total_correct\n",
        "    global seq_len_correct\n",
        "    global seq_len_total\n",
        "    global total_benchmark\n",
        "    \n",
        "    total_correct = {}\n",
        "    seq_len_correct = {}\n",
        "    seq_len_total = {}\n",
        "    total_benchmark = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4adfc359-26e7-4fcd-9d71-312a12492e5a",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "19cf8a64-d815-4d5a-a77d-0471e13f516f",
        "executionStartTime": 1630732369919,
        "executionStopTime": 1630732369940
      },
      "source": [
        "def print_stat():\n",
        "    print('total_correct', total_correct)\n",
        "    print('seq_len_correct', seq_len_correct)\n",
        "    print('seq_len_total', seq_len_total)\n",
        "    print('total_benchmark', total_benchmark)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "fcd1813c-4c37-40b5-9031-f792b5f9d56c",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "d87b5438-46eb-4e93-9a32-5320f0398c0f",
        "executionStartTime": 1630732371142,
        "executionStopTime": 1630732371169,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def query_model(X, Y):\n",
        "    \n",
        "    global total_benchmark\n",
        "    with T.no_grad():\n",
        "      start_time = time.time()\n",
        "      predicts, z3, z2, z1 = net(X)\n",
        "      temp_z3 = torch.unsqueeze(z3,0)\n",
        "      model_output, hidden, int_output = rnn_model(temp_z3)\n",
        "\n",
        "      target_list = list(Y.cpu().numpy())\n",
        "\n",
        "    top_indx = []\n",
        "\n",
        "    top3_list = []\n",
        "\n",
        "    print('---- Top-k ----')\n",
        "    for i, m in enumerate(model_output):\n",
        "        top3 = []\n",
        "        prob = nn.functional.softmax(m, dim=0).data\n",
        "        # Taking the class with the highest probability score from the output\n",
        "        xx = torch.topk(prob,3,dim=0)[1]\n",
        "        for x in xx.cpu().numpy():\n",
        "          print(indx2api[x])\n",
        "          top3.append((indx2api[x], prob[x].item()))\n",
        "        top3_list.append(top3)\n",
        "        print('====')\n",
        "        \n",
        "    print('---- Predicted ----')\n",
        "    for m in model_output:\n",
        "        prob = nn.functional.softmax(m, dim=0).data\n",
        "        api_ind = torch.max(prob, dim=0)[1].item()\n",
        "        top_indx.append(api_ind)\n",
        "        if DEBUG:\n",
        "            print(indx2api[api_ind], prob[api_ind])\n",
        "\n",
        "\n",
        "    print('---- Expected ----')\n",
        "    seq_len = 0\n",
        "    for o in list(Y):\n",
        "        print(o.item())\n",
        "        if o.item() != len(api2indx)-1:\n",
        "          seq_len += 1\n",
        "        print(indx2api[o.item()])\n",
        "    print('seq length', seq_len)\n",
        "    if seq_len_correct.get(seq_len, -1) == -1:\n",
        "      seq_len_correct[seq_len] = 0\n",
        "      seq_len_total[seq_len] = 0\n",
        "    \n",
        "    seq_len_total[seq_len] += 1\n",
        "    total_benchmark += 1\n",
        "\n",
        "    o = list(Y)\n",
        "    expected = ((indx2api[o[0].item()], indx2api[o[1].item()], indx2api[o[2].item()]))\n",
        "    \n",
        "    top3_list = beam_search(top3_list)\n",
        "    for i,t in enumerate(top3_list):\n",
        "      if t[0] == expected:\n",
        "        print(i+1, t[0], '\\t***MATCH')\n",
        "        if total_correct.get(i+1, -1) == -1:\n",
        "          total_correct[i+1] = 0\n",
        "        total_correct[i+1] += 1\n",
        "        seq_len_correct[seq_len] += 1\n",
        "        break\n",
        "      else:\n",
        "        print(t[0])\n",
        "    return(top3_list)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "75839cae-af9c-401e-8bc4-8ff9a67ceedc",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "85dbaf0f-86b1-4f46-976d-39aad71b84c9",
        "executionStartTime": 1630732375321,
        "executionStopTime": 1630732375340,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def api_edit_distance(seq1, seq2):\n",
        "\n",
        "    edit_distantce = 0\n",
        "\n",
        "    for i in range(len(seq1)):\n",
        "        if seq1[i] != seq2[i]:\n",
        "            edit_distantce += 1\n",
        "\n",
        "    return(edit_distantce)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "cdd910b9-58bf-4365-acbe-c7a44a3772e4",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7ee9cfce-a811-4bc3-8149-cbea6289588b",
        "executionStartTime": 1630743251287,
        "executionStopTime": 1630743251352
      },
      "source": [
        "net = torch.load('net_model.pt')\n",
        "rnn_model = torch.load('rnn_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7d95d683-0426-4feb-881d-b05ab1681ac4",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "fb2b2fe3-5b56-496d-8a6e-7b77a95a9e48",
        "executionStartTime": 1630743565193,
        "executionStopTime": 1630743565241
      },
      "source": [
        "reset_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "05792f31-b2ea-44cc-9250-42e023af9d2b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "4787fbdf-afe9-4eb4-b566-8c3436793e7d",
        "executionStartTime": 1630743253845,
        "executionStopTime": 1630743253934
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ea892a3b-bb83-4c57-afaa-4087e65cbed9",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "e172fcb5-920c-4d11-b9e7-5a0543677351",
        "executionStartTime": 1630743568308,
        "executionStopTime": 1630743568352
      },
      "source": [
        "def Composite01():\n",
        "    in1 = torch.tensor([[5, 2], [1, 3], [0, 2]])\n",
        "    out_orig = torch.tensor([[[5, 5], [1, 1], [0, 0]],\n",
        "                                [[2, 2], [3, 3], [2, 2]]])                            \n",
        "    out = torch.transpose(in1.expand((2, 3, 2)), 0, 2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(in1, out))\n",
        "    \n",
        "    domain_io = []\n",
        "    domain_io.append(['expand', torch.transpose(in1.expand((2, 3, 2)), 0, 2), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    print('-------------------------------------')\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', torch.transpose(in1.expand((2, 3, 2)), 0, 2), [in1.expand((2, 3, 2))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "        \n",
        "Composite01()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1b5a4348-473d-4595-819a-7417b71a20dd",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "1162645e-e452-4e61-8a4e-05704d53068a",
        "executionStartTime": 1630743575151,
        "executionStopTime": 1630743575235
      },
      "source": [
        "def Composite02():\n",
        "    domain_inpt10 = torch.tensor([5, 1, 0, 3, 0, 0, 2, 0, 2])\n",
        "    domain_out10 = torch.lt(domain_inpt10, 1)\n",
        "    \n",
        "    domain_inpt20 = domain_out10\n",
        "    domain_inpt21 = domain_inpt10\n",
        "\n",
        "    domain_output_orig = torch.tensor([1, 1, 0, 1, 0, 0, 1, 0, 1])\n",
        "    domain_output = torch.where(domain_inpt20, domain_inpt21, 1)\n",
        "\n",
        "    print('domain_inpt10 : ', domain_inpt10, domain_inpt10.shape)\n",
        "    print('domain_inpt20 : ', domain_inpt20, domain_inpt20.shape)\n",
        "    print('domain_output : ', domain_output, domain_output.shape)\n",
        "    print(torch.equal(domain_output, domain_output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['lt', domain_output, [domain_inpt10, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['where', domain_output, [domain_inpt20, domain_inpt21, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite02()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a4071bf2-4258-4634-bf33-e4af47a1be74",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "6aac174b-d421-47d1-b95d-ae76dce9f776",
        "executionStartTime": 1630732025084,
        "executionStopTime": 1630732025178
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1515d5f8-0224-42ae-b3c9-f9cb1c7fd024",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "dad1fa3a-14a8-4ed6-b1e1-dc76b736612c",
        "executionStartTime": 1630723387768,
        "executionStopTime": 1630723387846
      },
      "source": [
        "def Composite05():\n",
        "    in1 = torch.tensor([[4, 3, 1], [6, 5, 2]])\n",
        "    in2 = torch.tensor([[[5, 5]], [[1, 5]], [[6, 0]]])\n",
        "    output_orig = torch.tensor([[[29, 35]], [[47, 55]]])\n",
        "    output = torch.tensordot(in1, in2, 1)\n",
        "    \n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output_orig, output))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', output, [in1, in2]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite05()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6ab97c41-f1e8-4781-b929-3653010ed3c2",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "52e7715f-9662-4e1e-b3e8-20bbb542f4c4",
        "executionStartTime": 1630743583316,
        "executionStopTime": 1630743583514
      },
      "source": [
        "def Composite06():\n",
        "    in1 = torch.tensor([3, 5, 0, 2, 3, 3, 0])\n",
        "    in2 = torch.unsqueeze(in1, 1)\n",
        "    output_orig = torch.tensor([\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
        "                [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
        "            ]).int()\n",
        "    output = torch.eq(in1, in2).int()\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['unsqueeze',  torch.eq(in1, in2), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['eq', torch.eq(in1, in2), [in1, torch.unsqueeze(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite06()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "68a89d21-583f-419e-ad91-32b92ca06547",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5d5d1b28-414c-4e33-abc6-68f82cd52904",
        "executionStartTime": 1630723388009,
        "executionStopTime": 1630723388113
      },
      "source": [
        "def Composite07():\n",
        "    in1 = torch.tensor([\n",
        "                    [[8, 4, 6], [2, 12, 3]],\n",
        "                    [[11, 12, 5], [9, 12, 12]],\n",
        "                    [[9, 2, 13], [7, 0, 7]],\n",
        "                    [[2, 10, 5], [7, 1, 2]],\n",
        "                ])\n",
        "    output_orig = torch.tensor([\n",
        "                [[8, 4, 6], [11, 12, 5], [9, 2, 13], [2, 10, 5]],\n",
        "                [[2, 12, 3], [9, 12, 12], [7, 0, 7], [7, 1, 2]],\n",
        "            ])\n",
        "    output = torch.transpose(in1, 0, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', output, [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite07()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "572331fb-6bb2-40f4-801e-b5a66ead21c2",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5f4b101c-4322-4545-9b5c-8f3d4aff3f76",
        "executionStartTime": 1630743594466,
        "executionStopTime": 1630743594793
      },
      "source": [
        "def Composite08():\n",
        "    in1 = torch.tensor([1, 0, 0, 2, 1, 3, 5, 0, 1, 2, 10])\n",
        "    in2 = torch.tensor([12, 3, 45, 6, 7, 8, 9, 87, 65, 4, 32])\n",
        "    in3 = torch.gt(in1, 1)\n",
        "    output_orig = torch.tensor([6, 8, 9, 4, 32])\n",
        "    output = torch.masked_select(in2, torch.gt(in1, 1))\n",
        "\n",
        "    print('in1: ', in1, in1.shape, in1.dtype)\n",
        "    print('in2: ', in2, in2.shape, in2.dtype)\n",
        "    print('in3: ', in2, in2.shape, in2.dtype)\n",
        "    print('output', output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []   \n",
        "    domain_io.append(['gt', torch.masked_select(in2, torch.gt(in1, 1)), [in1, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []   \n",
        "    domain_io.append(['masked_select', torch.masked_select(in2, torch.gt(in1, 1)), [in2, torch.gt(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite08()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6e6f5c11-b490-42ac-92fe-eb0ad269c8ab",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7895503a-1c54-4170-84e6-408d60273ca6",
        "executionStartTime": 1630723388313,
        "executionStopTime": 1630723388322
      },
      "source": [
        "def Composite11():\n",
        "    in1 = torch.tensor([4, 0, 1, 1, 0, 4, 0, 0, 3, 4, 1])\n",
        "    out_orig = torch.tensor([4, 3, 0, 1, 3])\n",
        "    out = torch.bincount(in1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['bincount', torch.bincount(in1), [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite11()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b2193d68-963d-41ee-9790-44c77c7eaf60",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c5e5deb7-97bf-481a-b350-95147480c9cf",
        "executionStartTime": 1630743602076,
        "executionStopTime": 1630743602285
      },
      "source": [
        "def Composite13():\n",
        "    in1 = torch.tensor([[3, 5], [10, 2]])\n",
        "    in2 = torch.tensor([[[1, 0], [5, 4]], [[3, 10], [2, 0]]])\n",
        "    in3 = torch.matmul(in1, in2)\n",
        "    out_orig = torch.tensor([[[28, 20], [19, 30]], [[20, 8], [34, 100]]])\n",
        "    out = torch.transpose(torch.matmul(in1, in2), 0, 1)\n",
        "\n",
        "    print('in1 : ', in1, in1.shape, in1.dtype)\n",
        "    print('in2 : ', in2, in2.shape, in2.dtype)\n",
        "    print('in3 : ', in3, in3.shape, in3.dtype)\n",
        "    print('output : ', out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['matmul', torch.transpose(torch.matmul(in1, in2), 0, 1), [in1, in2]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', torch.transpose(torch.matmul(in1, in2), 0, 1), [torch.matmul(in1, in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite13()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "86f453a8-9729-49c8-81f3-dbd96c943fa0",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "0bf77010-a4a5-4615-a3f9-c75a640e6fb6",
        "executionStartTime": 1630743292130,
        "executionStopTime": 1630743292315
      },
      "source": [
        "def Composite14():\n",
        "    in1 = torch.tensor([\n",
        "                    [\n",
        "                        [False, False, True],\n",
        "                        [False, False, False],\n",
        "                        [True, False, True],\n",
        "                        [False, True, False],\n",
        "                        [False, False, False],\n",
        "                        [True, True, True],\n",
        "                        [True, True, False],\n",
        "                    ]\n",
        "                ]).int()\n",
        "    out_orig = torch.tensor([[True, False, True, True, False, True, True]]).int()\n",
        "    out = torch.any(in1, -1).int()\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['any', torch.any(in1, -1), [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite14()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "082bb679-4413-4bf6-ad22-aea790ac605f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5718fd49-0175-4b42-8cad-accdc70f4ffb",
        "executionStartTime": 1630743612356,
        "executionStopTime": 1630743612539
      },
      "source": [
        "def Composite15():\n",
        "    in1 = torch.tensor([3, 1, 2, 0, 1, 0, 10, 1, 0])\n",
        "    out_orig = torch.tensor([3, 0, 2, 0, 0, 0, 10, 0, 0])\n",
        "    out = torch.mul(in1, torch.ne(in1, 1)) \n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['ne', torch.mul(in1, torch.ne(in1, 1)), [in1, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['mul', torch.mul(in1, torch.ne(in1, 1)), [in1, torch.ne(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite15()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3f3b0e0c-4c77-4fb4-84ee-98282341878a",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "67435d9f-9468-4104-8b34-244265a465d1",
        "executionStartTime": 1630743618699,
        "executionStopTime": 1630743618779
      },
      "source": [
        "def Composite16():\n",
        "    in1 = torch.tensor([[2, 5], [3, 0], [8, 7]])\n",
        "    in2 = torch.tensor([4, 10, 6])\n",
        "    out_orig = torch.tensor([[8, 20], [30, 0], [48, 42]])\n",
        "    out = torch.mul(in1, torch.unsqueeze(in2, 1))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = [] \n",
        "    domain_io.append(['unsqueeze',torch.mul(in1, torch.unsqueeze(in2, 1)), [in2]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = [] \n",
        "    domain_io.append(['mul', torch.mul(in1, torch.unsqueeze(in2, 1)), [in1,torch.unsqueeze(in2, 1)]])    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "2a5da941-867e-4f23-8526-3c59c8779b98",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "f7363897-7e6a-45dc-b9c3-e25f8e3fac56",
        "executionStartTime": 1630723388884,
        "executionStopTime": 1630723389020
      },
      "source": [
        "def Composite17():\n",
        "    in1 = torch.tensor([17, 32, 99])\n",
        "    out_orig = torch.tensor([[17, 17], [32, 32], [99, 99]])\n",
        "    out = torch.stack((in1, in1), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []    \n",
        "    domain_io.append(['stack', out, [in1, in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite17()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "df782abe-b8bc-41eb-8207-a85009def8ac",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a674f109-140e-4bec-a79d-b05ea7fbdaea",
        "executionStartTime": 1630743629922,
        "executionStopTime": 1630743630154
      },
      "source": [
        "def Composite18():\n",
        "    in1 = torch.tensor([[[1, 1, 1], [1, 0, 1]], [[1, 2, 3], [4, 5, 6]]])\n",
        "    in2 = torch.tensor([[1, 1, 1, 1], [1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "    in3 = torch.tensor([100, 200, 300, 400])\n",
        "    in4 = torch.matmul(in1, in2)\n",
        "\n",
        "    out_orig = torch.tensor([\n",
        "                [[107, 209, 311, 413], [106, 207, 308, 409]],\n",
        "                [[118, 223, 328, 433], [139, 250, 361, 472]],\n",
        "            ])\n",
        "    out = torch.add(in3, torch.matmul(in1, in2))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(in3, in3.shape, in3.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['matmul', out, [in1, in2]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['add', out, [in3, torch.matmul(in1, in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite18()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "75e64ee1-901a-4efd-afa6-1e7ad750a040",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2be48928-dd14-4d05-8e74-cff812128d46",
        "executionStartTime": 1630743638566,
        "executionStopTime": 1630743640135
      },
      "source": [
        "# NOT SUPPORTING by 16\n",
        "def Composite20():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([\n",
        "                    [7, 2, 1],\n",
        "                    [4, 5, 1],\n",
        "                    [4, 4, 2],\n",
        "                    [3, 4, 3],\n",
        "                    [0, 0, 1],\n",
        "                ])\n",
        "    out_orig = torch.tensor([[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "    out = torch.nn.functional.one_hot(torch.argmax(in1, 1), 3)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['argmax', torch.nn.functional.one_hot(torch.argmax(in1, 1),3), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(torch.argmax(in1, 1),3), [torch.argmax(in1, 1), torch.tensor(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite20()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7a76be2e-e633-4841-bb9a-afe73f204673",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "abd1a483-d69d-4a81-adba-64c2fc44ccdd",
        "executionStartTime": 1630723389208,
        "executionStopTime": 1630723389300
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite21():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[2], [0], [1], [0]])\n",
        "    in2 = torch.tensor([[2, 5, 3], [1, 3, 6], [1, 6, 3], [7, 0, 3]])\n",
        "    out_orig = torch.tensor([[3], [1], [6], [7]])\n",
        "    out = torch.gather(in2, 1, in1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['gather', out, [in2, in1]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite21()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "35ccba4a-5c26-487c-bd41-1d91745d904f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "6e4f2ba1-4e6a-417c-9a1f-3ad02cfe5801",
        "executionStartTime": 1630723389313,
        "executionStopTime": 1630723389327
      },
      "source": [
        "def Composite22():\n",
        "    in1 = torch.tensor([3, 1, 10])\n",
        "    in2 = torch.tensor([[6, 4], [5, 1], [3, 4]])\n",
        "    out_orig = torch.tensor([53, 53])\n",
        "    out = torch.tensordot(in1, in2, 1 )\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite22()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "697bd3e2-d5f2-42c8-9129-0d0edccc1c86",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7343e848-d91d-4960-a095-f1ff873c26f1",
        "executionStartTime": 1630743647869,
        "executionStopTime": 1630743648004
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite23():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[0, 5, 2], [3, 1, 4], [5, 1, 5]])\n",
        "    out_orig = torch.tensor([\n",
        "                [1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
        "                [0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
        "                [0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "            ])\n",
        "    out = torch.max(torch.nn.functional.one_hot(in1, 9), 1)[0]\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.sum(torch.nn.functional.one_hot(in1, 9), 1), [in1, torch.tensor(9)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.nn.functional.one_hot(in1, 9), 1), [torch.nn.functional.one_hot(in1, 9)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite23()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b904a04d-0e98-42c9-93cb-63888c56b660",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "278562f5-408a-4b54-ba14-0d391a7ab49f",
        "executionStartTime": 1630743342336,
        "executionStopTime": 1630743342487
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite24():\n",
        "  if is16 == True:\n",
        "        return\n",
        "  in1 = torch.tensor([3, 1, 4, 5, 2, 8, 6, 7])\n",
        "  in2 = 0\n",
        "  in3 = torch.tensor([1, 0, 2, 0, 1, 1, 0, 2])\n",
        "  out_orig = torch.tensor([3, 1, 2, 5, 2, 8, 6, 3.5])\n",
        "  out = torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float())\n",
        "\n",
        "  print(in1, in1.shape, in1.dtype)\n",
        "  print(in2)\n",
        "  print(in3, in3.shape, in3.dtype)\n",
        "  print(out, out.shape)\n",
        "  print(torch.equal(out, out_orig))\n",
        "\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['ne', torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float()), [in3, torch.tensor(in2)]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['div', torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float()), [in1, in3]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['where', torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float()), [torch.ne(in3, in2), torch.div(in1, in3), in1]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "Composite24()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "bb60132b-5b1c-4fb0-bce5-f9531c5419f7",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a56b8f7d-050b-4b7a-865d-0d06f033009f",
        "executionStartTime": 1630743656406,
        "executionStopTime": 1630743656522
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIS\n",
        "def Composite25():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    out_orig = torch.tensor([\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "            ]).int()\n",
        "    out = torch.tile(torch.eye(3), (4, 1)).int()\n",
        "\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['eye', torch.tile(torch.eye(3), (4, 1)), []])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tile', torch.tile(torch.eye(3), (4, 1)), [torch.eye(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite25()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "04d940b0-f200-4085-903a-58baf1fd67bf",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "051d5b4e-949b-4180-a571-f4c18ab31ebf",
        "executionStartTime": 1630743661634,
        "executionStopTime": 1630743661785
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite26():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[[3, 4], [1, 2]], [[5, 2], [10, 3]], [[10, 20], [4, 7]]])\n",
        "    out_orig = torch.tensor([10, 20, 41])\n",
        "    out = torch.sum(torch.sum(in1, 1), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.sum(in1, 1), 1), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.sum(in1, 1), 1), [torch.sum(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite26()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "70d207f8-2791-40d5-8b53-c0b26811e597",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8fa2cbc4-68df-4f16-a57b-bb6711316544",
        "executionStartTime": 1630743667964,
        "executionStopTime": 1630743668081
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite27():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([0, 3, 5, 6])\n",
        "    out_orig = torch.tensor([1, 0, 0, 1, 0, 1, 1, 0])\n",
        "    out = torch.sum(torch.nn.functional.one_hot(in1, 8), 0)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.sum(torch.nn.functional.one_hot(in1, 8), 0), [in1, torch.tensor(8)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.nn.functional.one_hot(in1, 8), 0), [torch.nn.functional.one_hot(in1, 8)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite27()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d108eea9-7cbd-4878-9c9d-fbba108dfb57",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b7c0a847-42c1-4aad-837b-14649b2b94e5",
        "executionStartTime": 1630723389914,
        "executionStopTime": 1630723389921
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite29():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21])\n",
        "    in2 = torch.tensor([12, 0, 10, 23, 16])\n",
        "    out_orig = torch.tensor([6, 0, 5, 11, 8])\n",
        "    out = torch.searchsorted(in1, in2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['searchsorted', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite29()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "29ad64fb-ec79-48fb-8407-229657dc0c23",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "d3a57080-6b11-44e6-a3f5-ce368232caa2",
        "executionStartTime": 1630723389997,
        "executionStopTime": 1630723390003
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "import math\n",
        "def Composite30():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "    in2 = torch.tensor([[9.0, 4.0], [8.0, 5.0], [7.0, 6.0]])\n",
        "    out_orig = torch.tensor([[math.sqrt(68), math.sqrt(58), math.sqrt(52)],\n",
        "                  [math.sqrt(36), math.sqrt(26), math.sqrt(20)],\n",
        "                  [math.sqrt(20), math.sqrt(10), math.sqrt(4)]])\n",
        "    out = torch.cdist(in1, in2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['cdist', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite30()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d7127cbc-7e27-4680-b91a-1f1177af0d59",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "af3141c5-c45c-42a7-a7f9-5f9c8867d345",
        "executionStartTime": 1630743676076,
        "executionStopTime": 1630743676155
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite32():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[1, 6, 2, 1], [3, 1, 4, 2], [2, 1, 2, 5]])\n",
        "    out_orig = torch.tensor([13, 15, 20])\n",
        "    out = torch.tensordot(in1, torch.arange(4), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.tensordot(in1, torch.arange(4), 1), []])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', torch.tensordot(in1, torch.arange(4), 1), [in1, torch.arange(4)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite32()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9c8f575d-a283-4e0b-bfef-ed56c1e904f6",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "bdd49672-6637-48cc-a7a5-1f1ddde92fa6",
        "executionStartTime": 1630723390208,
        "executionStopTime": 1630723390217
      },
      "source": [
        "def Composite34():\n",
        "    in1 = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[10, 20], [30, 40]]])\n",
        "    in2 = torch.tensor([3, 5, 10])\n",
        "    out_orig = torch.tensor([[128, 236], [344, 452]])\n",
        "    out = torch.tensordot(in2, in1, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite34()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "77d15600-7991-4c25-bf78-de7501f0db4f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c84ec2ff-0ddb-41c2-a709-2288364f2b4c",
        "executionStartTime": 1630743684391,
        "executionStopTime": 1630743684559
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite36():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([1, 0, 1, 1, 0, 1, 0, 1])\n",
        "    out_orig = torch.tensor([1.0, 0.0, 0.333333, 0.25, 0.0, 0.166667, 0.0, 0.125])\n",
        "    out = torch.div(in1, torch.add(in1, torch.arange(8)))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(out_orig, out_orig.shape, out_orig.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.arange(8), []])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "    print('--------------------------------------')\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['add', torch.div(in1, torch.add(in1, torch.arange(8))), [in1, torch.arange(8)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "    print('--------------------------------------')\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['div', torch.div(in1, torch.add(in1, torch.arange(8))), [in1, torch.add(in1, torch.arange(8))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite36()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d95b8a15-65e5-4b3c-9c5a-1d2e32c43d42",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "bb54d18c-73ee-4841-97d8-d148e00fe052",
        "executionStartTime": 1630723390406,
        "executionStopTime": 1630723390421
      },
      "source": [
        "def Composite37():\n",
        "    in1 = torch.tensor([\n",
        "                    [\n",
        "                        [[10, 20, 30], [40, 50, 60]],\n",
        "                        [[12, 34, 56], [78, 98, 76]],\n",
        "                    ]\n",
        "                ])\n",
        "    in2 = torch.tensor([5, 10, 20])\n",
        "    out_orig = torch.tensor([[[850, 1900], [1520, 2890]]])\n",
        "    out = torch.tensordot(in1, in2, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite37()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7c5e28bf-9c8d-4fae-97b7-894f614db564",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b32ca6e9-9b15-4dc5-9076-dc742d6d54ba",
        "executionStartTime": 1630743693043,
        "executionStopTime": 1630743693166
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite39():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[15, 10, 9, 20], [11, 0, 1, 9], [10, 1, 11, 25]])\n",
        "    out_orig = torch.tensor([\n",
        "                [225, 100, 81, 400],\n",
        "                [121, 0, 1, 81],\n",
        "                [100, 1, 121, 625],\n",
        "            ])\n",
        "    out = torch.square(torch.mul(in1, in1.bool()))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['mul', torch.square(torch.mul(in1, in1.bool().long())), [in1, in1.bool().long()]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['square', torch.square(torch.mul(in1, in1.bool().long())), [torch.mul(in1, in1.bool().long())]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite39()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "17c379b2-ca7d-40b0-a018-6fd0107d4733",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c52f7956-c835-4d55-b621-edb5804b80a2",
        "executionStartTime": 1630743431427,
        "executionStopTime": 1630743431530
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "#torch.masked_select(in1, torch.ne(torch.arange(10), in2))\n",
        "def Composite41():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([5, 2, 8, 2, 4, 1, 1, 0, 2, 1])\n",
        "    in2 = 3\n",
        "    out_orig = torch.tensor([5, 2, 8, 4, 1, 1, 0, 2, 1])\n",
        "    out = torch.masked_select(in1, torch.ne(torch.arange(10), in2))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.masked_select(in1, torch.ne(torch.arange(10), in2)),[]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['ne', torch.masked_select(in1, torch.ne(torch.arange(10), in2)), [torch.arange(10), torch.tensor(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['masked_select',torch.masked_select(in1, torch.ne(torch.arange(10), in2)), [in1, torch.ne(torch.arange(10), in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite41()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "2a6ef7a2-80e9-46ac-a5ba-596a123fc38e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c0e22164-da0f-4173-ae22-6047f67575f7",
        "executionStartTime": 1630723390733,
        "executionStopTime": 1630723390743
      },
      "source": [
        "def Composite42():\n",
        "    in1 = torch.tensor([4, 6, 2, 6, 7, 3, 3])\n",
        "    out_orig = torch.tensor([0, 0, 0, 0, 1, 0, 0]).int()\n",
        "    out = torch.eq(in1, 7)\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['eq', torch.eq(in1, 7), [in1, torch.tensor(7)]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite42()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "af9fc845-64de-457f-8462-439770682f27",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "dba5521a-3740-4df0-89a3-fa0e8970123f",
        "executionStartTime": 1630743701670,
        "executionStopTime": 1630743701829
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite44():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([\n",
        "                    [3, 5, 2],\n",
        "                    [6, 2, 3],\n",
        "                    [8, 7, 1],\n",
        "                    [0, 3, 5],\n",
        "                    [4, 7, 3],\n",
        "                    [2, 1, 6],\n",
        "                    [10, 20, 30],\n",
        "                    [4, 5, 6],\n",
        "                ])                \n",
        "    out_orig = torch.tensor([[9, 7, 5], [8, 19, 6], [6, 8, 9], [14, 25, 36]])\n",
        "    out = torch.sum(torch.reshape(in1, (-1, 2, 3)), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['reshape', torch.sum(torch.reshape(in1, (-1, 2, 3)), 1), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    print('-----------------------')\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['sum', torch.sum(torch.reshape(in1, (-1, 2, 3)), 1), [torch.reshape(in1, (-1, 2, 2))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite44()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "5c387073-abb7-426a-acdc-61aebf814872",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "3a405db1-0d1b-4c55-8fd2-0fb1fa430016",
        "executionStartTime": 1630743455068,
        "executionStopTime": 1630743455155
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite45():\n",
        "  if is16 == True:\n",
        "        return\n",
        "  in1 = torch.tensor([1, 0, 1, 0, 1])\n",
        "  in2 = torch.tensor([[[12, 34], [56, 78], [23, 54], [76, 78], [42, 24]]])\n",
        "  out_orig = torch.tensor([[[34, 12],\n",
        "         [56, 78],\n",
        "         [54, 23],\n",
        "         [76, 78],\n",
        "         [24, 42]]])\n",
        "  out = torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2)\n",
        "\n",
        "  print(in1, in1.shape)\n",
        "  print(in2, in2.shape)\n",
        "  print(out, out.shape)\n",
        "  print(torch.equal(out, out_orig))\n",
        "  \n",
        "  domain_io = []\n",
        "  domain_io.append(['unsqueeze',torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2), [in1]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['roll', torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2), [in2]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['where', torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2), [torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "Composite45()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "540e0a31-1971-442a-80aa-98eaada30270",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "946f1073-d0c1-4bca-b1bc-267e153322a7",
        "executionStartTime": 1630743708612,
        "executionStopTime": 1630743708679
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite46():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([3, 4, 1])\n",
        "    out_orig = torch.tensor([0, 0, 0, 1, 1, 1, 1, 2])\n",
        "    out = torch.repeat_interleave(torch.arange(3), in1, 0)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.repeat_interleave(torch.arange(3), in1, 0), []])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['repeat_interleave', torch.repeat_interleave(torch.arange(3), in1, 0), [torch.arange(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite46()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "0217267c-9413-4a3e-a4b9-5cf4fe69024b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c78e3b4c-a97e-4a25-883f-7770ffdcef04",
        "executionStartTime": 1630743470268,
        "executionStopTime": 1630743470337
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite48():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([32, 53, 45, 38, 29, 89, 64, 23])\n",
        "    in2 = torch.tensor([38, 53, 89, 38, 32, 64])\n",
        "    out_orig = torch.tensor([3, 1, 5, 3, 0, 6])\n",
        "    out = torch.argmax(torch.eq(in1, torch.unsqueeze(in2, 1)).int(), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    print('torch.unsqueeze(in1, 1)', torch.unsqueeze(in1, 1))\n",
        "    print('torch.eq(in2, torch.unsqueeze(in1, 1)).float()', torch.eq(in2, torch.unsqueeze(in1, 1)).int())\n",
        "    print('torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1)', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).int(), 1))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['unsqueeze',torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['eq', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1), [in2,torch.unsqueeze(in1, 1).float()]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['argmax', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1), [torch.eq(in2, torch.unsqueeze(in1, 1)).float()]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite48()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "83a92db4-6065-4611-be4d-ae6cdb3a2915",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "42ce2252-5507-41b3-888a-77508bdcf274",
        "executionStartTime": 1630743479738,
        "executionStopTime": 1630743479861
      },
      "source": [
        "def Composite49():\n",
        "    in1 = torch.tensor([\n",
        "                    [[[1, 2, 3], [4, 5, 6]]],\n",
        "                    [[[8, 10, 0], [6, 4, 2]]],\n",
        "                    [[[9, 8, 7], [1, 2, 3]]],\n",
        "                ])\n",
        "    in2 = torch.tensor([20, 5, 10])\n",
        "    out_orig = torch.tensor([\n",
        "                [[[20, 40, 60], [80, 100, 120]]],\n",
        "                [[[40, 50, 0], [30, 20, 10]]],\n",
        "                [[[90, 80, 70], [10, 20, 30]]],\n",
        "            ])\n",
        "    out = torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3), [in1]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['mul', torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3), [in2,torch.transpose(in1, 0, 3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3), [torch.mul(in2, torch.transpose(in1, 0, 3))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite49()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4180f08d-4399-40f5-aef1-e5397a85b722",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "a27947b8-20c0-4c50-990e-271930af5f02",
        "executionStopTime": 1630743716632,
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1630743716535
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite50():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor(3)\n",
        "    out_orig = torch.tensor([\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "            ])\n",
        "    out = torch.nn.functional.one_hot(in1.expand(5), 6)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['expand', torch.nn.functional.one_hot(in1, 6), [torch.tensor(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(in1, 6), [in1, torch.tensor(6)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c4a74fc8-f65f-49e5-9052-91ad86420855",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "bacbe589-a100-42e5-978d-83b9027806f2",
        "executionStartTime": 1630743722239,
        "executionStopTime": 1630743722397
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "bf965e21-03a6-4695-b745-9265921aaa08",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "be421ce1-4900-4a2a-80fa-2f05e9a9c625",
        "executionStartTime": 1630732113152,
        "executionStopTime": 1630732113202
      },
      "source": [
        "tc = 0\n",
        "for t in sorted(total_correct):\n",
        "    tc +=  total_correct[t]\n",
        "    print(t, total_correct[t], tc/(total_benchmark-1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
