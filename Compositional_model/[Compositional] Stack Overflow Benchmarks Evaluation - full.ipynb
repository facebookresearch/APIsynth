{
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "bento_kernel_pytorch",
      "metadata": {
        "kernel_name": "bento_kernel_pytorch",
        "nightly_builds": true,
        "fbpkg_supported": true,
        "is_prebuilt": true
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "last_server_session_id": "35724094-1d32-49ea-ab05-98e6afcfdb46",
    "last_kernel_id": "5fe46811-517d-49d4-b7eb-f786e866096b",
    "last_base_url": "https://devvm3095.ftw0.facebook.com:8090/",
    "last_msg_id": "597f30d4-eec31cd683f030f845cb5276_5418",
    "captumWidgetMessage": {},
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "originalKey": "668d427a-0f72-4272-a69d-04d355a30268",
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "e02fa667-6a89-4894-8520-61066acfd87a",
        "executionStartTime": 1630727702784,
        "executionStopTime": 1630727702793
      },
      "source": [
        "import random\n",
        "from random import choice\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch as T\n",
        "device = T.device(\"cuda\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "837b5119-01cd-4ef5-ab13-9bfea06148fd",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "11a64636-aaee-4420-8d91-f07947205da4",
        "executionStartTime": 1630727702888,
        "executionStopTime": 1630727702896
      },
      "source": [
        "is16 = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "30157177-0cc8-42c7-9242-1aa3a8c032b1",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "e5165ba9-879f-4824-b1b8-5b0a5c5c8016",
        "executionStartTime": 1630727702996,
        "executionStopTime": 1630727703002,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class FinalEmbedding:\n",
        "    def __init__(self,x,y):\n",
        "        self.x_data = x\n",
        "        self.y_data = y\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        preds = self.x_data[idx]\n",
        "        trgts = self.y_data[idx] \n",
        "        sample = { \n",
        "        'predictors' : preds,\n",
        "        'targets' : trgts\n",
        "        }\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "8726406d-f512-4906-839c-243c7eae3052",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "6f82f014-3cbe-4a1c-89c3-35ccf3ffa40b",
        "executionStartTime": 1630727703109,
        "executionStopTime": 1630727703116
      },
      "source": [
        "from iopath.common.file_io import PathManager\n",
        "from iopath.fb.manifold import ManifoldPathHandler\n",
        "\n",
        "def load_checkpoint(checkpoint_path, map_location=None):\n",
        "    pm = PathManager()\n",
        "    pm.register_handler(ManifoldPathHandler())\n",
        "    with pm.open(checkpoint_path, \"rb\") as f:\n",
        "        if map_location is not None:\n",
        "            checkpoint = torch.load(f, map_location=map_location)\n",
        "        else:\n",
        "            checkpoint = torch.load(f, map_location=lambda storage, loc: storage)\n",
        "    return checkpoint\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "cb50dc9d-7dd4-43f7-8b8f-5bcc9eaaceb9",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "96d90ad8-cf9b-4ca0-8d8e-6a6e8f5b8b59",
        "executionStartTime": 1630730426983,
        "executionStopTime": 1630730427151
      },
      "source": [
        "api2indx = torch.load('Â api2indx.pt')\n",
        "api2indx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6a98ec39-b608-4f95-8efb-429d2611fe99",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "0438457a-df14-4f7e-b7c3-1c43771c338f",
        "executionStartTime": 1630727703237,
        "executionStopTime": 1630727703243,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class pycoder_parameters:\n",
        "\n",
        "    ''' Core Fuzzing Parameters '''\n",
        "    NUM_FUZZ_PER_API= 100001 #000\n",
        "    NUM_TEST_FUZZ = 2\n",
        "    FLOAT_TENSOR = False #We either generate float or integer tensors\n",
        "    UNIT_TEST = False\n",
        "    COMPOSITE = True\n",
        "\n",
        "    ''' Fuzzing Detailed Parameters '''\n",
        "    MAX_TENSOR_DIMENSIONS = 3 #how many rows, columns, etc.\n",
        "    MIN_VAL_PER_DIMENSION = 1 # e.g., min number of rows, columns, etc. \n",
        "    MAX_VAL_PER_DIMENSION = 5 # e.g., max number of rows, columns, etc. \n",
        "\n",
        "    #So far limiting to integers\n",
        "    MIN_TENSOR_VALUE = 1\n",
        "    MAX_TENSOR_VALUE = 15\n",
        "    \n",
        "\n",
        "    ''' Embedding Parameters '''\n",
        "    EMBEDDING_NOISE_LEVEL = 0 #0 noise by default\n",
        "    EMBEDDING_SIZE = 150\n",
        "    SHAPE_EMBEDDING_SIZE = 6\n",
        "\n",
        "\n",
        "    data_type = 'float' if FLOAT_TENSOR is  True else 'integer'\n",
        "    model_type = 'Composite_' if COMPOSITE is  True else 'Single_'\n",
        "    file_name = str(model_type) + str(NUM_FUZZ_PER_API) + '_' + data_type\n",
        "    fuzzing   = file_name + '.pt'\n",
        "    embedding = file_name + '.embedding' + '.pt',\n",
        "    classification = file_name + '.model_result' + '.pt' \n",
        "    train_valid_test = file_name + 'train_valid_test.pt'\n",
        "\n",
        "    def setNoiseLevel(self, noise):\n",
        "        self.EMBEDDING_NOISE_LEVEL = noise\n",
        "        self.embedding = self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt'\n",
        "\n",
        "    def getEmbeddingFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt')\n",
        "\n",
        "    def getVisulizationFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '_' +  'tSNE.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b406ce8b-2e2f-4301-8276-82a7c84533f6",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "b3a09398-1f62-421d-874b-47b70d947792",
        "executionStartTime": 1630727703252,
        "executionStopTime": 1630727703267,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "NOISE = 0\n",
        "f = pycoder_parameters()\n",
        "f.setNoiseLevel(NOISE)\n",
        "f.embedding = f.getEmbeddingFile() \n",
        "print(f.embedding)\n",
        "print(f.SHAPE_EMBEDDING_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "049bb1f9-af4b-4a08-b522-601462a658dd",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "5a365888-2d95-40a7-9008-f3cbc7c85b24",
        "executionStartTime": 1630727703270,
        "executionStopTime": 1630727703277,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "import sklearn.datasets\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "EMBEDDING_SIZE = f.EMBEDDING_SIZE\n",
        "SHAPE_EMBEDDING_SIZE = f.SHAPE_EMBEDDING_SIZE\n",
        "\n",
        "def encode_values_to_code(tensor):\n",
        "    tensor = tensor.clone()\n",
        "    tensor[(tensor>=100) & (tensor<1000)] = 100\n",
        "    tensor[(tensor>=1000)] = 101\n",
        "    tensor[(tensor<=-20) & (tensor>-100)] = -20\n",
        "    tensor[(tensor<=-100) & (tensor>-1000)] = -21\n",
        "    tensor[(tensor<=-1000)] = -22\n",
        "    return tensor\n",
        "\n",
        "def tensor_flatten_pad(tensor, embed_size=EMBEDDING_SIZE, shape_embed_size=SHAPE_EMBEDDING_SIZE, isNoise=False):\n",
        "    \n",
        "    t_flatten = torch.flatten(tensor)\n",
        "    padding_length = embed_size - list(t_flatten.shape)[-1]\n",
        "    p1d = (0,padding_length) #just padding the last dimension\n",
        "    t_pad = F.pad(input=t_flatten, pad=p1d, mode='constant', value=0).type(torch.FloatTensor)\n",
        "    \n",
        "    type_padding = 0\n",
        "    if tensor.dtype == torch.bool:\n",
        "        type_padding = 1\n",
        "        #print('Bool')\n",
        "    elif tensor.dtype == torch.float64 \\\n",
        "        or tensor.dtype == torch.double \\\n",
        "        or tensor.dtype == torch.float32 \\\n",
        "        or tensor.dtype == torch.float16:\n",
        "            type_padding = 2\n",
        "\n",
        "    \n",
        "    \n",
        "    '''size embedding'''\n",
        "    if(shape_embed_size > 0):\n",
        "        t_shape = list(tensor.shape)\n",
        "        padding_length = shape_embed_size -1 - len(t_shape)\n",
        "        p1d = (0,padding_length) #just padding the last dimension\n",
        "        s_pad = F.pad(input=torch.Tensor(t_shape), pad=p1d, mode='constant', value=0).type(torch.float)\n",
        "\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        s_pad_list = s_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1] + s_pad_list + [-1])\n",
        "    \n",
        "    else:\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1])\n",
        "        \n",
        "    encoded_tensor = encode_values_to_code(tensor_embedding)\n",
        "    return(encoded_tensor)\n",
        "\n",
        "'unit test'\n",
        "t1 = torch.tensor([[[1,2,3]],[[4,555,6]]])\n",
        "tf = tensor_flatten_pad(t1, shape_embed_size=5, isNoise=True)\n",
        "print(tf, tf.shape)\n",
        "\n",
        "t2 = torch.tensor([[[True,False,True]],[[True,True,False]]])\n",
        "tf1 = tensor_flatten_pad(t2, shape_embed_size=0)\n",
        "print(tf1, tf1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "14a1958d-9842-43ec-88a2-52b37e86094f",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "bc0a5653-bca6-4bd7-afbc-687854565123",
        "executionStartTime": 1630727703284,
        "executionStopTime": 1630727703289,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def embed_tensors(data_list):\n",
        "       \n",
        "    global EMBEDDING_SIZE\n",
        "    global api2indx\n",
        "    \n",
        "    X=[]\n",
        "    y=[]\n",
        "\n",
        "    all_input_output_tensors = set()\n",
        "    duplicate_count = 0\n",
        "\n",
        "    dict_indx = len(api2indx)\n",
        "\n",
        "    final_output = data_list[-1][1]\n",
        "\n",
        "    prev_out = torch.Tensor()\n",
        "    \n",
        "    api_seq_x = []\n",
        "    api_seq_y = []\n",
        "\n",
        "    for data in data_list:\n",
        "        api = data[0]\n",
        "        api_indx = api2indx[api]\n",
        "        \n",
        "        input_list = data[2] #.get_input()\n",
        "        output_tensor = final_output #data.get_output()\n",
        "        \n",
        "        it_pad = []\n",
        "\n",
        "        for input_tensor in input_list:\n",
        "            if input_tensor.shape == prev_out.shape and torch.all(input_tensor.eq(prev_out)).item():\n",
        "                t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                t[-1] = -1\n",
        "                it_pad.append(t)\n",
        "            else:         \n",
        "                #flatten the input tensor\n",
        "                it_pad.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "            \n",
        "        \n",
        "        #adding addidional tensors with zero embeddings for < 2 tensors\n",
        "        for i in range(len(it_pad),3):\n",
        "            t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "            t[-1] = -1\n",
        "            it_pad.append(t)\n",
        "       \n",
        "        ot_pad = tensor_flatten_pad(output_tensor, isNoise=True)\n",
        "\n",
        "        x = T.flatten(T.stack((it_pad[0],it_pad[1], it_pad[2], ot_pad)))\n",
        "\n",
        "\n",
        "        xl = (x,api_indx)\n",
        "        \n",
        "        if xl in all_input_output_tensors:\n",
        "            duplicate_count += 1\n",
        "        else:\n",
        "            all_input_output_tensors.add(xl)\n",
        "\n",
        "    \n",
        "        api_seq_x.append(x) \n",
        "        api_seq_y.append(api_indx)\n",
        "\n",
        "        prev_out = data[1]\n",
        "\n",
        "    X.append(api_seq_x)\n",
        "    y.append(api_seq_y)\n",
        "    \n",
        "    return(X,y)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6e66ee1e-fff6-4f2f-959d-5c8d29e2d536",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "c90896e7-2edb-4833-94ae-56c102a4d394",
        "executionStartTime": 1630727703478,
        "executionStopTime": 1630727703491
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "01c0045d-86e4-455d-9452-e3d62fc4b757",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "3f9adcf2-d341-4149-92a4-8872f48b9c7c",
        "executionStartTime": 1630727703501,
        "executionStopTime": 1630727703506,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def process_dataX(tensor_list):\n",
        "    \n",
        "    #print(tensor_list)\n",
        "    io_seq = []\n",
        "    \n",
        "    n0 = tensor_list[0]\n",
        "\n",
        "    if(len(tensor_list) == 1):\n",
        "        n1 = torch.zeros(n0.shape)\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "        \n",
        "    elif(len(tensor_list) == 2):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "\n",
        "    elif(len(tensor_list) == 3):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = tensor_list[2]\n",
        "\n",
        "        \n",
        "    new_list = torch.stack((n0, n1, n2))\n",
        "\n",
        "    io_seq.append(new_list)\n",
        "    \n",
        "    return(torch.stack(io_seq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "2780856a-e54b-41e4-847e-086b02c5a541",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "f41bf315-8f04-4747-9786-2f7a6bc658ca",
        "executionStartTime": 1630727703515,
        "executionStopTime": 1630727703626,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "indx2api = {}\n",
        "EOS = '<eol>'\n",
        "\n",
        "def process_dataY(api_seq):\n",
        "    global indx2api\n",
        "    global api2indx\n",
        "\n",
        "    ''' Add <eol> to the dictionary '''\n",
        "    indx2api = {v: k for k, v in api2indx.items()}\n",
        "\n",
        "    if api2indx.get(EOS, -1) == -1:\n",
        "        max_key = max(indx2api.keys())\n",
        "        print(max_key)\n",
        "        indx2api[max_key+1] = EOS\n",
        "        api2indx[EOS] = max_key+1\n",
        "\n",
        "    eos = api2indx[EOS]\n",
        "\n",
        "    api_tensors = []\n",
        "\n",
        "\n",
        "    api0 = api_seq[0]\n",
        "\n",
        "    if len(api_seq) == 1:\n",
        "        api1 = eos\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 2:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 3:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = api_seq[2]\n",
        "\n",
        "    else:\n",
        "        print('!!! Not supposed to be here')\n",
        "\n",
        "    t = torch.tensor([api0, api1, api2])\n",
        "    api_tensors.append(t)\n",
        "    \n",
        "    return(torch.stack(api_tensors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "debb723f-b63b-4bb8-a102-f5f5097d7c83",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "0d1742fd-1704-4ee0-94dc-a8f2d1b5d226",
        "executionStartTime": 1630727703754,
        "executionStopTime": 1630727703811,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, bidirectional=True)   \n",
        "        \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        #Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        \n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        \n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out1 = out.contiguous().view(-1, self.hidden_dim*2)\n",
        "        out1 = self.fc(out1)\n",
        "        \n",
        "        return out1, hidden, out\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        hidden = torch.zeros(self.n_layers*2, batch_size, self.hidden_dim).to(device)\n",
        "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "642fc079-bc0e-4663-b16f-794c3824cade",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "a3ae1269-8e10-4f57-9feb-1fc615f2cfba",
        "executionStartTime": 1630727703821,
        "executionStopTime": 1630727703827
      },
      "source": [
        "class FFNet(T.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FFNet, self).__init__()\n",
        "\n",
        "    self.hid1 = T.nn.Linear(4*(f.EMBEDDING_SIZE+f.SHAPE_EMBEDDING_SIZE+1+2), 500)\n",
        "    self.hid2 = T.nn.Linear(500, 250)\n",
        "    self.hid3 = T.nn.Linear(250, 100)\n",
        "    self.oupt = T.nn.Linear(100, len(api2indx))\n",
        "\n",
        "    T.nn.init.xavier_uniform_(self.hid1.weight)\n",
        "    T.nn.init.zeros_(self.hid1.bias)\n",
        "    T.nn.init.xavier_uniform_(self.hid2.weight)\n",
        "    T.nn.init.zeros_(self.hid2.bias)\n",
        "    T.nn.init.xavier_uniform_(self.oupt.weight)\n",
        "    T.nn.init.zeros_(self.oupt.bias)\n",
        "\n",
        "    T.nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    z1 = T.tanh(self.hid1(x))\n",
        "    z2 = T.tanh(self.hid2(z1))\n",
        "    z3 = T.tanh(self.hid3(z2))\n",
        "    z = self.oupt(z3)  # no softmax: CrossEntropyLoss() \n",
        "    return (z, z3, z2, z1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "e5b75496-a745-452e-8d35-9373bfdc0920",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "4fe84ec4-1030-4879-9d55-0841f2552305",
        "executionStartTime": 1630727704063,
        "executionStopTime": 1630727704070
      },
      "source": [
        "DEBUG = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a2bf12d5-a7bc-434f-9de9-a5647e773f45",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ab9fd814-c692-468f-b082-45175ee4e84f",
        "executionStartTime": 1630727704078,
        "executionStopTime": 1630727704172
      },
      "source": [
        "def embed_tensor_for_model(domain_io):\n",
        "\n",
        "    x, y = embed_tensors(domain_io)\n",
        "    \n",
        "    X = process_dataX(x[0])\n",
        "    Y = process_dataY(y[0])\n",
        "    ds = FinalEmbedding(X,Y)\n",
        "\n",
        "    X = ds[0]['predictors'].to(device)\n",
        "    Y = ds[0]['targets'].to(device)  # [0] [1] or [2]\n",
        "\n",
        "    return(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f6667502-0d2e-4635-84e7-11077a89399d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "56ec6a7e-99c7-4fa6-8f91-9db55d86fc62",
        "executionStartTime": 1630727704268,
        "executionStopTime": 1630727704348
      },
      "source": [
        "def beam_search(top3_list):\n",
        "\n",
        "    api_seq = []\n",
        "    api_seq1 = []\n",
        "    for i in top3_list[0]:\n",
        "        for j in top3_list[1]:\n",
        "            api_seq1.append(((i[0], j[0]), i[1]*j[1]))\n",
        "    \n",
        "    api_seq1.sort(key = lambda x: x[1], reverse=True) \n",
        "\n",
        "    for k in top3_list[2]:\n",
        "        for s1 in api_seq1:\n",
        "            api_seq.append(((s1[0][0], s1[0][1], k[0]), s1[1]*k[1]))\n",
        "\n",
        "    api_seq.sort(key = lambda x: x[1], reverse=True) \n",
        "    \n",
        "    return(api_seq)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "0be1d328-4d66-4a8e-b9c2-3b674ad94320",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "cd313246-2c16-4665-9ce5-b17ab081a164",
        "executionStartTime": 1630727704360,
        "executionStopTime": 1630727704457
      },
      "source": [
        "total_correct = {}\n",
        "seq_len_correct = {}\n",
        "seq_len_total = {}\n",
        "total_benchmark = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "069b18b8-c5e3-4432-bfac-2ea9b674d7f5",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "dadaba3a-5c26-485f-b80b-941683b50d47",
        "executionStartTime": 1630727704467,
        "executionStopTime": 1630727704549
      },
      "source": [
        "def reset_stat():\n",
        "    global total_correct\n",
        "    global seq_len_correct\n",
        "    global seq_len_total\n",
        "    global total_benchmark\n",
        "    \n",
        "    total_correct = {}\n",
        "    seq_len_correct = {}\n",
        "    seq_len_total = {}\n",
        "    total_benchmark = 0\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "fdc8eb07-e737-4f36-9216-a21f56b8a5a9",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "0d6b9f78-b86a-4db5-a522-014c5e64542e",
        "executionStartTime": 1630730448402,
        "executionStopTime": 1630730448412
      },
      "source": [
        "reset_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f794cd50-4661-43e7-a6da-341574304dc4",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "68eaf507-8d5d-49b7-bcf6-d39907d51f38",
        "executionStartTime": 1630730449466,
        "executionStopTime": 1630730449481
      },
      "source": [
        "def print_stat():\n",
        "    print('total_correct', total_correct)\n",
        "    print('seq_len_correct', seq_len_correct)\n",
        "    print('seq_len_total', seq_len_total)\n",
        "    print('total_benchmark', total_benchmark)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c2d403c1-9ff4-45ca-b9ba-e9a8ac6d43dc",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "d47fffb6-2472-4ec8-93e6-d04a4c26b580",
        "executionStartTime": 1630730450578,
        "executionStopTime": 1630730450691
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "800d2ccd-7166-4494-b420-386c19d120ef",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "95d59c5f-efd7-4687-9c9c-7adb8a237913",
        "executionStartTime": 1630746426177,
        "executionStopTime": 1630746426183
      },
      "source": [
        "def query_model(X, Y):\n",
        "    \n",
        "    global total_benchmark\n",
        "    with T.no_grad():\n",
        "      start_time = time.time()\n",
        "      predicts, z3, z2, z1 = net(X)\n",
        "      temp_z3 = torch.unsqueeze(z3,0)\n",
        "      model_output, hidden, int_output = rnn_model(temp_z3)\n",
        "\n",
        "      target_list = list(Y.cpu().numpy())\n",
        "    \n",
        "    top_indx = []\n",
        "\n",
        "    top3_list = []\n",
        "\n",
        "    print('---- Top-k ----')\n",
        "    for i, m in enumerate(model_output):\n",
        "        top3 = []\n",
        "        prob = nn.functional.softmax(m, dim=0).data\n",
        "        # Taking the class with the highest probability score from the output\n",
        "        xx = torch.topk(prob,5,dim=0)[1]\n",
        "        for x in xx.cpu().numpy():\n",
        "          print(indx2api[x])\n",
        "          top3.append((indx2api[x], prob[x].item()))\n",
        "        top3_list.append(top3)\n",
        "        print('====')\n",
        "        \n",
        "    print('---- Predicted ----')\n",
        "    for m in model_output:\n",
        "        prob = nn.functional.softmax(m, dim=0).data\n",
        "        api_ind = torch.max(prob, dim=0)[1].item()\n",
        "        top_indx.append(api_ind)\n",
        "        if DEBUG:\n",
        "            print(indx2api[api_ind], prob[api_ind])\n",
        "\n",
        "\n",
        "    print('---- Expected ----')\n",
        "    seq_len = 0\n",
        "    for o in list(Y):\n",
        "        if o.item() != len(api2indx)-1:\n",
        "          seq_len += 1\n",
        "        print(indx2api[o.item()])\n",
        "    print('seq length', seq_len)\n",
        "    if seq_len_correct.get(seq_len, -1) == -1:\n",
        "      seq_len_correct[seq_len] = 0\n",
        "      seq_len_total[seq_len] = 0\n",
        "    \n",
        "    seq_len_total[seq_len] += 1\n",
        "    total_benchmark += 1\n",
        "\n",
        "    o = list(Y)\n",
        "    expected = ((indx2api[o[0].item()], indx2api[o[1].item()], indx2api[o[2].item()]))\n",
        "    \n",
        "    top3_list = beam_search(top3_list)\n",
        "    for i,t in enumerate(top3_list):\n",
        "      if t[0] == expected:\n",
        "        print(i+1, t[0], '\\t***MATCH')\n",
        "        if total_correct.get(i+1, -1) == -1:\n",
        "          total_correct[i+1] = 0\n",
        "        total_correct[i+1] += 1\n",
        "        seq_len_correct[seq_len] += 1\n",
        "        break\n",
        "      else:\n",
        "        print(t[0])\n",
        "    return(top3_list)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "fbca7f5a-2087-4189-a675-02d0f6a18ff2",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "4ff6906e-ad33-4018-bbeb-5dfcdeaf786f",
        "executionStartTime": 1630727705054,
        "executionStopTime": 1630727705197,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def api_edit_distance(seq1, seq2):\n",
        "\n",
        "    edit_distantce = 0\n",
        "\n",
        "    for i in range(len(seq1)):\n",
        "        if seq1[i] != seq2[i]:\n",
        "            edit_distantce += 1\n",
        "\n",
        "    return(edit_distantce)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b898e38b-c10c-437e-9850-5fecf1d6ef00",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ed2d542b-56ff-4d73-a19c-cf47e8825596",
        "executionStartTime": 1630746743050,
        "executionStopTime": 1630746743059
      },
      "source": [
        "net = torch.load('net_model.pt')\n",
        "rnn_model = torch.load('rnn_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7855ce6a-2401-43b7-b7fb-46496c827f2d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "d1cf4971-85fc-4161-986d-9e96474d240d",
        "executionStartTime": 1630746745181,
        "executionStopTime": 1630746745238
      },
      "source": [
        "reset_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b74e9fce-a6bb-4968-ac2f-ccb2dc90c860",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "53f13a9d-5e55-4097-8377-da4e9f5a08c6",
        "executionStartTime": 1630746746293,
        "executionStopTime": 1630746746415
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "2f7b8ca2-7dab-42c7-850d-a2f8e502de4e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "4afefb8e-b2ed-46ba-a5f8-f10a8c278d38",
        "executionStartTime": 1630746749628,
        "executionStopTime": 1630746749730
      },
      "source": [
        "def Composite01():\n",
        "    in1 = torch.tensor([[5, 2], [1, 3], [0, 2]])\n",
        "    out_orig = torch.tensor([[[5, 5], [1, 1], [0, 0]],\n",
        "                                [[2, 2], [3, 3], [2, 2]]])                            \n",
        "    out = torch.transpose(in1.expand((2, 3, 2)), 0, 2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(in1, out))\n",
        "    \n",
        "    domain_io = []\n",
        "    domain_io.append(['expand', in1.expand((2, 3, 2)), [in1]])\n",
        "    domain_io.append(['transpose', out, [in1.expand((2, 3, 2))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "        \n",
        "Composite01()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1d23d4f4-f651-476a-be4f-b647a94cdbb7",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "786f1e16-4100-40c4-aa26-673cc14b25b3",
        "executionStartTime": 1630746755015,
        "executionStopTime": 1630746755136
      },
      "source": [
        "def Composite02():\n",
        "    domain_inpt10 = torch.tensor([5, 1, 0, 3, 0, 0, 2, 0, 2])\n",
        "    domain_out10 = torch.lt(domain_inpt10, 1)\n",
        "    \n",
        "    domain_inpt20 = domain_out10\n",
        "    domain_inpt21 = domain_inpt10\n",
        "\n",
        "    domain_output_orig = torch.tensor([1, 1, 0, 1, 0, 0, 1, 0, 1])\n",
        "    domain_output = torch.where(domain_inpt20, domain_inpt21, 1)\n",
        "\n",
        "    print('domain_inpt10 : ', domain_inpt10, domain_inpt10.shape)\n",
        "    print('domain_inpt20 : ', domain_inpt20, domain_inpt20.shape)\n",
        "    print('domain_output : ', domain_output, domain_output.shape)\n",
        "    print(torch.equal(domain_output, domain_output_orig))\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['lt', domain_inpt20, [domain_inpt10, torch.tensor(1)]])\n",
        "    domain_io.append(['where', domain_output, [domain_inpt20, domain_inpt21, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite02()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "757e39bc-bff7-4d5e-aef2-08a379d235b6",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "712c11a8-501e-4a7c-aa5d-72cf18f39c1d",
        "executionStartTime": 1630746760452,
        "executionStopTime": 1630746760570
      },
      "source": [
        "def Composite05():\n",
        "    in1 = torch.tensor([[4, 3, 1], [6, 5, 2]])\n",
        "    in2 = torch.tensor([[[5, 5]], [[1, 5]], [[6, 0]]])\n",
        "    output_orig = torch.tensor([[[29, 35]], [[47, 55]]])\n",
        "    output = torch.tensordot(in1, in2, 1)\n",
        "    \n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output_orig, output))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', output, [in1, in2]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite05()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "56cf2e91-497e-4e24-9aed-6a59b42c6e77",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5c6bb36c-782e-4261-a239-ba993753f934",
        "executionStartTime": 1630746763296,
        "executionStopTime": 1630746763476
      },
      "source": [
        "def Composite06():\n",
        "    in1 = torch.tensor([3, 5, 0, 2, 3, 3, 0])\n",
        "    in2 = torch.unsqueeze(in1, 1)\n",
        "    output_orig = torch.tensor([\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
        "                [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
        "            ]).int()\n",
        "    output = torch.eq(in1, in2).int()\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['unsqueeze', torch.unsqueeze(in1, 1), [in1]])\n",
        "    domain_io.append(['eq', torch.eq(in1, in2), [in1, torch.unsqueeze(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite06()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "585063b6-6e36-4d14-8078-8cfbbb0d2f70",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "198c8f75-3712-47ea-8381-0fc7dc175e6f",
        "executionStartTime": 1630746770257,
        "executionStopTime": 1630746770278
      },
      "source": [
        "def Composite07():\n",
        "    in1 = torch.tensor([\n",
        "                    [[8, 4, 6], [2, 12, 3]],\n",
        "                    [[11, 12, 5], [9, 12, 12]],\n",
        "                    [[9, 2, 13], [7, 0, 7]],\n",
        "                    [[2, 10, 5], [7, 1, 2]],\n",
        "                ])\n",
        "    output_orig = torch.tensor([\n",
        "                [[8, 4, 6], [11, 12, 5], [9, 2, 13], [2, 10, 5]],\n",
        "                [[2, 12, 3], [9, 12, 12], [7, 0, 7], [7, 1, 2]],\n",
        "            ])\n",
        "    output = torch.transpose(in1, 0, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', output, [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite07()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "51a8a190-3a0c-4152-a88b-5ac1128ff3ef",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "cb1eef97-7c47-497d-95ca-7d93c6b3713f",
        "executionStartTime": 1630746772920,
        "executionStopTime": 1630746773079
      },
      "source": [
        "def Composite08():\n",
        "    # in1 = torch.tensor([-1, 0, -3, 2, 1, 3, 5, -1, -9, 2, 10])\n",
        "    in1 = torch.tensor([1, 0, 0, 2, 1, 3, 5, 0, 1, 2, 10])\n",
        "    in2 = torch.tensor([12, 3, 45, 6, 7, 8, 9, 87, 65, 4, 32])\n",
        "    in3 = torch.gt(in1, 1)\n",
        "    output_orig = torch.tensor([6, 8, 9, 4, 32])\n",
        "    output = torch.masked_select(in2, torch.gt(in1, 1))\n",
        "\n",
        "    print('in1: ', in1, in1.shape, in1.dtype)\n",
        "    print('in2: ', in2, in2.shape, in2.dtype)\n",
        "    print('in3: ', in2, in2.shape, in2.dtype)\n",
        "    print('output', output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []   \n",
        "    domain_io.append(['gt', torch.gt(in1, 1), [in1, torch.tensor(1)]])\n",
        "    domain_io.append(['masked_select', torch.masked_select(in2, torch.gt(in1, 1)), [in2, torch.gt(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite08()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "bb8d967b-1c4b-4a06-8b05-56204c074a62",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a683775a-737d-4621-95d7-914934643940",
        "executionStartTime": 1630746777946,
        "executionStopTime": 1630746778087
      },
      "source": [
        "def Composite11():\n",
        "    in1 = torch.tensor([4, 0, 1, 1, 0, 4, 0, 0, 3, 4, 1])\n",
        "    out_orig = torch.tensor([4, 3, 0, 1, 3])\n",
        "    out = torch.bincount(in1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['bincount', torch.bincount(in1), [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite11()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "469f2845-ebcd-4af4-b576-3eda8e545939",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c6a035b9-e406-416d-83cd-380c3358b5f4",
        "executionStartTime": 1630746781517,
        "executionStopTime": 1630746781622
      },
      "source": [
        "def Composite13():\n",
        "    in1 = torch.tensor([[3, 5], [10, 2]])\n",
        "    in2 = torch.tensor([[[1, 0], [5, 4]], [[3, 10], [2, 0]]])\n",
        "    in3 = torch.matmul(in1, in2)\n",
        "    out_orig = torch.tensor([[[28, 20], [19, 30]], [[20, 8], [34, 100]]])\n",
        "    out = torch.transpose(torch.matmul(in1, in2), 0, 1)\n",
        "\n",
        "    print('in1 : ', in1, in1.shape, in1.dtype)\n",
        "    print('in2 : ', in2, in2.shape, in2.dtype)\n",
        "    print('in3 : ', in3, in3.shape, in3.dtype)\n",
        "    print('output : ', out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['matmul', torch.matmul(in1, in2), [in1, in2]])\n",
        "    domain_io.append(['transpose', torch.transpose(torch.matmul(in1, in2), 0, 1), [torch.matmul(in1, in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite13()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a672a810-0ee0-4ac2-905a-6cce82c61afd",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "d010c5bd-68c6-476d-bd3a-d719b72ac1e3",
        "executionStartTime": 1630746787031,
        "executionStopTime": 1630746787167
      },
      "source": [
        "def Composite14():\n",
        "    in1 = torch.tensor([\n",
        "                    [\n",
        "                        [False, False, True],\n",
        "                        [False, False, False],\n",
        "                        [True, False, True],\n",
        "                        [False, True, False],\n",
        "                        [False, False, False],\n",
        "                        [True, True, True],\n",
        "                        [True, True, False],\n",
        "                    ]\n",
        "                ]).int()\n",
        "    out_orig = torch.tensor([[True, False, True, True, False, True, True]]).int()\n",
        "    out = torch.any(in1, -1).int()\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['any', torch.any(in1, -1), [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite14()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4a059d4a-7671-4a77-9835-fa56b6cb3151",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "dbd16717-2579-465d-95d4-014eb87e9de0",
        "executionStartTime": 1630746792924,
        "executionStopTime": 1630746793030
      },
      "source": [
        "def Composite15():\n",
        "    in1 = torch.tensor([3, 1, 2, 0, 1, 0, 10, 1, 0])\n",
        "    out_orig = torch.tensor([3, 0, 2, 0, 0, 0, 10, 0, 0])\n",
        "    out = torch.mul(in1, torch.ne(in1, 1)) \n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['ne', torch.ne(in1, 1), [in1, torch.tensor(1)]])\n",
        "    domain_io.append(['mul', torch.mul(in1, torch.ne(in1, 1)), [in1, torch.ne(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite15()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "bab969d1-ac8d-4af8-8dda-eb9653578de8",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a9a2133d-f50e-4919-b3a2-68b9e168ce45",
        "executionStartTime": 1630746800243,
        "executionStopTime": 1630746800277
      },
      "source": [
        "def Composite16():\n",
        "    in1 = torch.tensor([[2, 5], [3, 0], [8, 7]])\n",
        "    in2 = torch.tensor([4, 10, 6])\n",
        "    out_orig = torch.tensor([[8, 20], [30, 0], [48, 42]])\n",
        "    out = torch.mul(in1, torch.unsqueeze(in2, 1))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = [] \n",
        "    domain_io.append(['unsqueeze', torch.unsqueeze(in2, 1), [in2]])\n",
        "    domain_io.append(['mul', torch.mul(in1, torch.unsqueeze(in2, 1)), [in1,torch.unsqueeze(in2, 1)]])    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "63c9b411-aa58-4f4c-a3bb-55ca12d6382a",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2d7099b2-6e7d-4abb-9441-987f22c486ad",
        "executionStartTime": 1630746804099,
        "executionStopTime": 1630746804270
      },
      "source": [
        "def Composite17():\n",
        "    in1 = torch.tensor([17, 32, 99])\n",
        "    out_orig = torch.tensor([[17, 17], [32, 32], [99, 99]])\n",
        "    out = torch.stack((in1, in1), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []    \n",
        "    domain_io.append(['stack', out, [in1, in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite17()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "aa72a222-7f6c-4f83-9c65-914ae77c80d4",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a9e90500-ed9f-4f6c-97a9-736776261172",
        "executionStartTime": 1630746807398,
        "executionStopTime": 1630746807421
      },
      "source": [
        "def Composite18():\n",
        "    in1 = torch.tensor([[[1, 1, 1], [1, 0, 1]], [[1, 2, 3], [4, 5, 6]]])\n",
        "    in2 = torch.tensor([[1, 1, 1, 1], [1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "    in3 = torch.tensor([100, 200, 300, 400])\n",
        "    in4 = torch.matmul(in1, in2)\n",
        "\n",
        "    out_orig = torch.tensor([\n",
        "                [[107, 209, 311, 413], [106, 207, 308, 409]],\n",
        "                [[118, 223, 328, 433], [139, 250, 361, 472]],\n",
        "            ])\n",
        "    out = torch.add(in3, torch.matmul(in1, in2))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(in3, in3.shape, in3.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['matmul', torch.matmul(in1, in2), [in1, in2]])\n",
        "    domain_io.append(['add', out, [in3, torch.matmul(in1, in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite18()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b6352065-dc15-41f2-adf7-0300aef7ad57",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8a671b90-7048-45de-8eb8-8c8ea2419c43",
        "executionStartTime": 1630746812636,
        "executionStopTime": 1630746812789
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite20():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([\n",
        "                    [7, 2, 1],\n",
        "                    [4, 5, 1],\n",
        "                    [4, 4, 2],\n",
        "                    [3, 4, 3],\n",
        "                    [0, 0, 1],\n",
        "                ])\n",
        "    out_orig = torch.tensor([[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "    out = torch.nn.functional.one_hot(torch.argmax(in1, 1), 3)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['argmax', torch.argmax(in1, 1), [in1]])\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(torch.argmax(in1, 1),3), [torch.argmax(in1, 1), torch.tensor(3)]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite20()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a057afc0-8e78-4a2a-b9ac-1cf0101c4bc2",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "77d212c5-38bd-4de2-8c27-26c31477a77a",
        "executionStartTime": 1630746815379,
        "executionStopTime": 1630746815491
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite21():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[2], [0], [1], [0]])\n",
        "    in2 = torch.tensor([[2, 5, 3], [1, 3, 6], [1, 6, 3], [7, 0, 3]])\n",
        "    out_orig = torch.tensor([[3], [1], [6], [7]])\n",
        "    out = torch.gather(in2, 1, in1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['gather', out, [in2, in1]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite21()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "85f054db-fe70-4352-a069-518db185c47a",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "9d187c7f-cd1a-4b8f-9182-d86ba50c9d35",
        "executionStartTime": 1630746819327,
        "executionStopTime": 1630746819443
      },
      "source": [
        "def Composite22():\n",
        "    in1 = torch.tensor([3, 1, 10])\n",
        "    in2 = torch.tensor([[6, 4], [5, 1], [3, 4]])\n",
        "    out_orig = torch.tensor([53, 53])\n",
        "    out = torch.tensordot(in1, in2, 1 )\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite22()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a490787f-e031-478e-a850-759178b5ec19",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "f7b49a7d-6b5d-4859-acea-2fea99b6b254",
        "executionStartTime": 1630746822943,
        "executionStopTime": 1630746823096
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite23():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[0, 5, 2], [3, 1, 4], [5, 1, 5]])\n",
        "    out_orig = torch.tensor([\n",
        "                [1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
        "                [0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
        "                [0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "            ])\n",
        "    out = torch.max(torch.nn.functional.one_hot(in1, 9), 1)[0]\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(in1, 9), [in1, torch.tensor(9)]])\n",
        "    domain_io.append(['sum', torch.sum(torch.nn.functional.one_hot(in1, 9), 1), [torch.nn.functional.one_hot(in1, 9)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite23()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "01c6e0ac-35a0-4e28-b301-02debec25715",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "3b8ce18a-2599-475a-b34f-98b121e7854f",
        "executionStartTime": 1630746829205,
        "executionStopTime": 1630746829318
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite24():\n",
        "  if is16 == True:\n",
        "        return\n",
        "  in1 = torch.tensor([3, 1, 4, 5, 2, 8, 6, 7])\n",
        "  in2 = 0\n",
        "  in3 = torch.tensor([1, 0, 2, 0, 1, 1, 0, 2])\n",
        "  out_orig = torch.tensor([3, 1, 2, 5, 2, 8, 6, 3.5])\n",
        "  out = torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float())\n",
        "\n",
        "  print(in1, in1.shape, in1.dtype)\n",
        "  print(in2)\n",
        "  print(in3, in3.shape, in3.dtype)\n",
        "  print(out, out.shape)\n",
        "  print(torch.equal(out, out_orig))\n",
        "\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['ne', torch.ne(in3, in2), [in3, torch.tensor(in2)]])\n",
        "  domain_io.append(['div', torch.div(in1, in3), [in1, in3]])\n",
        "  domain_io.append(['where', torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float()), [torch.ne(in3, in2), torch.div(in1, in3), in1]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "Composite24()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "e2627384-5c8b-4209-82f6-579bff8305d7",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "28a9c23c-30ef-4f55-8a96-1e546c92cc45",
        "executionStartTime": 1630746839356,
        "executionStopTime": 1630746839459
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIS\n",
        "def Composite25():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    out_orig = torch.tensor([\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "            ]).int()\n",
        "    out = torch.tile(torch.eye(3), (4, 1)).int()\n",
        "\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['eye', out, []])\n",
        "    domain_io.append(['tile', torch.tile(torch.eye(3), (4, 1)), [torch.eye(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite25()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "88c75b0a-f8e0-4e88-aea6-d2703d0eb00f",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ae1b37db-53ae-4bc6-8f8e-a8d97f7b82c0",
        "executionStartTime": 1630746849028,
        "executionStopTime": 1630746849141
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite26():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[[3, 4], [1, 2]], [[5, 2], [10, 3]], [[10, 20], [4, 7]]])\n",
        "    out_orig = torch.tensor([10, 20, 41])\n",
        "    out = torch.sum(torch.sum(in1, 1), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['sum', torch.sum(in1, 1), [in1]])\n",
        "    domain_io.append(['sum', torch.sum(torch.sum(in1, 1), 1), [torch.sum(in1, 1)]])\n",
        "\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Composite26()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9d465f7d-5abd-4953-a177-d0d28708dce1",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2c3a6ca6-337e-44b0-8d47-dbdaed2f63a3",
        "executionStartTime": 1630746852351,
        "executionStopTime": 1630746852467
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite27():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([0, 3, 5, 6])\n",
        "    out_orig = torch.tensor([1, 0, 0, 1, 0, 1, 1, 0])\n",
        "    out = torch.sum(torch.nn.functional.one_hot(in1, 8), 0)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(in1, 8), [in1, torch.tensor(8)]])\n",
        "    domain_io.append(['max', torch.max(torch.nn.functional.one_hot(in1, 8), 0)[0], [torch.nn.functional.one_hot(in1, 8)]])\n",
        "\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite27()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "dc1eae68-58af-40a1-b311-1a5bdb89ceb8",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "af7e2e00-668b-4181-ab91-3be1e8ed452e",
        "executionStartTime": 1630746537004,
        "executionStopTime": 1630746537110
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite29():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21])\n",
        "    in2 = torch.tensor([12, 0, 10, 23, 16])\n",
        "    out_orig = torch.tensor([6, 0, 5, 11, 8])\n",
        "    out = torch.searchsorted(in1, in2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['searchsorted', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite29()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "e01c490f-8174-4b1a-8616-2e8eb862ac84",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ecaaa5fb-6087-4743-b5a0-851a0f7e167b",
        "executionStartTime": 1630746540990,
        "executionStopTime": 1630746541172
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "import math\n",
        "def Composite30():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "    in2 = torch.tensor([[9.0, 4.0], [8.0, 5.0], [7.0, 6.0]])\n",
        "    out_orig = torch.tensor([[math.sqrt(68), math.sqrt(58), math.sqrt(52)],\n",
        "                  [math.sqrt(36), math.sqrt(26), math.sqrt(20)],\n",
        "                  [math.sqrt(20), math.sqrt(10), math.sqrt(4)]])\n",
        "    out = torch.cdist(in1, in2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['cdist', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite30()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a3408dca-3b9d-4570-97da-8296af2948b2",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b7825c19-23b1-4b0b-ba53-b5a00dd2aa3f",
        "executionStartTime": 1630746866357,
        "executionStopTime": 1630746866493
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite32():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[1, 6, 2, 1], [3, 1, 4, 2], [2, 1, 2, 5]])\n",
        "    out_orig = torch.tensor([13, 15, 20])\n",
        "    out = torch.tensordot(in1, torch.arange(4), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.arange(4), []])\n",
        "    domain_io.append(['tensordot', torch.tensordot(in1, torch.arange(4), 1), [in1, torch.arange(4)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite32()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ae9c5bcb-2549-4618-aa2e-4a4e612501c3",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7a2ed2f4-ce6d-4e94-8e88-2ed33d4f4787",
        "executionStartTime": 1630746870104,
        "executionStopTime": 1630746870285
      },
      "source": [
        "def Composite34():\n",
        "    in1 = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[10, 20], [30, 40]]])\n",
        "    in2 = torch.tensor([3, 5, 10])\n",
        "    out_orig = torch.tensor([[128, 236], [344, 452]])\n",
        "    out = torch.tensordot(in2, in1, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite34()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "02ed9dea-8782-4695-94bc-d5f2d6c4d384",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "fff23d48-6bcc-410c-af9c-b6c011dcfffb",
        "executionStartTime": 1630746874810,
        "executionStopTime": 1630746874881
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite36():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([1, 0, 1, 1, 0, 1, 0, 1])\n",
        "    out_orig = torch.tensor([1.0, 0.0, 0.333333, 0.25, 0.0, 0.166667, 0.0, 0.125])\n",
        "    out = torch.div(in1, torch.add(in1, torch.arange(8)))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(out_orig, out_orig.shape, out_orig.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['arange', torch.arange(8), []])\n",
        "    domain_io.append(['add', torch.add(in1, torch.arange(8)), [in1, torch.arange(8)]])\n",
        "    domain_io.append(['div', torch.div(in1, torch.add(in1, torch.arange(8))), [in1, torch.add(in1, torch.arange(8))]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite36()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "21ea4d75-a703-4d39-b1d2-8df58cb7e607",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "d4311409-a84d-4ccd-b274-124c9cace37c",
        "executionStartTime": 1630746560309,
        "executionStopTime": 1630746560418
      },
      "source": [
        "def Composite37():\n",
        "    in1 = torch.tensor([\n",
        "                    [\n",
        "                        [[10, 20, 30], [40, 50, 60]],\n",
        "                        [[12, 34, 56], [78, 98, 76]],\n",
        "                    ]\n",
        "                ])\n",
        "    in2 = torch.tensor([5, 10, 20])\n",
        "    out_orig = torch.tensor([[[850, 1900], [1520, 2890]]])\n",
        "    out = torch.tensordot(in1, in2, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite37()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "eabe91ea-6b34-46db-8a86-a8ab9ea09123",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "d6b2d925-b152-4bea-bff2-11fb25639643",
        "executionStartTime": 1630746897888,
        "executionStopTime": 1630746897913
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite39():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[15, 10, 9, 20], [11, 0, 1, 9], [10, 1, 11, 25]])\n",
        "    out_orig = torch.tensor([\n",
        "                [225, 100, 81, 400],\n",
        "                [121, 0, 1, 81],\n",
        "                [100, 1, 121, 625],\n",
        "            ])\n",
        "    out = torch.square(torch.mul(in1, in1.bool()))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['mul', torch.mul(in1, in1.bool().long()), [in1, in1.bool().long()]])\n",
        "    domain_io.append(['square', torch.square(torch.mul(in1, in1.bool().long())), [torch.mul(in1, in1.bool().long())]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite39()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "398d804b-ca2d-4abe-b6ab-3fd9083cebe8",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2378f9f3-5f29-4eac-abbf-c7346cba6c46",
        "executionStartTime": 1630746901817,
        "executionStopTime": 1630746901905
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite41():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([5, 2, 8, 2, 4, 1, 1, 0, 2, 1])\n",
        "    in2 = 3\n",
        "    out_orig = torch.tensor([5, 2, 8, 4, 1, 1, 0, 2, 1])\n",
        "    out = torch.masked_select(in1, torch.ne(torch.arange(10), in2))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['arange', torch.arange(10),[]])\n",
        "    domain_io.append(['ne', torch.ne(torch.arange(10), in2), [torch.arange(10), torch.tensor(3)]])\n",
        "    domain_io.append(['masked_select',torch.masked_select(in1, torch.ne(torch.arange(10), in2)), [in1, torch.ne(torch.arange(10), in2)]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite41()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "02e284c5-066b-4daa-8c46-450688b5ec3b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5056a069-f294-4c30-93c7-e59826315335",
        "executionStartTime": 1630746915081,
        "executionStopTime": 1630746915233
      },
      "source": [
        "def Composite42():\n",
        "    in1 = torch.tensor([4, 6, 2, 6, 7, 3, 3])\n",
        "    out_orig = torch.tensor([0, 0, 0, 0, 1, 0, 0]).int()\n",
        "    out = torch.eq(in1, 7)\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['eq', torch.eq(in1, 7), [in1, torch.tensor(7)]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite42()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f1348958-39c9-42d7-8432-3f5119a4c759",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7570966f-5b1e-420b-927e-afd4b3b4d8cb",
        "executionStartTime": 1630746921509,
        "executionStopTime": 1630746921565
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite44():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([\n",
        "                    [3, 5, 2],\n",
        "                    [6, 2, 3],\n",
        "                    [8, 7, 1],\n",
        "                    [0, 3, 5],\n",
        "                    [4, 7, 3],\n",
        "                    [2, 1, 6],\n",
        "                    [10, 20, 30],\n",
        "                    [4, 5, 6],\n",
        "                ])                \n",
        "    out_orig = torch.tensor([[9, 7, 5], [8, 19, 6], [6, 8, 9], [14, 25, 36]])\n",
        "    out = torch.sum(torch.reshape(in1, (-1, 2, 3)), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['reshape', torch.reshape(in1, (-1, 2, 2)), [in1]])\n",
        "    domain_io.append(['sum', torch.sum(torch.reshape(in1, (-1, 2, 3)), 1), [torch.reshape(in1, (-1, 2, 2))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite44()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "39913211-543e-4ef7-b5b8-955e55598044",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "fc313bcf-7429-4d22-96f4-557274d6ad04",
        "executionStartTime": 1630746943742,
        "executionStopTime": 1630746943999
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite45():\n",
        "  if is16 == True:\n",
        "        return\n",
        "  in1 = torch.tensor([1, 0, 1, 0, 1])\n",
        "  in2 = torch.tensor([[[12, 34], [56, 78], [23, 54], [76, 78], [42, 24]]])\n",
        "  out_orig = torch.tensor([[[34, 12],\n",
        "         [56, 78],\n",
        "         [54, 23],\n",
        "         [76, 78],\n",
        "         [24, 42]]])\n",
        "  out = torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2)\n",
        "\n",
        "  print(in1, in1.shape)\n",
        "  print(in2, in2.shape)\n",
        "  print(out, out.shape)\n",
        "  print(torch.equal(out, out_orig))\n",
        "  \n",
        "  domain_io = []\n",
        "  domain_io.append(['unsqueeze', torch.unsqueeze(in1, 1), [in1]])\n",
        "  domain_io.append(['roll', torch.roll(in2, 1, -1), [in2]])\n",
        "  domain_io.append(['where', torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2), [torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "Composite45()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3880f869-9684-4f4c-97d6-c881e95ac007",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a788c3b2-996c-477b-86e1-7b1b75562d46",
        "executionStartTime": 1630746956719,
        "executionStopTime": 1630746956779
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite46():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([3, 4, 1])\n",
        "    out_orig = torch.tensor([0, 0, 0, 1, 1, 1, 1, 2])\n",
        "    out = torch.repeat_interleave(torch.arange(3), in1, 0)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.arange(3), []])\n",
        "    domain_io.append(['repeat_interleave', torch.repeat_interleave(torch.arange(3), in1, 0), [torch.arange(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite46()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "e74fa306-4772-4d97-b159-ff56fca49183",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "e81edb29-3866-463e-ac3d-ab2f15cb8af2",
        "executionStartTime": 1630746599306,
        "executionStopTime": 1630746599418
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite48():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([32, 53, 45, 38, 29, 89, 64, 23])\n",
        "    in2 = torch.tensor([38, 53, 89, 38, 32, 64])\n",
        "    out_orig = torch.tensor([3, 1, 5, 3, 0, 6])\n",
        "    out = torch.argmax(torch.eq(in1, torch.unsqueeze(in2, 1)).int(), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    print('torch.unsqueeze(in1, 1)', torch.unsqueeze(in1, 1))\n",
        "    print('torch.eq(in2, torch.unsqueeze(in1, 1)).float()', torch.eq(in2, torch.unsqueeze(in1, 1)).int())\n",
        "    print('torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1)', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).int(), 1))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['unsqueeze', torch.unsqueeze(in1, 1).float(), [in1]])\n",
        "    domain_io.append(['eq', torch.eq(in2, torch.unsqueeze(in1, 1)).float(), [in2,torch.unsqueeze(in1, 1).float()]])\n",
        "    domain_io.append(['argmax', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1), [torch.eq(in2, torch.unsqueeze(in1, 1)).float()]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite48()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "97971b79-8a27-4062-9789-b0582ea699c8",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "73c61b6a-27b7-492d-aa05-3457a44c6b35",
        "executionStartTime": 1630746609340,
        "executionStopTime": 1630746609446
      },
      "source": [
        "def Composite49():\n",
        "    in1 = torch.tensor([\n",
        "                    [[[1, 2, 3], [4, 5, 6]]],\n",
        "                    [[[8, 10, 0], [6, 4, 2]]],\n",
        "                    [[[9, 8, 7], [1, 2, 3]]],\n",
        "                ])\n",
        "    in2 = torch.tensor([20, 5, 10])\n",
        "    out_orig = torch.tensor([\n",
        "                [[[20, 40, 60], [80, 100, 120]]],\n",
        "                [[[40, 50, 0], [30, 20, 10]]],\n",
        "                [[[90, 80, 70], [10, 20, 30]]],\n",
        "            ])\n",
        "    out = torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['transpose', torch.transpose(in1, 0, 3), [in1]])\n",
        "    domain_io.append(['mul', torch.mul(in2, torch.transpose(in1, 0, 3)), [in2,torch.transpose(in1, 0, 3)]])\n",
        "    domain_io.append(['transpose', torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3), [torch.mul(in2, torch.transpose(in1, 0, 3))]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite49()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "112a81da-a6dc-4581-8790-c79debb8e2dc",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "71675657-963f-4a76-8c12-0fb9f1b0675b",
        "executionStopTime": 1630746615452,
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1630746615427
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite50():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor(3)\n",
        "    out_orig = torch.tensor([\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "            ])\n",
        "    out = torch.nn.functional.one_hot(in1.expand(5), 6)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['expand', torch.tensor(3).expand((5,)), [torch.tensor(3)]])\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(in1, 6), [in1, torch.tensor(6)]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b74f7a2d-1316-4d99-bac1-83269b88b4ff",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "6802ce7d-2305-4fdc-b416-2521ed09f6ce",
        "executionStartTime": 1630746622705,
        "executionStopTime": 1630746622820
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ed251d3c-ffaa-4831-badd-89ede9c41a89",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c879de07-5d7f-47e3-be8a-7bd569da5c07",
        "executionStartTime": 1630730567885,
        "executionStopTime": 1630730567993
      },
      "source": [
        "tc = 0\n",
        "for t in sorted(total_correct):\n",
        "    tc +=  total_correct[t]\n",
        "    print(t, total_correct[t], tc/(total_benchmark-1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
