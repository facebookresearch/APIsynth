{
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "bento_kernel_pytorch",
      "metadata": {
        "kernel_name": "bento_kernel_pytorch",
        "nightly_builds": true,
        "fbpkg_supported": true,
        "is_prebuilt": true
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "last_server_session_id": "9c732520-7b34-4212-9499-4839d6fa8079",
    "last_kernel_id": "55a86e09-645a-4e32-aa4c-38dc99c8bbf2",
    "last_base_url": "https://devvm3630.vll0.facebook.com:8090/",
    "last_msg_id": "194a2587-a994214eea70f44f12bbe232_1437",
    "captumWidgetMessage": {},
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "originalKey": "1b5ebc2d-7012-46e4-8b12-4bcba7a161ff",
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "458276f5-7b8e-4cac-9995-5e3fecc3f4f7",
        "executionStartTime": 1632947404560,
        "executionStopTime": 1632947404600
      },
      "source": [
        "from torch import nn\n",
        "import time\n",
        "import torch\n",
        "import torch as T\n",
        "import torch.nn.functional as F\n",
        "# device = T.device(\"cuda\")\n",
        "device = T.device(\"cpu\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7a46bc16-5f8c-4bd1-89e8-bb2cb3a454d0",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "5da82e5d-8d53-4fdc-8a58-7a1bd9346ff5",
        "executionStartTime": 1632947406235,
        "executionStopTime": 1632947406256
      },
      "source": [
        "is16 = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c3839b51-5880-4455-8f3c-c1ce2e7f83d2",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "7669bef7-afd7-4b10-977d-dd94bfb7e99f",
        "executionStartTime": 1632947407040,
        "executionStopTime": 1632947407055,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class FinalEmbedding:\n",
        "    def __init__(self,x,y):\n",
        "        self.x_data = x\n",
        "        self.y_data = y\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        preds = self.x_data[idx]\n",
        "        trgts = self.y_data[idx] \n",
        "        sample = { \n",
        "        'predictors' : preds,\n",
        "        'targets' : trgts\n",
        "        }\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "94841941-b711-4b4d-9dec-e6ff849f24ef",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "50040042-609e-467b-b342-d14f41e41f7f",
        "executionStartTime": 1632947408343,
        "executionStopTime": 1632947408354
      },
      "source": [
        "from iopath.common.file_io import PathManager\n",
        "from iopath.fb.manifold import ManifoldPathHandler\n",
        "\n",
        "def load_checkpoint(checkpoint_path, map_location=None):\n",
        "    pm = PathManager()\n",
        "    pm.register_handler(ManifoldPathHandler())\n",
        "    with pm.open(checkpoint_path, \"rb\") as f:\n",
        "        if map_location is not None:\n",
        "            checkpoint = torch.load(f, map_location=map_location)\n",
        "        else:\n",
        "            checkpoint = torch.load(f, map_location=lambda storage, loc: storage)\n",
        "    return checkpoint\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "fedc7df6-e528-4ddc-9f7e-47c33fe01989",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "b1f4c6fd-7a82-4fa2-9007-db9b18cb5dd9",
        "executionStartTime": 1632947409073,
        "executionStopTime": 1632947409109,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class pycoder_parameters:\n",
        "\n",
        "    Path = 'gen1_33'\n",
        "\n",
        "    ''' Core Fuzzing Parameters '''\n",
        "    NUM_FUZZ_PER_API= 100001 #000\n",
        "    NUM_TEST_FUZZ = 2\n",
        "    FLOAT_TENSOR = False #We either generate float or integer tensors\n",
        "    UNIT_TEST = False\n",
        "    COMPOSITE = True\n",
        "\n",
        "    ''' Fuzzing Detailed Parameters '''\n",
        "    MAX_TENSOR_DIMENSIONS = 3 #how many rows, columns, etc.\n",
        "    MIN_VAL_PER_DIMENSION = 1 # e.g., min number of rows, columns, etc. \n",
        "    MAX_VAL_PER_DIMENSION = 5 # e.g., max number of rows, columns, etc. \n",
        "\n",
        "    #So far limiting to integers\n",
        "    MIN_TENSOR_VALUE = 1\n",
        "    MAX_TENSOR_VALUE = 15\n",
        "    \n",
        "\n",
        "    ''' Embedding Parameters '''\n",
        "    EMBEDDING_NOISE_LEVEL = 0 #0 noise by default\n",
        "    EMBEDDING_SIZE = 150\n",
        "    SHAPE_EMBEDDING_SIZE = 6\n",
        "\n",
        "\n",
        "    data_type = 'float' if FLOAT_TENSOR is  True else 'integer'\n",
        "    model_type = 'Composite_' if COMPOSITE is  True else 'Single_'\n",
        "    file_name = str(model_type) + str(NUM_FUZZ_PER_API) + '_' + data_type\n",
        "    fuzzing   = file_name + '.pt'\n",
        "    embedding = file_name + '.embedding' + '.pt',\n",
        "    classification = file_name + '.model_result' + '.pt' \n",
        "    train_valid_test = file_name + 'train_valid_test.pt'\n",
        "\n",
        "    def setNoiseLevel(self, noise):\n",
        "        self.EMBEDDING_NOISE_LEVEL = noise\n",
        "        self.embedding = self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt'\n",
        "\n",
        "    def getEmbeddingFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt')\n",
        "\n",
        "    def getVisulizationFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '_' +  'tSNE.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f9ded57b-5861-4ebc-9a7c-3376594b7255",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "8caca021-bb87-49e1-bae1-9126425c49e6",
        "executionStartTime": 1632947410406,
        "executionStopTime": 1632947410490,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "NOISE = 0\n",
        "f = pycoder_parameters()\n",
        "f.setNoiseLevel(NOISE)\n",
        "f.embedding = f.getEmbeddingFile() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c6230582-27c2-4f38-94d3-9edb872003d7",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "95d27cc0-1406-461b-96ad-c8d169b0a427",
        "executionStartTime": 1632947421722,
        "executionStopTime": 1632947421750,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "EMBEDDING_SIZE = f.EMBEDDING_SIZE\n",
        "SHAPE_EMBEDDING_SIZE = f.SHAPE_EMBEDDING_SIZE\n",
        "\n",
        "\n",
        "def encode_values_to_code(tensor):\n",
        "    tensor = tensor.clone()\n",
        "    tensor[(tensor >= 100) & (tensor < 1000)] = 100\n",
        "    tensor[(tensor >= 1000)] = 101\n",
        "    tensor[(tensor <= -20) & (tensor > -100)] = -20\n",
        "    tensor[(tensor <= -100) & (tensor > -1000)] = -21\n",
        "    tensor[(tensor <= -1000)] = -22\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def tensor_flatten_pad(\n",
        "    tensor,\n",
        "    embed_size=EMBEDDING_SIZE,\n",
        "    shape_embed_size=SHAPE_EMBEDDING_SIZE,\n",
        "    isNoise=False,\n",
        "):\n",
        "\n",
        "    t_flatten = torch.flatten(tensor)\n",
        "    padding_length = embed_size - list(t_flatten.shape)[-1]\n",
        "    p1d = (0, padding_length)  # just padding the last dimension\n",
        "    t_pad = F.pad(input=t_flatten, pad=p1d, mode=\"constant\", value=0).type(\n",
        "        torch.FloatTensor\n",
        "    )\n",
        "\n",
        "    type_padding = 0\n",
        "    if tensor.dtype == torch.bool:\n",
        "        type_padding = 1\n",
        "        # print('Bool')\n",
        "    elif (\n",
        "        tensor.dtype == torch.float64\n",
        "        or tensor.dtype == torch.double\n",
        "        or tensor.dtype == torch.float32\n",
        "        or tensor.dtype == torch.float16\n",
        "    ):\n",
        "        type_padding = 2\n",
        "\n",
        "    \"\"\"size embedding\"\"\"\n",
        "    if shape_embed_size > 0:\n",
        "        t_shape = list(tensor.shape)\n",
        "        padding_length = shape_embed_size - 1 - len(t_shape)\n",
        "        p1d = (0, padding_length)  # just padding the last dimension\n",
        "        s_pad = F.pad(\n",
        "            input=torch.Tensor(t_shape), pad=p1d, mode=\"constant\", value=0\n",
        "        ).type(torch.float)\n",
        "\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        s_pad_list = s_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor(\n",
        "            [type_padding] + [-1] + t_pad_list + [-1] + s_pad_list + [-1]\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1])\n",
        "\n",
        "    encoded_tensor = encode_values_to_code(tensor_embedding)\n",
        "    return encoded_tensor\n",
        "\n",
        "\n",
        "\"unit test\"\n",
        "t1 = torch.tensor([[[1, 2, 3]], [[4, 555, 6]]])\n",
        "tf = tensor_flatten_pad(t1, shape_embed_size=5, isNoise=True)\n",
        "print(tf, tf.shape)\n",
        "\n",
        "t2 = torch.tensor([[[True, False, True]], [[True, True, False]]])\n",
        "tf1 = tensor_flatten_pad(t2, shape_embed_size=0)\n",
        "print(tf1, tf1.shape)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "426b4f46-1b52-4d0b-900a-fb0f5750ea4c",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "c0ed413d-afd9-4439-a2f4-b77407f7d35b",
        "executionStartTime": 1632947423085,
        "executionStopTime": 1632947423111,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def embed_tensors(data_list):\n",
        "       \n",
        "    global EMBEDDING_SIZE\n",
        "    global api2indx\n",
        "    \n",
        "    X=[]\n",
        "    y=[]\n",
        "\n",
        "    all_input_output_tensors = set()\n",
        "    duplicate_count = 0\n",
        "\n",
        "    dict_indx = len(api2indx)\n",
        "\n",
        "    final_output = data_list[-1][1]\n",
        "\n",
        "    prev_out = torch.Tensor()\n",
        "    \n",
        "    api_seq_x = []\n",
        "    api_seq_y = []\n",
        "\n",
        "    for data in data_list:\n",
        "        api = data[0]\n",
        "        api_indx = api2indx[api]\n",
        "        \n",
        "        input_list = data[2] #.get_input()\n",
        "        output_tensor = final_output #data.get_output()\n",
        "        \n",
        "        it_pad = []\n",
        "\n",
        "        for input_tensor in input_list:\n",
        "            if input_tensor.shape == prev_out.shape and torch.all(input_tensor.eq(prev_out)).item():\n",
        "                t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                t[-1] = -1\n",
        "                it_pad.append(t)\n",
        "            else:         \n",
        "                #flatten the input tensor\n",
        "                it_pad.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "            \n",
        "        \n",
        "        #adding addidional tensors with zero embeddings for < 2 tensors\n",
        "        for i in range(len(it_pad),3):\n",
        "            t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "            t[-1] = -1\n",
        "            it_pad.append(t)\n",
        "       \n",
        "        ot_pad = tensor_flatten_pad(output_tensor, isNoise=True)\n",
        "\n",
        "        x = T.flatten(T.stack((it_pad[0],it_pad[1], it_pad[2], ot_pad)))\n",
        "\n",
        "\n",
        "        xl = (x,api_indx)\n",
        "        \n",
        "        if xl in all_input_output_tensors:\n",
        "            duplicate_count += 1\n",
        "        else:\n",
        "            all_input_output_tensors.add(xl)\n",
        "\n",
        "    \n",
        "        api_seq_x.append(x) \n",
        "        api_seq_y.append(api_indx)\n",
        "\n",
        "        prev_out = data[1]\n",
        "\n",
        "    X.append(api_seq_x)\n",
        "    y.append(api_seq_y)\n",
        "    \n",
        "    return(X,y)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f0b8b05f-85dd-48ce-b946-48aaf66775f5",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "3a653e33-1d66-4f77-8eff-5904ff621beb",
        "executionStartTime": 1632947424822,
        "executionStopTime": 1632947424833,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def process_dataX(tensor_list):\n",
        "    \n",
        "    #print(tensor_list)\n",
        "    io_seq = []\n",
        "    \n",
        "    n0 = tensor_list[0]\n",
        "\n",
        "    if(len(tensor_list) == 1):\n",
        "        n1 = torch.zeros(n0.shape)\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "        \n",
        "    elif(len(tensor_list) == 2):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = torch.zeros(n0.shape)\n",
        "\n",
        "    elif(len(tensor_list) == 3):\n",
        "        n1 = tensor_list[1]\n",
        "        n2 = tensor_list[2]\n",
        "\n",
        "        \n",
        "    new_list = torch.stack((n0, n1, n2))\n",
        "\n",
        "    io_seq.append(new_list)\n",
        "    \n",
        "    return(torch.stack(io_seq))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "2e6bd0ec-6392-4d13-b316-b90c46fc5ad7",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "4df9a512-31a1-4886-84bc-7672d0673d93",
        "executionStartTime": 1632947426201,
        "executionStopTime": 1632947426221,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "indx2api = {}\n",
        "EOS = '<eol>'\n",
        "\n",
        "def process_dataY(api_seq):\n",
        "    global indx2api\n",
        "    global api2indx\n",
        "\n",
        "    ''' Add <eol> to the dictionary '''\n",
        "    indx2api = {v: k for k, v in api2indx.items()}\n",
        "\n",
        "    if api2indx.get(EOS, -1) == -1:\n",
        "        max_key = max(indx2api.keys())\n",
        "        print(max_key)\n",
        "        indx2api[max_key+1] = EOS\n",
        "        api2indx[EOS] = max_key+1\n",
        "\n",
        "    eos = api2indx[EOS]\n",
        "\n",
        "    api_tensors = []\n",
        "\n",
        "\n",
        "    api0 = api_seq[0]\n",
        "\n",
        "    if len(api_seq) == 1:\n",
        "        api1 = eos\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 2:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = eos\n",
        "\n",
        "    elif len(api_seq) == 3:\n",
        "        api1 = api_seq[1]\n",
        "        api2 = api_seq[2]\n",
        "\n",
        "    else:\n",
        "        print('!!! Not supposed to be here')\n",
        "\n",
        "    t = torch.tensor([api0, api1, api2])\n",
        "    api_tensors.append(t)\n",
        "    \n",
        "    return(torch.stack(api_tensors))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "32e2a58f-958a-40ec-a053-f3b6460c2c9f",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "7bac265b-cef5-43c5-b3e9-ed630bd3d965",
        "executionStartTime": 1632947427504,
        "executionStopTime": 1632947427521,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, bidirectional=True)   \n",
        "        \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        #Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        \n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        \n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out1 = out.contiguous().view(-1, self.hidden_dim*2)\n",
        "        out1 = self.fc(out1)\n",
        "        \n",
        "        return out1, hidden, out\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        hidden = torch.zeros(self.n_layers*2, batch_size, self.hidden_dim).to(device)\n",
        "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "52409377-40a1-4060-818a-ed5f7ea108ff",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "7b785ad1-fedb-46bc-85c4-938a2b286baf",
        "executionStartTime": 1632947428686,
        "executionStopTime": 1632947428714
      },
      "source": [
        "class FFNet(T.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FFNet, self).__init__()\n",
        "\n",
        "    self.hid1 = T.nn.Linear(4*(f.EMBEDDING_SIZE+f.SHAPE_EMBEDDING_SIZE+1+2), 500)\n",
        "    self.hid2 = T.nn.Linear(500, 250)\n",
        "    self.hid3 = T.nn.Linear(250, 100)\n",
        "    self.oupt = T.nn.Linear(100, len(api2indx))\n",
        "\n",
        "    T.nn.init.xavier_uniform_(self.hid1.weight)\n",
        "    T.nn.init.zeros_(self.hid1.bias)\n",
        "    T.nn.init.xavier_uniform_(self.hid2.weight)\n",
        "    T.nn.init.zeros_(self.hid2.bias)\n",
        "    T.nn.init.xavier_uniform_(self.oupt.weight)\n",
        "    T.nn.init.zeros_(self.oupt.bias)\n",
        "\n",
        "    T.nn.Dropout(p=0.2)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    z1 = T.tanh(self.hid1(x))\n",
        "    z2 = T.tanh(self.hid2(z1))\n",
        "    z3 = T.tanh(self.hid3(z2))\n",
        "    z = self.oupt(z3)  # no softmax: CrossEntropyLoss() \n",
        "    return (z, z3, z2, z1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c7bdc17c-c6c1-44d6-b2ec-c7167a532450",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "609261e0-b301-432d-aa9d-4745961eb7cc",
        "executionStartTime": 1632947429919,
        "executionStopTime": 1632947429927
      },
      "source": [
        "def embed_tensor_for_model(domain_io):\n",
        "\n",
        "    x, y = embed_tensors(domain_io)\n",
        "    \n",
        "    X = process_dataX(x[0])\n",
        "    Y = process_dataY(y[0])\n",
        "    ds = FinalEmbedding(X,Y)\n",
        "\n",
        "    X = ds[0]['predictors'].to(device)\n",
        "    Y = ds[0]['targets'].to(device)  # [0] [1] or [2]\n",
        "\n",
        "    return(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "41825d22-9f14-4b02-b9ae-4565dcfeec91",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8e599a28-88b3-4ff6-8bcd-20aec35f428b",
        "executionStartTime": 1632947430778,
        "executionStopTime": 1632947430806
      },
      "source": [
        "def beam_search(top3_list):\n",
        "\n",
        "    api_seq = []\n",
        "    api_seq1 = []\n",
        "    for i in top3_list[0]:\n",
        "        for j in top3_list[1]:\n",
        "            api_seq1.append(((i[0], j[0]), i[1]*j[1]))\n",
        "    \n",
        "    api_seq1.sort(key = lambda x: x[1], reverse=True) \n",
        "\n",
        "    for k in top3_list[2]:\n",
        "        for s1 in api_seq1:\n",
        "            api_seq.append(((s1[0][0], s1[0][1], k[0]), s1[1]*k[1]))\n",
        "\n",
        "    api_seq.sort(key = lambda x: x[1], reverse=True) \n",
        "    \n",
        "    return(api_seq)\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1d8edc0b-6b2b-4a31-9947-7d7d0e18c99f",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "effdd9d7-b2fd-4ca0-8e9a-4f167fe85636",
        "executionStartTime": 1632947432099,
        "executionStopTime": 1632947432132
      },
      "source": [
        "total_correct = {}\n",
        "seq_len_correct = {}\n",
        "seq_len_total = {}\n",
        "total_benchmark = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "22d755fa-a0d5-43d1-b60d-bbc5e289a81b",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "70937d50-5fb0-488c-a7f7-a086cf57dab0",
        "executionStartTime": 1632947432885,
        "executionStopTime": 1632947432920
      },
      "source": [
        "def reset_stat():\n",
        "    global total_correct\n",
        "    global seq_len_correct\n",
        "    global seq_len_total\n",
        "    global total_benchmark\n",
        "    \n",
        "    total_correct = {}\n",
        "    seq_len_correct = {}\n",
        "    seq_len_total = {}\n",
        "    total_benchmark = 0\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "5c088f2c-1ed5-4a11-adac-37d09ab53b86",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "e2ef0ee8-6361-46d0-866d-ab09e74bb07b",
        "executionStartTime": 1632947433967,
        "executionStopTime": 1632947433991
      },
      "source": [
        "reset_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a9d6df5e-ed54-42aa-87a5-4dade7e961cd",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "67af21a9-1e12-4319-bd26-7d8b02e7015d",
        "executionStartTime": 1632947434662,
        "executionStopTime": 1632947434681
      },
      "source": [
        "def print_stat():\n",
        "    print('total_correct', total_correct)\n",
        "    print('seq_len_correct', seq_len_correct)\n",
        "    print('seq_len_total', seq_len_total)\n",
        "    print('total_benchmark', total_benchmark)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "684fd3ac-9c8e-44d8-aabf-f24b2aa8388d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "dfaf6b37-3284-433a-8270-dcf28e30993c",
        "executionStartTime": 1632947436103,
        "executionStopTime": 1632947436129
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "37c2cb61-8ea1-4464-a643-1d0525a7126d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "18356952-0478-4ecb-85c7-93bfcad6d1da",
        "executionStartTime": 1632947568264,
        "executionStopTime": 1632947568270
      },
      "source": [
        "def query_model(X, Y):\n",
        "    \n",
        "    global total_benchmark\n",
        "    with T.no_grad():\n",
        "      start_time = time.time()\n",
        "      predicts, z3, z2, z1 = net(X)\n",
        "      temp_z3 = torch.unsqueeze(z3,0)\n",
        "      model_output, hidden, int_output = rnn_model(temp_z3)\n",
        "\n",
        "      target_list = list(Y.cpu().numpy())\n",
        "    \n",
        "    top_indx = []\n",
        "\n",
        "    top3_list = []\n",
        "\n",
        "    print('---- Top-k ----')\n",
        "    for i, m in enumerate(model_output):\n",
        "        top3 = []\n",
        "        prob = nn.functional.softmax(m, dim=0).data\n",
        "        # Taking the class with the highest probability score from the output\n",
        "        xx = torch.topk(prob,5,dim=0)[1]\n",
        "        for x in xx.cpu().numpy():\n",
        "          print(indx2api[x])\n",
        "          top3.append((indx2api[x], prob[x].item()))\n",
        "        top3_list.append(top3)\n",
        "        print('====')\n",
        "        \n",
        "    print('---- Predicted ----')\n",
        "    for m in model_output:\n",
        "        prob = nn.functional.softmax(m, dim=0).data\n",
        "        api_ind = torch.max(prob, dim=0)[1].item()\n",
        "        top_indx.append(api_ind)\n",
        "        if DEBUG:\n",
        "            print(indx2api[api_ind], prob[api_ind])\n",
        "\n",
        "\n",
        "    print('---- Expected ----')\n",
        "    seq_len = 0\n",
        "    for o in list(Y):\n",
        "        if o.item() != len(api2indx)-1:\n",
        "          seq_len += 1\n",
        "        print(indx2api[o.item()])\n",
        "    # print('seq length', seq_len)\n",
        "    if seq_len_correct.get(seq_len, -1) == -1:\n",
        "      seq_len_correct[seq_len] = 0\n",
        "      seq_len_total[seq_len] = 0\n",
        "    \n",
        "    seq_len_total[seq_len] += 1\n",
        "    total_benchmark += 1\n",
        "\n",
        "    o = list(Y)\n",
        "    expected = ((indx2api[o[0].item()], indx2api[o[1].item()], indx2api[o[2].item()]))\n",
        "    \n",
        "    top3_list = beam_search(top3_list)\n",
        "    for i,t in enumerate(top3_list):\n",
        "      if t[0] == expected:\n",
        "        print(i+1, t[0], '\\t***MATCH')\n",
        "        if total_correct.get(i+1, -1) == -1:\n",
        "          total_correct[i+1] = 0\n",
        "        total_correct[i+1] += 1\n",
        "        seq_len_correct[seq_len] += 1\n",
        "        break\n",
        "      else:\n",
        "        print(t[0])\n",
        "    return(top3_list)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "207fd449-441a-41e8-a622-5c4f315f3090",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "3fbdfb31-ac88-4a4e-b74e-73898b987e96",
        "executionStartTime": 1632947569151,
        "executionStopTime": 1632947569358,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "def api_edit_distance(seq1, seq2):\n",
        "\n",
        "    edit_distantce = 0\n",
        "\n",
        "    for i in range(len(seq1)):\n",
        "        if seq1[i] != seq2[i]:\n",
        "            edit_distantce += 1\n",
        "\n",
        "    return(edit_distantce)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "db616029-ec51-41fa-a77a-0b701535282e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "218e24a1-d15a-4034-aea9-5242493ed637",
        "executionStartTime": 1632947569851,
        "executionStopTime": 1632947570028
      },
      "source": [
        "max_epochs = 20\n",
        "net = torch.load(f.Path + '/' + str(max_epochs) + '_train_net_model.pt')\n",
        "rnn_model = torch.load(f.Path + '/' + str(max_epochs) + '_train_rnn_model.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c0df81aa-138a-4a68-8f5b-33fd78fa12e2",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "3bbd52e9-1062-4a66-81fe-4139036ad220",
        "executionStartTime": 1632947570544,
        "executionStopTime": 1632947570725
      },
      "source": [
        "api2indx = torch.load(f.Path + '/api2indx.pt')\n",
        "api2indx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "3f0ac78e-cbea-44ee-bd62-8fc1867ab0fe",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "9c13600f-6067-461e-8256-8fa25e05c343",
        "executionStartTime": 1632947571346,
        "executionStopTime": 1632947571354
      },
      "source": [
        "reset_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a328855a-6d99-4cc2-88bb-99c04295b793",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "0a3e0e5e-45d7-4ec0-809c-c858cde79074",
        "executionStartTime": 1632947572335,
        "executionStopTime": 1632947572365
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4a77fb29-34ae-4ba4-bde6-36fd44318dce",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "0d02e811-eacc-49fa-97ef-7e8bdd0b883c",
        "executionStartTime": 1632947572890,
        "executionStopTime": 1632947572955
      },
      "source": [
        "DEBUG = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "339a30d4-241e-4eda-8730-d20a38afeba8",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "78c027d3-b010-4d49-82cd-d2f162c1e238",
        "executionStartTime": 1632947574569,
        "executionStopTime": 1632947574667
      },
      "source": [
        "def Composite01():\n",
        "    in1 = torch.tensor([[5, 2], [1, 3], [0, 2]])\n",
        "    out_orig = torch.tensor([[[5, 5], [1, 1], [0, 0]],\n",
        "                                [[2, 2], [3, 3], [2, 2]]])                            \n",
        "    out = torch.transpose(in1.expand((2, 3, 2)), 0, 2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(in1, out))\n",
        "    \n",
        "    domain_io = []\n",
        "    domain_io.append(['expand', in1.expand((2, 3, 2)), [in1]])\n",
        "    domain_io.append(['transpose', out, [in1.expand((2, 3, 2))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "        \n",
        "Composite01()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "359bb04d-daad-4cc6-9f6d-d8f2ef2b976a",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "0dfd86a5-c48c-4cdc-a9ac-774af1a20f25",
        "executionStartTime": 1632947657244,
        "executionStopTime": 1632947657256
      },
      "source": [
        "def Composite02():\n",
        "    domain_inpt10 = torch.tensor([5, 1, 0, 3, 0, 0, 2, 0, 2])\n",
        "    domain_out10 = torch.lt(domain_inpt10, 1)\n",
        "    \n",
        "    domain_inpt20 = domain_out10\n",
        "    domain_inpt21 = domain_inpt10\n",
        "\n",
        "    domain_output_orig = torch.tensor([1, 1, 0, 1, 0, 0, 1, 0, 1])\n",
        "    domain_output = torch.where(domain_inpt20, domain_inpt21, 1)\n",
        "\n",
        "    print('domain_inpt10 : ', domain_inpt10, domain_inpt10.shape)\n",
        "    print('domain_inpt20 : ', domain_inpt20, domain_inpt20.shape)\n",
        "    print('domain_output : ', domain_output, domain_output.shape)\n",
        "    print(torch.equal(domain_output, domain_output_orig))\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['lt', domain_inpt20, [domain_inpt10, torch.tensor(1)]])\n",
        "    domain_io.append(['where', domain_output, [domain_inpt20, domain_inpt21, torch.tensor(1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite02()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "546ac851-5a13-4006-9591-aa66f74463f4",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "9168ab82-6be9-4350-9c76-75cbcb4f85e6",
        "executionStartTime": 1632947657268,
        "executionStopTime": 1632947657371
      },
      "source": [
        "def Composite05():\n",
        "    in1 = torch.tensor([[4, 3, 1], [6, 5, 2]])\n",
        "    in2 = torch.tensor([[[5, 5]], [[1, 5]], [[6, 0]]])\n",
        "    output_orig = torch.tensor([[[29, 35]], [[47, 55]]])\n",
        "    output = torch.tensordot(in1, in2, 1)\n",
        "    \n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output_orig, output))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', output, [in1, in2]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite05()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "eb7bcc6a-609b-4014-adc6-db5416a80f85",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8627f415-946c-45c3-b0b5-4ee563c75c34",
        "executionStartTime": 1632947657462,
        "executionStopTime": 1632947657542
      },
      "source": [
        "def Composite06():\n",
        "    in1 = torch.tensor([3, 5, 0, 2, 3, 3, 0])\n",
        "    in2 = torch.unsqueeze(in1, 1)\n",
        "    output_orig = torch.tensor([\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
        "                [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
        "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0],\n",
        "            ]).int()\n",
        "    output = torch.eq(in1, in2).int()\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['unsqueeze', torch.unsqueeze(in1, 1), [in1]])\n",
        "    domain_io.append(['eq', torch.eq(in1, in2), [in1, torch.unsqueeze(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite06()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f272783f-b344-45f1-9989-859a65d8ca83",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "1f4cb6a6-638b-47cb-bea6-650c83004647",
        "executionStartTime": 1632947657552,
        "executionStopTime": 1632947657600
      },
      "source": [
        "def Composite07():\n",
        "    in1 = torch.tensor([\n",
        "                    [[8, 4, 6], [2, 12, 3]],\n",
        "                    [[11, 12, 5], [9, 12, 12]],\n",
        "                    [[9, 2, 13], [7, 0, 7]],\n",
        "                    [[2, 10, 5], [7, 1, 2]],\n",
        "                ])\n",
        "    output_orig = torch.tensor([\n",
        "                [[8, 4, 6], [11, 12, 5], [9, 2, 13], [2, 10, 5]],\n",
        "                [[2, 12, 3], [9, 12, 12], [7, 0, 7], [7, 1, 2]],\n",
        "            ])\n",
        "    output = torch.transpose(in1, 0, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['transpose', output, [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite07()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "55031112-7711-48f2-b307-7f2f1464f174",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "017ed16a-399d-4908-8509-30816c2ce4a5",
        "executionStartTime": 1632947657630,
        "executionStopTime": 1632947657807
      },
      "source": [
        "def Composite08():\n",
        "    # in1 = torch.tensor([-1, 0, -3, 2, 1, 3, 5, -1, -9, 2, 10])\n",
        "    in1 = torch.tensor([1, 0, 0, 2, 1, 3, 5, 0, 1, 2, 10])\n",
        "    in2 = torch.tensor([12, 3, 45, 6, 7, 8, 9, 87, 65, 4, 32])\n",
        "    in3 = torch.gt(in1, 1)\n",
        "    output_orig = torch.tensor([6, 8, 9, 4, 32])\n",
        "    output = torch.masked_select(in2, torch.gt(in1, 1))\n",
        "\n",
        "    print('in1: ', in1, in1.shape, in1.dtype)\n",
        "    print('in2: ', in2, in2.shape, in2.dtype)\n",
        "    print('in3: ', in2, in2.shape, in2.dtype)\n",
        "    print('output', output, output.shape, output.dtype)\n",
        "    print(torch.equal(output, output_orig))\n",
        "\n",
        "    domain_io = []   \n",
        "    domain_io.append(['gt', torch.gt(in1, 1), [in1, torch.tensor(1)]])\n",
        "    domain_io.append(['masked_select', torch.masked_select(in2, torch.gt(in1, 1)), [in2, torch.gt(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite08()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a3e5bf8d-cf55-4ff8-a43f-6e91b32915fd",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "80791d74-bfea-40d0-ba81-159ed9a950fb",
        "executionStartTime": 1632947657820,
        "executionStopTime": 1632947657902
      },
      "source": [
        "def Composite11():\n",
        "    in1 = torch.tensor([4, 0, 1, 1, 0, 4, 0, 0, 3, 4, 1])\n",
        "    out_orig = torch.tensor([4, 3, 0, 1, 3])\n",
        "    out = torch.bincount(in1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['bincount', torch.bincount(in1), [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite11()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ba09d188-3690-4c91-8d71-35233cbdd4e1",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "409ca988-d702-4412-9d5a-b4cd6143f651",
        "executionStartTime": 1632947657912,
        "executionStopTime": 1632947657981
      },
      "source": [
        "def Composite13():\n",
        "    in1 = torch.tensor([[3, 5], [10, 2]])\n",
        "    in2 = torch.tensor([[[1, 0], [5, 4]], [[3, 10], [2, 0]]])\n",
        "    in3 = torch.matmul(in1, in2)\n",
        "    out_orig = torch.tensor([[[28, 20], [19, 30]], [[20, 8], [34, 100]]])\n",
        "    out = torch.transpose(torch.matmul(in1, in2), 0, 1)\n",
        "\n",
        "    print('in1 : ', in1, in1.shape, in1.dtype)\n",
        "    print('in2 : ', in2, in2.shape, in2.dtype)\n",
        "    print('in3 : ', in3, in3.shape, in3.dtype)\n",
        "    print('output : ', out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['matmul', torch.matmul(in1, in2), [in1, in2]])\n",
        "    domain_io.append(['transpose', torch.transpose(torch.matmul(in1, in2), 0, 1), [torch.matmul(in1, in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite13()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "23540699-17d0-4214-b566-bb0bf4921014",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "10040022-b3c6-4459-a25c-ac1842fbe53c",
        "executionStartTime": 1632947658073,
        "executionStopTime": 1632947658106
      },
      "source": [
        "def Composite14():\n",
        "    in1 = torch.tensor([\n",
        "                    [\n",
        "                        [False, False, True],\n",
        "                        [False, False, False],\n",
        "                        [True, False, True],\n",
        "                        [False, True, False],\n",
        "                        [False, False, False],\n",
        "                        [True, True, True],\n",
        "                        [True, True, False],\n",
        "                    ]\n",
        "                ]).int()\n",
        "    out_orig = torch.tensor([[True, False, True, True, False, True, True]]).int()\n",
        "    out = torch.any(in1, -1).int()\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['any', torch.any(in1, -1), [in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite14()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "5e81d888-5013-4eb6-ba62-2ff3d4b75905",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "63b47067-d6f7-4183-949f-02e0fd82996d",
        "executionStartTime": 1632947658113,
        "executionStopTime": 1632947658239
      },
      "source": [
        "def Composite15():\n",
        "    in1 = torch.tensor([3, 1, 2, 0, 1, 0, 10, 1, 0])\n",
        "    out_orig = torch.tensor([3, 0, 2, 0, 0, 0, 10, 0, 0])\n",
        "    out = torch.mul(in1, torch.ne(in1, 1)) \n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['ne', torch.ne(in1, 1), [in1, torch.tensor(1)]])\n",
        "    domain_io.append(['mul', torch.mul(in1, torch.ne(in1, 1)), [in1, torch.ne(in1, 1)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite15()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6e51db72-bd07-4011-af8a-06452ede7cfe",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "679400e4-f572-42a6-ac94-9f7125c126d9",
        "executionStartTime": 1632947658243,
        "executionStopTime": 1632947658356
      },
      "source": [
        "def Composite16():\n",
        "    in1 = torch.tensor([[2, 5], [3, 0], [8, 7]])\n",
        "    in2 = torch.tensor([4, 10, 6])\n",
        "    out_orig = torch.tensor([[8, 20], [30, 0], [48, 42]])\n",
        "    out = torch.mul(in1, torch.unsqueeze(in2, 1))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = [] \n",
        "    domain_io.append(['unsqueeze', torch.unsqueeze(in2, 1), [in2]])\n",
        "    domain_io.append(['mul', torch.mul(in1, torch.unsqueeze(in2, 1)), [in1,torch.unsqueeze(in2, 1)]])    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "772c6b39-997b-49c9-9f53-885cdb7f6e28",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ee983a8f-45a4-4842-adf7-6d01b6cea6e8",
        "executionStartTime": 1632947658409,
        "executionStopTime": 1632947658489
      },
      "source": [
        "def Composite17():\n",
        "    in1 = torch.tensor([17, 32, 99])\n",
        "    out_orig = torch.tensor([[17, 17], [32, 32], [99, 99]])\n",
        "    out = torch.stack((in1, in1), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []    \n",
        "    domain_io.append(['stack', out, [in1, in1]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite17()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "92e8efb7-8312-4258-a2f2-96ae86dd6a49",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ccfba3a2-c19a-46d7-adc4-99b3cc8395b2",
        "executionStartTime": 1632947658493,
        "executionStopTime": 1632947658635
      },
      "source": [
        "def Composite18():\n",
        "    in1 = torch.tensor([[[1, 1, 1], [1, 0, 1]], [[1, 2, 3], [4, 5, 6]]])\n",
        "    in2 = torch.tensor([[1, 1, 1, 1], [1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "    in3 = torch.tensor([100, 200, 300, 400])\n",
        "    in4 = torch.matmul(in1, in2)\n",
        "\n",
        "    out_orig = torch.tensor([\n",
        "                [[107, 209, 311, 413], [106, 207, 308, 409]],\n",
        "                [[118, 223, 328, 433], [139, 250, 361, 472]],\n",
        "            ])\n",
        "    out = torch.add(in3, torch.matmul(in1, in2))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(in3, in3.shape, in3.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['matmul', torch.matmul(in1, in2), [in1, in2]])\n",
        "    domain_io.append(['add', out, [in3, torch.matmul(in1, in2)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite18()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d497ad70-02f2-4399-a663-49150fb0d06d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "95765a89-0ebf-43b4-9fb2-73b88e260404",
        "executionStartTime": 1632947658710,
        "executionStopTime": 1632947658787
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite20():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([\n",
        "                    [7, 2, 1],\n",
        "                    [4, 5, 1],\n",
        "                    [4, 4, 2],\n",
        "                    [3, 4, 3],\n",
        "                    [0, 0, 1],\n",
        "                ])\n",
        "    out_orig = torch.tensor([[1, 0, 0], [0, 1, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "    out = torch.nn.functional.one_hot(torch.argmax(in1, 1), 3)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['argmax', torch.argmax(in1, 1), [in1]])\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(torch.argmax(in1, 1),3), [torch.argmax(in1, 1), torch.tensor(3)]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite20()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c77ad3d2-d883-4d4d-8797-b4a6af033a97",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8ded0928-679a-43fd-abb7-2cc41b1b455e",
        "executionStartTime": 1632947658801,
        "executionStopTime": 1632947658870
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite21():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[2], [0], [1], [0]])\n",
        "    in2 = torch.tensor([[2, 5, 3], [1, 3, 6], [1, 6, 3], [7, 0, 3]])\n",
        "    out_orig = torch.tensor([[3], [1], [6], [7]])\n",
        "    out = torch.gather(in2, 1, in1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['gather', out, [in2, in1]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite21()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d408f3d3-b5ee-4ad4-a0e9-17de5f0e9615",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "30011c8d-3e6b-4e7b-9650-ec3eb73eb53f",
        "executionStartTime": 1632947658935,
        "executionStopTime": 1632947658965
      },
      "source": [
        "def Composite22():\n",
        "    in1 = torch.tensor([3, 1, 10])\n",
        "    in2 = torch.tensor([[6, 4], [5, 1], [3, 4]])\n",
        "    out_orig = torch.tensor([53, 53])\n",
        "    out = torch.tensordot(in1, in2, 1 )\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite22()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ae7605ad-8ea7-455f-90f0-aa49ec778a6e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7bb2aae6-505c-4c66-b6d9-868eb538b57e",
        "executionStartTime": 1632947659032,
        "executionStopTime": 1632947659047
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite23():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[0, 5, 2], [3, 1, 4], [5, 1, 5]])\n",
        "    out_orig = torch.tensor([\n",
        "                [1, 0, 1, 0, 0, 1, 0, 0, 0],\n",
        "                [0, 1, 0, 1, 1, 0, 0, 0, 0],\n",
        "                [0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
        "            ])\n",
        "    out = torch.max(torch.nn.functional.one_hot(in1, 9), 1)[0]\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(in1, 9), [in1, torch.tensor(9)]])\n",
        "    domain_io.append(['sum', torch.sum(torch.nn.functional.one_hot(in1, 9), 1), [torch.nn.functional.one_hot(in1, 9)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite23()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ecb1f0f5-9631-410d-be09-abe7c0baa6eb",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "033c36d0-da3b-4737-afd4-238d15e76b4d",
        "executionStartTime": 1632947659143,
        "executionStopTime": 1632947659245
      },
      "source": [
        "# NOT SUPPORTED by 16\n",
        "def Composite24():\n",
        "  if is16 == True:\n",
        "        return\n",
        "  in1 = torch.tensor([3, 1, 4, 5, 2, 8, 6, 7])\n",
        "  in2 = 0\n",
        "  in3 = torch.tensor([1, 0, 2, 0, 1, 1, 0, 2])\n",
        "  out_orig = torch.tensor([3, 1, 2, 5, 2, 8, 6, 3.5])\n",
        "  out = torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float())\n",
        "\n",
        "  print(in1, in1.shape, in1.dtype)\n",
        "  print(in2)\n",
        "  print(in3, in3.shape, in3.dtype)\n",
        "  print(out, out.shape)\n",
        "  print(torch.equal(out, out_orig))\n",
        "\n",
        "\n",
        "  domain_io = []\n",
        "  domain_io.append(['ne', torch.ne(in3, in2), [in3, torch.tensor(in2)]])\n",
        "  domain_io.append(['div', torch.div(in1, in3), [in1, in3]])\n",
        "  domain_io.append(['where', torch.where(torch.ne(in3, in2), torch.div(in1, in3), in1.float()), [torch.ne(in3, in2), torch.div(in1, in3), in1]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "Composite24()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "364d04c4-a59d-4974-96f4-ed6852228eef",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "eed8ab54-639e-4e1f-a478-192429e59942",
        "executionStartTime": 1632947659249,
        "executionStopTime": 1632947659372
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIS\n",
        "def Composite25():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    out_orig = torch.tensor([\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "                [1, 0, 0],\n",
        "                [0, 1, 0],\n",
        "                [0, 0, 1],\n",
        "            ]).int()\n",
        "    out = torch.tile(torch.eye(3), (4, 1)).int()\n",
        "\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['eye', out, []])\n",
        "    domain_io.append(['tile', torch.tile(torch.eye(3), (4, 1)), [torch.eye(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite25()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "cfebfaf7-0b54-48f5-8272-a11d3d538aa2",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "6b7fc28b-6df3-47cc-be4b-b76e923d732e",
        "executionStartTime": 1632947659477,
        "executionStopTime": 1632947659488
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite26():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[[3, 4], [1, 2]], [[5, 2], [10, 3]], [[10, 20], [4, 7]]])\n",
        "    out_orig = torch.tensor([10, 20, 41])\n",
        "    out = torch.sum(torch.sum(in1, 1), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['sum', torch.sum(in1, 1), [in1]])\n",
        "    domain_io.append(['sum', torch.sum(torch.sum(in1, 1), 1), [torch.sum(in1, 1)]])\n",
        "\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Composite26()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "64b4b126-aac7-451d-b1bc-2e0172334d4e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "405a3cf7-3c6c-4550-ae9f-cfaab334876c",
        "executionStartTime": 1632947659565,
        "executionStopTime": 1632947659576
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite27():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([0, 3, 5, 6])\n",
        "    out_orig = torch.tensor([1, 0, 0, 1, 0, 1, 1, 0])\n",
        "    out = torch.sum(torch.nn.functional.one_hot(in1, 8), 0)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(in1, 8), [in1, torch.tensor(8)]])\n",
        "    domain_io.append(['max', torch.max(torch.nn.functional.one_hot(in1, 8), 0)[0], [torch.nn.functional.one_hot(in1, 8)]])\n",
        "\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite27()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "be01905c-ad66-4cd8-924d-93245b80b346",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8e9f176e-18ac-4e92-8592-c509a3d38fe2",
        "executionStartTime": 1632947659637,
        "executionStopTime": 1632947659756
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite29():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21])\n",
        "    in2 = torch.tensor([12, 0, 10, 23, 16])\n",
        "    out_orig = torch.tensor([6, 0, 5, 11, 8])\n",
        "    out = torch.searchsorted(in1, in2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['searchsorted', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite29()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "389c935f-f4b2-4fda-b963-1777cfa7447e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "7724f0db-eb1d-4ee4-9eda-4514313502a6",
        "executionStartTime": 1632947659783,
        "executionStopTime": 1632947659895
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "import math\n",
        "def Composite30():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "    in2 = torch.tensor([[9.0, 4.0], [8.0, 5.0], [7.0, 6.0]])\n",
        "    out_orig = torch.tensor([[math.sqrt(68), math.sqrt(58), math.sqrt(52)],\n",
        "                  [math.sqrt(36), math.sqrt(26), math.sqrt(20)],\n",
        "                  [math.sqrt(20), math.sqrt(10), math.sqrt(4)]])\n",
        "    out = torch.cdist(in1, in2)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['cdist', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite30()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "29ae79e5-479f-41b2-8aad-5608caafcf0d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2c03b3bb-49ac-41ea-a1ed-c853dbf2394e",
        "executionStartTime": 1632947659900,
        "executionStopTime": 1632947659997
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite32():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[1, 6, 2, 1], [3, 1, 4, 2], [2, 1, 2, 5]])\n",
        "    out_orig = torch.tensor([13, 15, 20])\n",
        "    out = torch.tensordot(in1, torch.arange(4), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.arange(4), []])\n",
        "    domain_io.append(['tensordot', torch.tensordot(in1, torch.arange(4), 1), [in1, torch.arange(4)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite32()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "96e8507c-febc-486b-aa4a-855f8413de0e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "91ed0f17-a89f-4357-bfc7-606153341737",
        "executionStartTime": 1632947660006,
        "executionStopTime": 1632947660183
      },
      "source": [
        "def Composite34():\n",
        "    in1 = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[10, 20], [30, 40]]])\n",
        "    in2 = torch.tensor([3, 5, 10])\n",
        "    out_orig = torch.tensor([[128, 236], [344, 452]])\n",
        "    out = torch.tensordot(in2, in1, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite34()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c0cd4ad7-8db9-47ab-89bf-dd5b8bac7c1c",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "1f19b859-7b59-44b4-bce9-d23f95d0831e",
        "executionStartTime": 1632947660187,
        "executionStopTime": 1632947660311
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite36():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([1, 0, 1, 1, 0, 1, 0, 1])\n",
        "    out_orig = torch.tensor([1.0, 0.0, 0.333333, 0.25, 0.0, 0.166667, 0.0, 0.125])\n",
        "    out = torch.div(in1, torch.add(in1, torch.arange(8)))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(out_orig, out_orig.shape, out_orig.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['arange', torch.arange(8), []])\n",
        "    domain_io.append(['add', torch.add(in1, torch.arange(8)), [in1, torch.arange(8)]])\n",
        "    domain_io.append(['div', torch.div(in1, torch.add(in1, torch.arange(8))), [in1, torch.add(in1, torch.arange(8))]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite36()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "213cce3e-9162-4e38-941a-c29b36a354a6",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8068690a-1184-46f7-a018-1cadc3fe6b7e",
        "executionStartTime": 1632947660371,
        "executionStopTime": 1632947660510
      },
      "source": [
        "def Composite37():\n",
        "    in1 = torch.tensor([\n",
        "                    [\n",
        "                        [[10, 20, 30], [40, 50, 60]],\n",
        "                        [[12, 34, 56], [78, 98, 76]],\n",
        "                    ]\n",
        "                ])\n",
        "    in2 = torch.tensor([5, 10, 20])\n",
        "    out_orig = torch.tensor([[[850, 1900], [1520, 2890]]])\n",
        "    out = torch.tensordot(in1, in2, 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['tensordot', out, [in1, in2]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite37()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "638c40c9-3c66-4ab6-b249-f02431bb45ce",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "40bcea97-49ca-4552-a753-fdfcadbc9f85",
        "executionStartTime": 1632947660614,
        "executionStopTime": 1632947660659
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite39():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([[15, 10, 9, 20], [11, 0, 1, 9], [10, 1, 11, 25]])\n",
        "    out_orig = torch.tensor([\n",
        "                [225, 100, 81, 400],\n",
        "                [121, 0, 1, 81],\n",
        "                [100, 1, 121, 625],\n",
        "            ])\n",
        "    out = torch.square(torch.mul(in1, in1.bool()))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['mul', torch.mul(in1, in1.bool().long()), [in1, in1.bool().long()]])\n",
        "    domain_io.append(['square', torch.square(torch.mul(in1, in1.bool().long())), [torch.mul(in1, in1.bool().long())]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite39()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b9bced65-4b17-4d4e-8131-d536c3a7b963",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "19eec834-4e1f-411b-99f9-05fa911c1825",
        "executionStartTime": 1632947660708,
        "executionStopTime": 1632947660785
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite41():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([5, 2, 8, 2, 4, 1, 1, 0, 2, 1])\n",
        "    in2 = 3\n",
        "    out_orig = torch.tensor([5, 2, 8, 4, 1, 1, 0, 2, 1])\n",
        "    out = torch.masked_select(in1, torch.ne(torch.arange(10), in2))\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['arange', torch.arange(10),[]])\n",
        "    domain_io.append(['ne', torch.ne(torch.arange(10), in2), [torch.arange(10), torch.tensor(3)]])\n",
        "    domain_io.append(['masked_select',torch.masked_select(in1, torch.ne(torch.arange(10), in2)), [in1, torch.ne(torch.arange(10), in2)]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite41()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6931329a-fa8e-44dc-8f6f-88dd9a3d318c",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "aa8000d6-e6b3-4fd9-922e-baaaaccb6cdf",
        "executionStartTime": 1632947660833,
        "executionStopTime": 1632947660921
      },
      "source": [
        "def Composite42():\n",
        "    in1 = torch.tensor([4, 6, 2, 6, 7, 3, 3])\n",
        "    out_orig = torch.tensor([0, 0, 0, 0, 1, 0, 0]).int()\n",
        "    out = torch.eq(in1, 7)\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['eq', torch.eq(in1, 7), [in1, torch.tensor(7)]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite42()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "aeedff7f-cc0a-4044-9194-6ce2b9ed1c58",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "a3d50df3-d3d2-4ff4-ba02-9f9efdcf26be",
        "executionStartTime": 1632947660990,
        "executionStopTime": 1632947661119
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite44():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([\n",
        "                    [3, 5, 2],\n",
        "                    [6, 2, 3],\n",
        "                    [8, 7, 1],\n",
        "                    [0, 3, 5],\n",
        "                    [4, 7, 3],\n",
        "                    [2, 1, 6],\n",
        "                    [10, 20, 30],\n",
        "                    [4, 5, 6],\n",
        "                ])                \n",
        "    out_orig = torch.tensor([[9, 7, 5], [8, 19, 6], [6, 8, 9], [14, 25, 36]])\n",
        "    out = torch.sum(torch.reshape(in1, (-1, 2, 3)), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['reshape', torch.reshape(in1, (-1, 2, 2)), [in1]])\n",
        "    domain_io.append(['sum', torch.sum(torch.reshape(in1, (-1, 2, 3)), 1), [torch.reshape(in1, (-1, 2, 2))]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite44()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "2b314674-2735-4ffd-b908-e28bb641b1b3",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "712b0ad9-e9af-4569-8ff4-7d4e60fa308d",
        "executionStartTime": 1632947661129,
        "executionStopTime": 1632947661187
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite45():\n",
        "  if is16 == True:\n",
        "        return\n",
        "  in1 = torch.tensor([1, 0, 1, 0, 1])\n",
        "  in2 = torch.tensor([[[12, 34], [56, 78], [23, 54], [76, 78], [42, 24]]])\n",
        "  out_orig = torch.tensor([[[34, 12],\n",
        "         [56, 78],\n",
        "         [54, 23],\n",
        "         [76, 78],\n",
        "         [24, 42]]])\n",
        "  out = torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2)\n",
        "\n",
        "  print(in1, in1.shape)\n",
        "  print(in2, in2.shape)\n",
        "  print(out, out.shape)\n",
        "  print(torch.equal(out, out_orig))\n",
        "  \n",
        "  domain_io = []\n",
        "  domain_io.append(['unsqueeze', torch.unsqueeze(in1, 1), [in1]])\n",
        "  domain_io.append(['roll', torch.roll(in2, 1, -1), [in2]])\n",
        "  domain_io.append(['where', torch.where(torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2), [torch.unsqueeze(in1, 1).bool(), torch.roll(in2, 1, -1), in2]])\n",
        "  X, Y = embed_tensor_for_model(domain_io)\n",
        "  query_model(X, Y)\n",
        "\n",
        "Composite45()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "674938c7-f12c-4788-9b97-2d2e1ed4e3f9",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "4a6b3c67-dd9b-445d-8140-d9bcff0b054f",
        "executionStartTime": 1632947661197,
        "executionStopTime": 1632947661327
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite46():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([3, 4, 1])\n",
        "    out_orig = torch.tensor([0, 0, 0, 1, 1, 1, 1, 2])\n",
        "    out = torch.repeat_interleave(torch.arange(3), in1, 0)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "    domain_io.append(['arange', torch.arange(3), []])\n",
        "    domain_io.append(['repeat_interleave', torch.repeat_interleave(torch.arange(3), in1, 0), [torch.arange(3)]])\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite46()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1ea44d6c-6cdf-459e-b5aa-25e989c569e5",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "4281213d-295f-4d90-a295-edd8171bf0ec",
        "executionStartTime": 1632947661369,
        "executionStopTime": 1632947661379
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite48():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor([32, 53, 45, 38, 29, 89, 64, 23])\n",
        "    in2 = torch.tensor([38, 53, 89, 38, 32, 64])\n",
        "    out_orig = torch.tensor([3, 1, 5, 3, 0, 6])\n",
        "    out = torch.argmax(torch.eq(in1, torch.unsqueeze(in2, 1)).int(), 1)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    print('torch.unsqueeze(in1, 1)', torch.unsqueeze(in1, 1))\n",
        "    print('torch.eq(in2, torch.unsqueeze(in1, 1)).float()', torch.eq(in2, torch.unsqueeze(in1, 1)).int())\n",
        "    print('torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1)', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).int(), 1))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['unsqueeze', torch.unsqueeze(in1, 1).float(), [in1]])\n",
        "    domain_io.append(['eq', torch.eq(in2, torch.unsqueeze(in1, 1)).float(), [in2,torch.unsqueeze(in1, 1).float()]])\n",
        "    domain_io.append(['argmax', torch.argmax(torch.eq(in2, torch.unsqueeze(in1, 1)).float(), 1), [torch.eq(in2, torch.unsqueeze(in1, 1)).float()]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite48()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ef9f3cb7-de3b-4b42-b2da-67c95a87cf31",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "096352b5-a499-4316-9788-8e703f7798ca",
        "executionStartTime": 1632947661428,
        "executionStopTime": 1632947661470
      },
      "source": [
        "def Composite49():\n",
        "    in1 = torch.tensor([\n",
        "                    [[[1, 2, 3], [4, 5, 6]]],\n",
        "                    [[[8, 10, 0], [6, 4, 2]]],\n",
        "                    [[[9, 8, 7], [1, 2, 3]]],\n",
        "                ])\n",
        "    in2 = torch.tensor([20, 5, 10])\n",
        "    out_orig = torch.tensor([\n",
        "                [[[20, 40, 60], [80, 100, 120]]],\n",
        "                [[[40, 50, 0], [30, 20, 10]]],\n",
        "                [[[90, 80, 70], [10, 20, 30]]],\n",
        "            ])\n",
        "    out = torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(in2, in2.shape, in2.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['transpose', torch.transpose(in1, 0, 3), [in1]])\n",
        "    domain_io.append(['mul', torch.mul(in2, torch.transpose(in1, 0, 3)), [in2,torch.transpose(in1, 0, 3)]])\n",
        "    domain_io.append(['transpose', torch.transpose(torch.mul(in2, torch.transpose(in1, 0, 3)), 0, 3), [torch.mul(in2, torch.transpose(in1, 0, 3))]])\n",
        "\n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "Composite49()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "0170058a-d292-4c82-a3b6-5c13a6567b72",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "413dc996-16e4-40a5-aed5-2611d9047d95",
        "executionStopTime": 1632947661541,
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1632947661517
      },
      "source": [
        "# NOT SUPPORTED BY 16 APIs\n",
        "def Composite50():\n",
        "    if is16 == True:\n",
        "        return\n",
        "    in1 = torch.tensor(3)\n",
        "    out_orig = torch.tensor([\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "                [0, 0, 0, 1, 0, 0],\n",
        "            ])\n",
        "    out = torch.nn.functional.one_hot(in1.expand(5), 6)\n",
        "\n",
        "    print(in1, in1.shape, in1.dtype)\n",
        "    print(out, out.shape, out.dtype)\n",
        "    print(torch.equal(out, out_orig))\n",
        "\n",
        "    domain_io = []\n",
        "\n",
        "    domain_io.append(['expand', torch.tensor(3).expand((5,)), [torch.tensor(3)]])\n",
        "    domain_io.append(['one_hot', torch.nn.functional.one_hot(in1, 6), [in1, torch.tensor(6)]])\n",
        "    \n",
        "    X, Y = embed_tensor_for_model(domain_io)\n",
        "    query_model(X, Y)\n",
        "\n",
        "\n",
        "Composite50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "726713b4-1d86-43c7-8a0d-6b2c1b564c63",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "dedb4701-7108-442e-b74b-2f15ae101f01",
        "executionStartTime": 1632947661597,
        "executionStopTime": 1632947661647
      },
      "source": [
        "print_stat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "d69ad708-1305-4ed3-9872-cf74a928cad8",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ded01be5-e121-47e9-8379-9f96a903bd45",
        "executionStartTime": 1632947661728,
        "executionStopTime": 1632947661776
      },
      "source": [
        "tc = 0\n",
        "for t in sorted(total_correct):\n",
        "    tc +=  total_correct[t]\n",
        "    print(t, total_correct[t], tc/(total_benchmark-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "cb1a3dc1-da4a-4590-96f7-f21367efe4e7",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "1b6c6a6c-cffe-405e-85a4-06baff65d473",
        "executionStartTime": 1632947661787,
        "executionStopTime": 1632947661794
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
