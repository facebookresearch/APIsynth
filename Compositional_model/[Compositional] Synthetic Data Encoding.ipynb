{
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "bento_kernel_pytorch",
      "metadata": {
        "kernel_name": "bento_kernel_pytorch",
        "nightly_builds": true,
        "fbpkg_supported": true,
        "is_prebuilt": true
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "captumWidgetMessage": {},
    "last_msg_id": "be0545fa-7ee8a73abf2fc8a568a6c5e1_232",
    "last_server_session_id": "885abd8f-39a0-4cff-8d8f-d0f2a237a6eb",
    "last_kernel_id": "d71359d7-79f4-424e-b1d8-ab948f1047fa",
    "last_base_url": "https://devvm3095.ftw0.facebook.com:8090/",
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "originalKey": "2edb6939-2f73-40b4-9f9d-1e8cdef4e9c5",
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "255d914b-38b9-4da7-930d-2475bd312865",
        "executionStartTime": 1630674498074,
        "executionStopTime": 1630674498920
      },
      "source": [
        "import random\n",
        "from random import choice\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1648ab7a-21fb-41e9-bead-a4711d5d0406",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "f03c555d-ffb7-4fef-b7aa-d06cbbe45729",
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1630674500302,
        "executionStopTime": 1630674500313
      },
      "source": [
        "class pycoder_parameters:\n",
        "\n",
        "    ''' Path '''\n",
        "    Path = 'gen1_33' #'exhaustive_17api' #'seq_30api'\n",
        "\n",
        "    ''' Core Fuzzing Parameters '''\n",
        "    NUM_FUZZ_PER_API= 100001 #000\n",
        "    NUM_TEST_FUZZ = 2\n",
        "    FLOAT_TENSOR = False #We either generate float or integer tensors\n",
        "    UNIT_TEST = False\n",
        "    COMPOSITE = True\n",
        "\n",
        "    ''' Fuzzing Detailed Parameters '''\n",
        "    MAX_TENSOR_DIMENSIONS = 3 #how many rows, columns, etc.\n",
        "    MIN_VAL_PER_DIMENSION = 1 # e.g., min number of rows, columns, etc. \n",
        "    MAX_VAL_PER_DIMENSION = 5 # e.g., max number of rows, columns, etc. \n",
        "\n",
        "    #So far limiting to integers\n",
        "    MIN_TENSOR_VALUE = 1\n",
        "    MAX_TENSOR_VALUE = 15\n",
        "    \n",
        "\n",
        "    ''' Embedding Parameters '''\n",
        "    EMBEDDING_NOISE_LEVEL = 0 #0 noise by default\n",
        "    EMBEDDING_SIZE = 150\n",
        "    SHAPE_EMBEDDING_SIZE = 6\n",
        "\n",
        "\n",
        "    data_type = 'float' if FLOAT_TENSOR is  True else 'integer'\n",
        "    model_type = 'Composite_' if COMPOSITE is  True else 'Single_'\n",
        "    file_name = str(model_type) + str(NUM_FUZZ_PER_API) + '_' + data_type\n",
        "    fuzzing   = file_name + '.pt'\n",
        "    embedding = file_name + '.embedding' + '.pt',\n",
        "    classification = file_name + '.model_result' + '.pt' \n",
        "    train_valid_test = file_name + 'train_valid_test.pt'\n",
        "\n",
        "    def setNoiseLevel(self, noise):\n",
        "        self.EMBEDDING_NOISE_LEVEL = noise\n",
        "        self.embedding = self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt'\n",
        "\n",
        "    def getEmbeddingFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt')\n",
        "\n",
        "    def getVisulizationFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '_' +  'tSNE.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6ce47f64-f5d0-46b9-876f-e07c51de84ed",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "7b2ebf7d-db3d-449d-a05b-ecc7c5c0d68b",
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1630674503209,
        "executionStopTime": 1630674503230
      },
      "source": [
        "NOISE = 0\n",
        "f = pycoder_parameters()\n",
        "f.setNoiseLevel(NOISE)\n",
        "f.embedding = f.getEmbeddingFile() \n",
        "print(f.embedding)\n",
        "print(f.SHAPE_EMBEDDING_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7dd57e12-0531-4627-8e72-e754ac7feee2",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "71d40835-61ce-4b64-a944-9e3e3d4299dc",
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1630674504852,
        "executionStopTime": 1630674504952
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "def add_noise(orig_tensor):\n",
        "    \n",
        "    orig_tensor = orig_tensor.double()\n",
        "    data = torch.flatten(orig_tensor).numpy()\n",
        "\n",
        "    zero_like = torch.flatten(torch.zeros_like(orig_tensor,dtype=bool))\n",
        "\n",
        "    mask = zero_like.numpy()\n",
        "\n",
        "    elem_size = np.prod(list(orig_tensor.shape))\n",
        "    N =  int(elem_size * f.EMBEDDING_NOISE_LEVEL)\n",
        "    \n",
        "    # # marking first n indexes as true\n",
        "    mask[:N] = True\n",
        "    \n",
        "    # # shuffling the mask\n",
        "    np.random.shuffle(mask)\n",
        "    \n",
        "    # # applying mask to the data\n",
        "    data[mask] = 0\n",
        "    return(torch.Tensor(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "23468c5c-046d-4467-820b-24041218e0d6",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "07fb1d61-30ec-443f-965b-5f7ea37d2f0d",
        "executionStartTime": 1630674506938,
        "executionStopTime": 1630674507027
      },
      "source": [
        "import sklearn.datasets\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "EMBEDDING_SIZE = f.EMBEDDING_SIZE\n",
        "SHAPE_EMBEDDING_SIZE = f.SHAPE_EMBEDDING_SIZE\n",
        "\n",
        "def encode_values_to_code(tensor):\n",
        "    tensor = tensor.clone()\n",
        "    tensor[(tensor>=100) & (tensor<1000)] = 100\n",
        "    tensor[(tensor>=1000)] = 101\n",
        "    tensor[(tensor<=-20) & (tensor>-100)] = -20\n",
        "    tensor[(tensor<=-100) & (tensor>-1000)] = -21\n",
        "    tensor[(tensor<=-1000)] = -22\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def tensor_flatten_pad(tensor, embed_size=EMBEDDING_SIZE, shape_embed_size=SHAPE_EMBEDDING_SIZE, isNoise=False):\n",
        "    \n",
        "    t_flatten = torch.flatten(tensor)\n",
        "\n",
        "    if isNoise is True:\n",
        "        t_flatten = add_noise(t_flatten)\n",
        "    padding_length = embed_size - list(t_flatten.shape)[-1]\n",
        "    p1d = (0,padding_length) #just padding the last dimension\n",
        "    t_pad = F.pad(input=t_flatten, pad=p1d, mode='constant', value=0).type(torch.FloatTensor)\n",
        "    \n",
        "    type_padding = 0\n",
        "    if tensor.dtype == torch.bool:\n",
        "        type_padding = 1\n",
        "    elif tensor.dtype == torch.float64 \\\n",
        "        or tensor.dtype == torch.double \\\n",
        "        or tensor.dtype == torch.float32 \\\n",
        "        or tensor.dtype == torch.float16:\n",
        "            type_padding = 2\n",
        "    \n",
        "\n",
        "    '''size embedding'''\n",
        "    if(shape_embed_size > 0):\n",
        "        t_shape = list(tensor.shape)\n",
        "        padding_length = shape_embed_size -1 - len(t_shape)\n",
        "        p1d = (0,padding_length) #just padding the last dimension\n",
        "        s_pad = F.pad(input=torch.Tensor(t_shape), pad=p1d, mode='constant', value=0).type(torch.float)\n",
        "\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        s_pad_list = s_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1] + s_pad_list + [-1])\n",
        "    \n",
        "    else:\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1])\n",
        "        \n",
        "    encoded_tensor = encode_values_to_code(tensor_embedding)\n",
        "    return(encoded_tensor)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "77378f71-0b4b-4206-b446-5a18b23e9128",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "81af520f-237f-45b2-b9b1-bd80aa46ee7d",
        "executionStartTime": 1630674511683,
        "executionStopTime": 1630674511705
      },
      "source": [
        "import itertools\n",
        "from random import sample\n",
        "\n",
        "def split_dataset(orig_dataset, train_frac=0.9):\n",
        "\n",
        "    print('len orig_dataset', len(orig_dataset))\n",
        "  \n",
        "    dataset =  orig_dataset #sample(orig_dataset,len(orig_dataset)//10)\n",
        "\n",
        "    print('len dataset', len(dataset))\n",
        "\n",
        "    length = len(dataset)\n",
        "    train_length = int(length * train_frac)\n",
        "    valid_length = int((length - train_length) / 2)\n",
        "    test_length  = length - train_length - valid_length\n",
        "\n",
        "    print(train_length, valid_length, test_length)\n",
        "\n",
        "    idx = list(range(length))  # indices to all elements\n",
        "    random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
        "    train_idx = idx[:train_length]\n",
        "    val_idx = idx[train_length:(train_length + valid_length)]\n",
        "    test_idx = idx[(train_length + valid_length):]\n",
        "\n",
        "    train_set = [dataset[i] for i in train_idx]\n",
        "    valid_set = [dataset[i] for i in val_idx]\n",
        "    test_set = [dataset[i] for i in test_idx]\n",
        "\n",
        "\n",
        "    print(len(train_set), len(valid_set), len(test_set))\n",
        "    return(train_set, valid_set, test_set)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "49a60925-b4e8-48fe-b126-2955f25ed9c9",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "89d5755d-293c-4aa4-aad5-e265d576caf8",
        "executionStartTime": 1630674513207,
        "executionStopTime": 1630674513231
      },
      "source": [
        "def split_training_data(orig_dataset, train_frac=0.5):\n",
        "\n",
        "    print('len orig_dataset', len(orig_dataset))\n",
        "  \n",
        "    dataset =  orig_dataset #sample(orig_dataset,len(orig_dataset)//10)\n",
        "\n",
        "    print('len dataset', len(dataset))\n",
        "\n",
        "    length = len(dataset)\n",
        "    train_length = int(length * train_frac)\n",
        "    pretrain_length = int((length - train_length))\n",
        "    \n",
        "    print(train_length, pretrain_length)\n",
        "\n",
        "    idx = list(range(length))  # indices to all elements\n",
        "    random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
        "    train_idx = idx[:train_length]\n",
        "    pretrain_idx = idx[train_length:]\n",
        "\n",
        "    train_set = [dataset[i] for i in train_idx]\n",
        "    pretrain_set = [dataset[i] for i in pretrain_idx]\n",
        "\n",
        "\n",
        "    print(len(train_set), len(pretrain_set))\n",
        "    return(train_set, pretrain_set)\n",
        "#train_set, pretrain_set = split_training_data(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7903de91-69f2-4c2f-b775-2ffa68a5b0ce",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "69e0fc8e-d0d3-4d38-bfe5-775178cccd6a",
        "executionStartTime": 1630616000387,
        "executionStopTime": 1630616000433
      },
      "source": [
        "api2indx = torch.load('exhaustive_17api/api2indx.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "428acbf3-ec4a-4b45-b457-40eb6ee65169",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ddc61ece-c8ea-44ed-80c6-a88510a2dbca",
        "executionStartTime": 1630674522744,
        "executionStopTime": 1630674522832
      },
      "source": [
        "api2indx = {}\n",
        "api2indx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "97f21202-12da-4617-9056-c08070075589",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "d8204cce-d6c3-445c-982d-19c3f0325233",
        "executionStartTime": 1630530486156,
        "executionStopTime": 1630530486172
      },
      "source": [
        "all_x_values = []\n",
        "def remove_duplicate(x):\n",
        "    for i in all_x_values:\n",
        "        if torch.equal(i,x) is True:\n",
        "            return(True)\n",
        "    return(False)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "4ff0c499-e90a-4312-a30f-b33e945b4131",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "cbd12aba-2e44-4659-8cc6-0016d9b12d45",
        "executionStartTime": 1630674525970,
        "executionStopTime": 1630674525976
      },
      "source": [
        "def load_training_data(dataset):\n",
        "       \n",
        "    global EMBEDDING_SIZE\n",
        "    global api2indx\n",
        "    \n",
        "    X=[]\n",
        "    y=[]\n",
        "    dict_indx = len(api2indx)\n",
        "    for data_list in dataset:\n",
        "        if data_list[-1] == -1:\n",
        "            continue\n",
        "        final_output = data_list[-1][1]\n",
        "        prev_out = torch.Tensor()\n",
        "        api_seq_x = []\n",
        "        api_seq_y = []\n",
        "        for data in data_list:        \n",
        "            if data == -1:\n",
        "                continue    \n",
        "            api = data[0]\n",
        "            if api2indx.get(api, -1) == -1: \n",
        "                api2indx[api] = dict_indx\n",
        "                dict_indx += 1\n",
        "                 \n",
        "            api_indx = api2indx[api]\n",
        "            input_list = data[2] #.get_input()\n",
        "            output_tensor = final_output #data.get_output()\n",
        "\n",
        "            it_pad = []\n",
        "            for input_tensor in input_list:\n",
        "                if input_tensor.shape == prev_out.shape and torch.all(input_tensor.eq(prev_out)).item():\n",
        "                    #same with previous output\n",
        "                    t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                    t[-1] = -1\n",
        "                    it_pad.append(t)\n",
        "                else:         \n",
        "                    #flatten the input tensor\n",
        "                    it_pad.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "                \n",
        "            #adding addidional tensors with zero embeddings for < 2 tensors\n",
        "            for i in range(len(it_pad),3):\n",
        "                t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                t[-1] = -1\n",
        "                it_pad.append(t)\n",
        "                \n",
        "            ot_pad = tensor_flatten_pad(output_tensor, isNoise=True)\n",
        "            x = T.flatten(T.stack((it_pad[0],it_pad[1], it_pad[2], ot_pad)))      \n",
        "            api_seq_x.append(x) \n",
        "            api_seq_y.append(api_indx)\n",
        "            prev_out = data[1]\n",
        "        X.append(api_seq_x)\n",
        "        y.append(api_seq_y)\n",
        "    print(len(X), len(y))\n",
        "    return(X,y)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a465364d-a235-4829-bedd-d88f95fb7281",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "e8b40574-563a-44e5-8ef9-5e7707cc6a01",
        "executionStartTime": 1630614089603,
        "executionStopTime": 1630614089691
      },
      "source": [
        "def shuffle_dataset(X_dataset, Y_dataset):\n",
        "\n",
        "    print('len orig_dataset', len(X_dataset),  len(Y_dataset))\n",
        "  \n",
        "    length = len(X_dataset)\n",
        "\n",
        "    idx = list(range(length))  # indices to all elements\n",
        "    random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
        "    data_idx = idx[:]\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    x = [X_dataset[i] for i in data_idx]\n",
        "    y = [Y_dataset[i] for i in data_idx]\n",
        "\n",
        "    print(len(x), len(y))\n",
        "    return(x,y)\n",
        "\n",
        "''' Test '''\n",
        "x = [1,2,3,4]\n",
        "y = [5,6,7,8]\n",
        "\n",
        "x, y = shuffle_dataset(x,y)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6953e01e-05dc-4b6a-9898-4f5c63df8aed",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b33081f3-9706-4b15-b580-ea2274e25156",
        "executionStartTime": 1630674535274,
        "executionStopTime": 1630674535303
      },
      "source": [
        "f.setNoiseLevel(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "75bf0662-ce2a-41ba-84ba-d894b9713fe1",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ebeab2b8-d280-4c8a-8d1d-b7c1330f7f0d",
        "executionStartTime": 1629566793375,
        "executionStopTime": 1629566793411
      },
      "source": [
        "def load_pretraining_data0(dataset):\n",
        "       \n",
        "    global EMBEDDING_SIZE\n",
        "    global api2indx\n",
        "    \n",
        "    X=[]\n",
        "    y=[]\n",
        "    dict_indx = len(api2indx)\n",
        "    for data_list in dataset:\n",
        "        if data_list[-1] == -1:\n",
        "            continue\n",
        "        api_seq_x = []\n",
        "        api_seq_y = []\n",
        "        for data in data_list:   \n",
        "            if data == -1:\n",
        "                continue      \n",
        "            api = data[0]\n",
        "            if api2indx.get(api, -1) == -1: \n",
        "                api2indx[api] = dict_indx\n",
        "                dict_indx += 1\n",
        "                    \n",
        "            api_indx = api2indx[api]\n",
        "            \n",
        "            input_list = data[2]\n",
        "            output_tensor = data[1] \n",
        "\n",
        "            it_pad = []\n",
        "\n",
        "            for input_tensor in input_list:\n",
        "                it_pad.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "                \n",
        "            \n",
        "            #adding addidional tensors with zero embeddings for < 3 tensors\n",
        "            for i in range(len(it_pad),3):\n",
        "                t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                t[-1] = -1\n",
        "                it_pad.append(t)\n",
        "                \n",
        "            ot_pad = tensor_flatten_pad(output_tensor, isNoise=True)\n",
        "            x = T.flatten(T.stack((it_pad[0],it_pad[1], it_pad[2], ot_pad)))      \n",
        "        \n",
        "            api_seq_x.append(x) \n",
        "            api_seq_y.append(api_indx)\n",
        "\n",
        "        X.append(api_seq_x)\n",
        "        y.append(api_seq_y)\n",
        "\n",
        "    \n",
        "  \n",
        "    print(len(X), len(y))\n",
        "\n",
        "    return(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1e972ffe-9df9-4c33-94d4-c1799e3da44a",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ac99b814-4acc-4df1-9396-2579226f8422",
        "executionStartTime": 1629566794341,
        "executionStopTime": 1629566794383
      },
      "source": [
        "def load_pretraining_data1(dataset):\n",
        "       \n",
        "    global EMBEDDING_SIZE\n",
        "    global api2indx\n",
        "    \n",
        "    X=[]\n",
        "    y=[]\n",
        "    dict_indx = len(api2indx)\n",
        "    for data_list in dataset:\n",
        "        if data_list[-1] == -1:\n",
        "            continue\n",
        "        final_output = data_list[-1][1]\n",
        "        prev_out = torch.Tensor()\n",
        "        api_seq_x = []\n",
        "        api_seq_y = []\n",
        "        for data in data_list:  \n",
        "            if data == -1:\n",
        "                continue          \n",
        "            api = data[0]\n",
        "            if api2indx.get(api, -1) == -1: \n",
        "                api2indx[api] = dict_indx\n",
        "                dict_indx += 1\n",
        "                 \n",
        "            api_indx = api2indx[api]\n",
        "            input_list = data[2] #.get_input()\n",
        "            output_tensor = final_output #data.get_output()\n",
        "\n",
        "            it_pad = []\n",
        "            for input_tensor in input_list:\n",
        "                it_pad.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "                \n",
        "            #adding addidional tensors with zero embeddings for < 2 tensors\n",
        "            for i in range(len(it_pad),3):\n",
        "                t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                t[-1] = -1\n",
        "                it_pad.append(t)\n",
        "                \n",
        "            ot_pad = tensor_flatten_pad(output_tensor, isNoise=True)\n",
        "            x = T.flatten(T.stack((it_pad[0],it_pad[1], it_pad[2], ot_pad)))      \n",
        "            api_seq_x.append(x) \n",
        "            api_seq_y.append(api_indx)\n",
        "            prev_out = data[1]\n",
        "        X.append(api_seq_x)\n",
        "        y.append(api_seq_y)\n",
        "    print(len(X), len(y))\n",
        "    return(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "70b0a8bf-ea5d-42cd-b18a-0eeee7980398",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "8d4cc777-9778-418f-afd7-a2d65274cf77",
        "executionStartTime": 1630530633157,
        "executionStopTime": 1630530633203
      },
      "source": [
        "api2indx = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "e11657b6-67a2-4db6-90b6-e7ad50fbc5ed",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "Traing/Pretraining Embedding Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "5419dd87-80af-40c7-9776-cf321de1f6ff",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "aaea5110-a16a-4405-a222-21a90716654e",
        "executionStartTime": 1630530634850,
        "executionStopTime": 1630530638243
      },
      "source": [
        "SAVE_FILE = f.fuzzing\n",
        "for i in range(4,7):\n",
        "    fuzz_file = f.Path + '/fuzzing_data/' + str(i*10000) + '_' + SAVE_FILE\n",
        "    embed_file = f.Path + '/pretraining_embeddings0/' + str(i*10000) + '_pretraining_embedding0.pt' #+ f.embedding\n",
        "    print(fuzz_file, embed_file)\n",
        "    l = torch.load(fuzz_file)\n",
        "    x, y = load_pretraining_data0(l)\n",
        "    torch.save((x,y),embed_file)\n",
        "    print('saving done')\n",
        "    l.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "58be58ec-64f5-41cc-9458-d4c2b70c0500",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b34a4211-1b04-4c9d-ba72-5248867260d5",
        "executionStartTime": 1630686201388,
        "executionStopTime": 1630693030212
      },
      "source": [
        "SAVE_FILE = f.fuzzing\n",
        "for i in range(4,6):\n",
        "    fuzz_file = f.Path + '/fuzzing_data/' + str(i*10000) + '_' + SAVE_FILE\n",
        "    embed_file = f.Path + '/training_embeddings/' + str(i*10000) + '_training_embedding.pt' #+ f.embedding\n",
        "    print(fuzz_file, embed_file)\n",
        "    l = torch.load(fuzz_file)\n",
        "    x, y = load_training_data(l)\n",
        "    torch.save((x,y),embed_file)\n",
        "    if i == 1:\n",
        "        torch.save(api2indx, f.Path + '/api2indx.pt')\n",
        "    print('saving done')\n",
        "    l.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f20da14b-3247-4156-bdaa-49b358fda968",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c20001fa-531d-4a22-9baa-2d321196145f",
        "executionStartTime": 1630342433152,
        "executionStopTime": 1630346440657
      },
      "source": [
        "SAVE_FILE = f.fuzzing\n",
        "for i in range(10,13):\n",
        "    fuzz_file = f.Path + '/fuzzing_data/' + str(2*i*1000) + '_' + SAVE_FILE\n",
        "    embed_file = f.Path + '/training_embeddings/' + str(2*i*1000) + '_training_embedding.pt' #+ f.embedding\n",
        "    print(fuzz_file, embed_file)\n",
        "    l = torch.load(fuzz_file)\n",
        "    x, y = load_training_data(l)\n",
        "    torch.save((x,y),embed_file)\n",
        "    if i == 1:\n",
        "        torch.save(api2indx, f.Path + '/api2indx.pt')\n",
        "    print('saving done')\n",
        "    del x\n",
        "    del y\n",
        "    del l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "de6c025f-78e2-4195-a1ca-070fe9c5c44e",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "01812303-ee35-4530-a463-16c01fc58ed8",
        "executionStartTime": 1630073527419,
        "executionStopTime": 1630073527485
      },
      "source": [
        "torch.save(api2indx, f.Path + '/api2indx.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "7e267118-a855-4370-805f-34c862be982d",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "200bed25-d154-441b-8a6c-fa20281b936e",
        "executionStartTime": 1629566814270,
        "executionStopTime": 1629571306540
      },
      "source": [
        "SAVE_FILE = f.fuzzing\n",
        "for i in range(1,4):\n",
        "    fuzz_file = f.Path + '/fuzzing_data/' + str(i*10000) + '_' + SAVE_FILE\n",
        "    embed_file = f.Path + '/pretraining_embeddings1/' + str(i*10000) + '_pretraining_embedding1.pt' #+ f.embedding\n",
        "    print(fuzz_file, embed_file)\n",
        "    l = torch.load(fuzz_file)\n",
        "    x, y = load_pretraining_data1(l)\n",
        "    torch.save((x,y),embed_file)\n",
        "    print('saving done')\n",
        "    l.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "38779e0d-9af7-4628-a134-e9b6ea51c6e2",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "2f88dc8c-6bda-4097-8e96-f74f18846524",
        "executionStartTime": 1629818347681,
        "executionStopTime": 1629818347840
      },
      "source": [
        "api2indx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a29ebb50-0565-4d37-b6e4-9bc00ee8f83c",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "69b2740a-c089-47d8-91bf-c4a9ca8e14f2",
        "executionStartTime": 1630630749041,
        "executionStopTime": 1630632351199
      },
      "source": [
        "SAVE_FILE = f.fuzzing\n",
        "i = 10\n",
        "fuzz_file = f.Path + '/fuzzing_data/' + str(i*10000) + '_' + SAVE_FILE\n",
        "embed_file = f.Path + '/' + str(i*10000) + '_test_embedding.pt' #+ f.embedding\n",
        "print(embed_file)\n",
        "l = torch.load(fuzz_file)\n",
        "test_set, valid_set = split_training_data(l)\n",
        "x, y = load_training_data(test_set)\n",
        "torch.save((x,y),embed_file)\n",
        "embed_file = f.Path + '/' + str(i*10000) + '_valid_embedding.pt' #+ f.embedding\n",
        "print(embed_file)\n",
        "x, y = load_training_data(valid_set)\n",
        "torch.save((x,y),embed_file)\n",
        "l.clear()\n",
        "print('saving done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "1b8f7a98-542f-4039-8895-3220e24d6421",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ded38bed-e27e-42a1-bd80-5f66ebe7c5dd",
        "executionStartTime": 1629406973403,
        "executionStopTime": 1629406973431
      },
      "source": [
        "api2indx = torch.load(f.Path + '/' + 'api2indx.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "79fbd159-29f5-41ef-a04d-18c3f4607786",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "2ccee2ae-68ed-4f58-a51a-69c2a50e060e",
        "executionStartTime": 1630102357766,
        "executionStopTime": 1630102357927
      },
      "source": [
        "api2indx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "21fef79d-1bf2-46e2-90d5-12bb6aba0df8",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "1d146b06-831c-437a-a711-542cca534fc4",
        "executionStartTime": 1629508771667,
        "executionStopTime": 1629508772797
      },
      "source": [
        "fuzz_file = f.Path + '/fuzzing_data/test.pt'\n",
        "embed_file = f.Path + '/test_embedding.pt' \n",
        "print(fuzz_file, embed_file)\n",
        "l = torch.load(fuzz_file)\n",
        "x, y = load_training_data(l)\n",
        "torch.save((x,y),embed_file)\n",
        "print('saving done')\n",
        "l.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "98a545ae-75d6-4681-9ab2-2dbdc176b0ea",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b17babbf-4e33-4a15-ad25-ef8fc3d54823",
        "executionStartTime": 1629508788556,
        "executionStopTime": 1629508789502
      },
      "source": [
        "fuzz_file = f.Path + '/fuzzing_data/valid.pt'\n",
        "embed_file = f.Path + '/valid_embedding.pt' \n",
        "print(fuzz_file, embed_file)\n",
        "l = torch.load(fuzz_file)\n",
        "x, y = load_training_data(l)\n",
        "torch.save((x,y),embed_file)\n",
        "print('saving done')\n",
        "l.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "9f8c2a35-0452-4a93-af92-9ad4f43a58e2",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "77a7ad4c-5fe1-442c-864d-04ea80cb96fb",
        "executionStartTime": 1630629166772,
        "executionStopTime": 1630629168618
      },
      "source": [
        "SAVE_FILE = f.fuzzing\n",
        "\n",
        "fuzz_file = 'exhaustive_17api/3seq_testing/try1/3seq_test_fuzzing.pt'\n",
        "embed_file =  'exhaustive_17api/3seq_testing/try1/test_embedding.pt' #+ f.embedding\n",
        "print(embed_file)\n",
        "l = torch.load(fuzz_file)\n",
        "x, y = load_training_data(l)\n",
        "torch.save((x,y),embed_file)\n",
        "l.clear()\n",
        "print('saving done')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
