{
  "metadata": {
    "bento_stylesheets": {
      "bento/extensions/flow/main.css": true,
      "bento/extensions/kernel_selector/main.css": true,
      "bento/extensions/kernel_ui/main.css": true,
      "bento/extensions/new_kernel/main.css": true,
      "bento/extensions/system_usage/main.css": true,
      "bento/extensions/theme/main.css": true
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "bento_kernel_pytorch",
      "metadata": {
        "kernel_name": "bento_kernel_pytorch",
        "nightly_builds": true,
        "fbpkg_supported": true,
        "is_prebuilt": true
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "captumWidgetMessage": {},
    "last_msg_id": "82cfe4c0-05710700782a2e188f36aad4_591",
    "last_server_session_id": "46807815-18e1-4f54-8601-8c6bcbbae5d1",
    "last_kernel_id": "e2996ce3-e160-427d-87f1-5c80a2a68d39",
    "last_base_url": "https://devvm3630.vll0.facebook.com:8090/",
    "outputWidgetContext": {}
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "originalKey": "c9cbbd0b-6cec-47b2-8337-05fd70905057",
        "code_folding": [],
        "hidden_ranges": [],
        "requestMsgId": "c9cbbd0b-6cec-47b2-8337-05fd70905057",
        "executionStartTime": 1632873035439,
        "executionStopTime": 1632873036163
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b167fc61-69da-47d1-9b71-87404eeb3d63",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "b167fc61-69da-47d1-9b71-87404eeb3d63",
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1632873037033,
        "executionStopTime": 1632873037046
      },
      "source": [
        "class pycoder_parameters:\n",
        "\n",
        "    ''' Path '''\n",
        "    Path = 'gen1_33' #'exhaustive_17api' #'seq_30api'\n",
        "\n",
        "    ''' Core Fuzzing Parameters '''\n",
        "    NUM_FUZZ_PER_API= 100001 #000\n",
        "    NUM_TEST_FUZZ = 2\n",
        "    FLOAT_TENSOR = False #We either generate float or integer tensors\n",
        "    UNIT_TEST = False\n",
        "    COMPOSITE = True\n",
        "\n",
        "    ''' Fuzzing Detailed Parameters '''\n",
        "    MAX_TENSOR_DIMENSIONS = 3 #how many rows, columns, etc.\n",
        "    MIN_VAL_PER_DIMENSION = 1 # e.g., min number of rows, columns, etc. \n",
        "    MAX_VAL_PER_DIMENSION = 5 # e.g., max number of rows, columns, etc. \n",
        "\n",
        "    #So far limiting to integers\n",
        "    MIN_TENSOR_VALUE = 1\n",
        "    MAX_TENSOR_VALUE = 15\n",
        "    \n",
        "\n",
        "    ''' Embedding Parameters '''\n",
        "    EMBEDDING_NOISE_LEVEL = 0 #0 noise by default\n",
        "    EMBEDDING_SIZE = 150\n",
        "    SHAPE_EMBEDDING_SIZE = 6\n",
        "\n",
        "\n",
        "    data_type = 'float' if FLOAT_TENSOR is  True else 'integer'\n",
        "    model_type = 'Composite_' if COMPOSITE is  True else 'Single_'\n",
        "    file_name = str(model_type) + str(NUM_FUZZ_PER_API) + '_' + data_type\n",
        "    fuzzing   = file_name + '.pt'\n",
        "    embedding = file_name + '.embedding' + '.pt',\n",
        "    classification = file_name + '.model_result' + '.pt' \n",
        "    train_valid_test = file_name + 'train_valid_test.pt'\n",
        "\n",
        "    def setNoiseLevel(self, noise):\n",
        "        self.EMBEDDING_NOISE_LEVEL = noise\n",
        "        self.embedding = self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt'\n",
        "\n",
        "    def getEmbeddingFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '.pt')\n",
        "\n",
        "    def getVisulizationFile(self):\n",
        "        return(self.file_name + '.embedding' + '_' + str(self.EMBEDDING_NOISE_LEVEL) + '_' +  'tSNE.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "275fd779-1f5d-4e4c-9b22-55a6866e9dd9",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "275fd779-1f5d-4e4c-9b22-55a6866e9dd9",
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1632873040592,
        "executionStopTime": 1632873040604
      },
      "source": [
        "NOISE = 0\n",
        "f = pycoder_parameters()\n",
        "f.setNoiseLevel(NOISE)\n",
        "f.embedding = f.getEmbeddingFile() \n",
        "print(f.embedding)\n",
        "print(f.SHAPE_EMBEDDING_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f933af4f-f84a-41b8-bb82-13405d634757",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "f933af4f-f84a-41b8-bb82-13405d634757",
        "code_folding": [],
        "hidden_ranges": [],
        "executionStartTime": 1632873298329,
        "executionStopTime": 1632873298335
      },
      "source": [
        "import numpy as np\n",
        " \n",
        "def add_noise(orig_tensor):\n",
        "    \n",
        "    orig_tensor = orig_tensor.double()\n",
        "    data = torch.flatten(orig_tensor).numpy()\n",
        "\n",
        "    zero_like = torch.flatten(torch.zeros_like(orig_tensor,dtype=bool))\n",
        "\n",
        "    mask = zero_like.numpy()\n",
        "\n",
        "    elem_size = np.prod(list(orig_tensor.shape))\n",
        "    N =  int(elem_size * f.EMBEDDING_NOISE_LEVEL)\n",
        "    \n",
        "    # marking first n indexes as true\n",
        "    mask[:N] = True\n",
        "    \n",
        "    # shuffling the mask\n",
        "    np.random.shuffle(mask)\n",
        "    \n",
        "    # applying mask to the data\n",
        "    data[mask] = 0\n",
        "    return(torch.Tensor(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "f8d7fc48-0632-4921-90d2-2980cdae83f9",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "f8d7fc48-0632-4921-90d2-2980cdae83f9",
        "executionStartTime": 1632873300533,
        "executionStopTime": 1632873300642
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "EMBEDDING_SIZE = f.EMBEDDING_SIZE\n",
        "SHAPE_EMBEDDING_SIZE = f.SHAPE_EMBEDDING_SIZE\n",
        "\n",
        "def encode_values_to_code(tensor):\n",
        "    tensor = tensor.clone()\n",
        "    tensor[(tensor>=100) & (tensor<1000)] = 100\n",
        "    tensor[(tensor>=1000)] = 101\n",
        "    tensor[(tensor<=-20) & (tensor>-100)] = -20\n",
        "    tensor[(tensor<=-100) & (tensor>-1000)] = -21\n",
        "    tensor[(tensor<=-1000)] = -22\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def tensor_flatten_pad(tensor, embed_size=EMBEDDING_SIZE, shape_embed_size=SHAPE_EMBEDDING_SIZE, isNoise=False):\n",
        "    \n",
        "    t_flatten = torch.flatten(tensor)\n",
        "\n",
        "    if isNoise is True:\n",
        "        t_flatten = add_noise(t_flatten)\n",
        "    padding_length = embed_size - list(t_flatten.shape)[-1]\n",
        "    p1d = (0,padding_length) #just padding the last dimension\n",
        "    t_pad = F.pad(input=t_flatten, pad=p1d, mode='constant', value=0).type(torch.FloatTensor)\n",
        "    \n",
        "    type_padding = 0\n",
        "    if tensor.dtype == torch.bool:\n",
        "        type_padding = 1\n",
        "    elif tensor.dtype == torch.float64 \\\n",
        "        or tensor.dtype == torch.double \\\n",
        "        or tensor.dtype == torch.float32 \\\n",
        "        or tensor.dtype == torch.float16:\n",
        "            type_padding = 2\n",
        "    \n",
        "\n",
        "    '''size embedding'''\n",
        "    if(shape_embed_size > 0):\n",
        "        t_shape = list(tensor.shape)\n",
        "        padding_length = shape_embed_size -1 - len(t_shape)\n",
        "        p1d = (0,padding_length) #just padding the last dimension\n",
        "        s_pad = F.pad(input=torch.Tensor(t_shape), pad=p1d, mode='constant', value=0).type(torch.float)\n",
        "\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        s_pad_list = s_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1] + s_pad_list + [-1])\n",
        "    \n",
        "    else:\n",
        "        t_pad_list = t_pad.tolist()\n",
        "        tensor_embedding = torch.Tensor([type_padding] + [-1] + t_pad_list + [-1])\n",
        "        \n",
        "    encoded_tensor = encode_values_to_code(tensor_embedding)\n",
        "    return(encoded_tensor)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "6d4422ac-65f0-40a0-bb16-9e703eeaf0f3",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "6d4422ac-65f0-40a0-bb16-9e703eeaf0f3",
        "executionStartTime": 1632873338407,
        "executionStopTime": 1632873338415
      },
      "source": [
        "all_x_values = []\n",
        "def remove_duplicate(x):\n",
        "    for i in all_x_values:\n",
        "        if torch.equal(i,x) is True:\n",
        "            return(True)\n",
        "    return(False)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "bd2e6a06-95ce-4d3c-a891-99b2fd893205",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "bd2e6a06-95ce-4d3c-a891-99b2fd893205",
        "executionStartTime": 1632873342204,
        "executionStopTime": 1632873342210
      },
      "source": [
        "def load_training_data(dataset):\n",
        "       \n",
        "    global EMBEDDING_SIZE\n",
        "    global api2indx\n",
        "    \n",
        "    X=[]\n",
        "    y=[]\n",
        "    dict_indx = len(api2indx)\n",
        "    for data_list in dataset:\n",
        "        if data_list[-1] == -1:\n",
        "            continue\n",
        "        final_output = data_list[-1][1]\n",
        "        prev_out = torch.Tensor()\n",
        "        api_seq_x = []\n",
        "        api_seq_y = []\n",
        "        for data in data_list:        \n",
        "            if data == -1:\n",
        "                continue    \n",
        "            api = data[0]\n",
        "            if api2indx.get(api, -1) == -1: \n",
        "                api2indx[api] = dict_indx\n",
        "                dict_indx += 1\n",
        "                 \n",
        "            api_indx = api2indx[api]\n",
        "            input_list = data[2] #.get_input()\n",
        "            output_tensor = final_output #data.get_output()\n",
        "\n",
        "            it_pad = []\n",
        "            for input_tensor in input_list:\n",
        "                if input_tensor.shape == prev_out.shape and torch.all(input_tensor.eq(prev_out)).item():\n",
        "                    #same with previous output\n",
        "                    t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                    t[-1] = -1\n",
        "                    it_pad.append(t)\n",
        "                else:         \n",
        "                    #flatten the input tensor\n",
        "                    it_pad.append(tensor_flatten_pad(input_tensor,isNoise=True))\n",
        "                \n",
        "            #adding addidional tensors with zero embeddings for < 2 tensors\n",
        "            for i in range(len(it_pad),3):\n",
        "                t = torch.zeros(EMBEDDING_SIZE + SHAPE_EMBEDDING_SIZE + 1 + 2)\n",
        "                t[-1] = -1\n",
        "                it_pad.append(t)\n",
        "                \n",
        "            ot_pad = tensor_flatten_pad(output_tensor, isNoise=True)\n",
        "            x = T.flatten(T.stack((it_pad[0],it_pad[1], it_pad[2], ot_pad)))      \n",
        "            api_seq_x.append(x) \n",
        "            api_seq_y.append(api_indx)\n",
        "            prev_out = data[1]\n",
        "        X.append(api_seq_x)\n",
        "        y.append(api_seq_y)\n",
        "    print(len(X), len(y))\n",
        "    return(X,y)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "a431720a-2781-45be-9eba-b87542b7be91",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "a431720a-2781-45be-9eba-b87542b7be91",
        "executionStartTime": 1632873347634,
        "executionStopTime": 1632873347706
      },
      "source": [
        "def shuffle_dataset(X_dataset, Y_dataset):\n",
        "\n",
        "    print('len orig_dataset', len(X_dataset),  len(Y_dataset))\n",
        "  \n",
        "    length = len(X_dataset)\n",
        "\n",
        "    idx = list(range(length))  # indices to all elements\n",
        "    random.shuffle(idx)  # in-place shuffle the indices to facilitate random splitting\n",
        "    data_idx = idx[:]\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    x = [X_dataset[i] for i in data_idx]\n",
        "    y = [Y_dataset[i] for i in data_idx]\n",
        "\n",
        "    print(len(x), len(y))\n",
        "    return(x,y)\n",
        "\n",
        "''' Test '''\n",
        "x = [1,2,3,4]\n",
        "y = [5,6,7,8]\n",
        "\n",
        "x, y = shuffle_dataset(x,y)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "c13270b5-43a0-40a5-a087-f6520956e01c",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "c13270b5-43a0-40a5-a087-f6520956e01c",
        "executionStartTime": 1632873350767,
        "executionStopTime": 1632873350779
      },
      "source": [
        "f.setNoiseLevel(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "ca67e714-638c-41c3-b9f0-748507ed1e92",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "ca67e714-638c-41c3-b9f0-748507ed1e92",
        "executionStartTime": 1632874147720,
        "executionStopTime": 1632874147727
      },
      "source": [
        "api2indx = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "21d71bb0-ca01-453f-9483-f4a9887f472f",
        "showInput": false,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": []
      },
      "source": [
        "Traing/Pretraining Embedding Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "cbaa15c7-b0bd-4590-94d8-e9c57f581198",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "cbaa15c7-b0bd-4590-94d8-e9c57f581198",
        "executionStartTime": 1632874153323,
        "executionStopTime": 1632875259892
      },
      "source": [
        "SAVE_FILE = f.fuzzing\n",
        "for i in range(1,9):\n",
        "    fuzz_file = f.Path + '/fuzzing_data/' + str(i*10000) + '_' + SAVE_FILE\n",
        "    embed_file = f.Path + '/training_embeddings/' + str(i*10000) + '_training_embedding.pt' #+ f.embedding\n",
        "    print(fuzz_file, embed_file)\n",
        "    l = torch.load(fuzz_file)\n",
        "    x, y = load_training_data(l)\n",
        "    torch.save((x,y),embed_file)\n",
        "    if i == 1:\n",
        "        torch.save(api2indx, f.Path + '/api2indx.pt')\n",
        "    print('saving done')\n",
        "    l.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "08059bf8-1ea2-43fd-8a96-0a31220a22fe",
        "showInput": true,
        "customInput": null,
        "collapsed": false,
        "requestMsgId": "08059bf8-1ea2-43fd-8a96-0a31220a22fe",
        "executionStartTime": 1632875685013,
        "executionStopTime": 1632875685155
      },
      "source": [
        "api2indx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "0a18ac5b-788d-4892-9129-16177faf8c41",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "0a18ac5b-788d-4892-9129-16177faf8c41",
        "executionStartTime": 1632875689108,
        "executionStopTime": 1632875689176
      },
      "source": [
        "torch.save(api2indx, f.Path + '/api2indx.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "b2f1b8eb-89f2-41cb-907c-3f564d8d9aa0",
        "showInput": true,
        "customInput": null,
        "code_folding": [],
        "hidden_ranges": [],
        "collapsed": false,
        "requestMsgId": "b2f1b8eb-89f2-41cb-907c-3f564d8d9aa0",
        "executionStartTime": 1632876086583,
        "executionStopTime": 1632876472065
      },
      "source": [
        "SAVE_FILE = f.fuzzing\n",
        "i = 9\n",
        "fuzz_file = f.Path + '/fuzzing_data/' + str(i*10000) + '_' + SAVE_FILE\n",
        "embed_file = f.Path + '/' + str(i*10000) + '_test_embedding.pt' #+ f.embedding\n",
        "print(embed_file)\n",
        "l = torch.load(fuzz_file)\n",
        "x, y = load_training_data(l)\n",
        "torch.save((x,y),embed_file)\n",
        "l.clear()\n",
        "print('saving done')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
